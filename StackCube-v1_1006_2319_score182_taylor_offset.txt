nohup: ignoring input
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
using taylor
RDT_taylor_img_p(
  (t_embedder): TimestepEmbedder(
    (mlp): Sequential(
      (0): Linear(in_features=256, out_features=2048, bias=True)
      (1): SiLU()
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
  )
  (freq_embedder): TimestepEmbedder(
    (mlp): Sequential(
      (0): Linear(in_features=256, out_features=2048, bias=True)
      (1): SiLU()
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
  )
  (blocks): ModuleList(
    (0-27): 28 x RDTBlock_taylor_img_p(
      (norm1): RmsNorm()
      (attn): TaylorAttention(
        (qkv): Linear(in_features=2048, out_features=6144, bias=True)
        (q_norm): RmsNorm()
        (k_norm): RmsNorm()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=2048, out_features=2048, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (cross_attn): TaylorCrossAttention(
        (q): Linear(in_features=2048, out_features=2048, bias=True)
        (kv): Linear(in_features=2048, out_features=4096, bias=True)
        (q_norm): RmsNorm()
        (k_norm): RmsNorm()
        (attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=2048, out_features=2048, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
      )
      (norm2): RmsNorm()
      (ffn): WrappedTaylorMlp(
        (fc1): Linear(in_features=2048, out_features=2048, bias=True)
        (act): GELU(approximate='tanh')
        (fc2): Linear(in_features=2048, out_features=2048, bias=True)
      )
      (norm3): RmsNorm()
    )
  )
  (final_layer): FinalLayer(
    (norm_final): RmsNorm()
    (ffn_final): Mlp(
      (fc1): Linear(in_features=2048, out_features=2048, bias=True)
      (act): GELU(approximate='tanh')
      (drop1): Dropout(p=0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=2048, out_features=128, bias=True)
      (drop2): Dropout(p=0, inplace=False)
    )
  )
)
Diffusion params: 1.228320e+09
Loading weights from /root/autodl-tmp/ckpt/rdt/maniskill-model/rdt/mp_rank_00_model_states.pt
test inter text encode time
0
policy.encode_instruction GPU time: 180.984 ms
1
policy.encode_instruction GPU time: 21.656 ms
2
policy.encode_instruction GPU time: 17.270 ms
3
policy.encode_instruction GPU time: 17.126 ms
4
policy.encode_instruction GPU time: 17.091 ms
5
policy.encode_instruction GPU time: 17.472 ms
6
policy.encode_instruction GPU time: 17.322 ms
7
policy.encode_instruction GPU time: 18.006 ms
8
policy.encode_instruction GPU time: 20.458 ms
9
policy.encode_instruction GPU time: 17.233 ms
10
policy.encode_instruction GPU time: 17.140 ms
11
policy.encode_instruction GPU time: 17.134 ms
12
policy.encode_instruction GPU time: 17.162 ms
13
policy.encode_instruction GPU time: 17.202 ms
14
policy.encode_instruction GPU time: 17.518 ms
15
policy.encode_instruction GPU time: 17.122 ms
16
policy.encode_instruction GPU time: 17.140 ms
17
policy.encode_instruction GPU time: 17.145 ms
18
policy.encode_instruction GPU time: 17.243 ms
19
policy.encode_instruction GPU time: 17.138 ms
20
policy.encode_instruction GPU time: 17.131 ms
21
policy.encode_instruction GPU time: 17.112 ms
22
policy.encode_instruction GPU time: 17.189 ms
23
policy.encode_instruction GPU time: 18.591 ms
24
policy.encode_instruction GPU time: 17.534 ms
25
policy.encode_instruction GPU time: 17.128 ms
26
policy.encode_instruction GPU time: 17.047 ms
27
policy.encode_instruction GPU time: 17.101 ms
28
policy.encode_instruction GPU time: 17.084 ms
29
policy.encode_instruction GPU time: 17.153 ms
[ 0.01        0.31622777 10.        ]
grid search:   0%|          | 0/9 [00:00<?, ?it/s]
  0%|          | 0/10 [00:00<?, ?it/s][ARunning trial with alpha=1.0, temp=0.01. Re-seeding with 20241201.


  0%|          | 0/25 [00:00<?, ?it/s][A[Abefore pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  34.24972915649414
-------------------------------
-------------------------------
model running time:  7.897088050842285
-------------------------------
-------------------------------
model running time:  29.519744873046875
-------------------------------
-------------------------------
model running time:  9.734208106994629
-------------------------------
-------------------------------
model running time:  26.138591766357422
-------------------------------
Vision time :  145.10922241210938
Action time :  143.70716857910156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.08243179321289
-------------------------------
-------------------------------
model running time:  7.823359966278076
-------------------------------
-------------------------------
model running time:  26.11814308166504
-------------------------------
-------------------------------
model running time:  9.684991836547852
-------------------------------
-------------------------------
model running time:  25.970848083496094
-------------------------------
Vision time :  85.50272369384766
Action time :  101.57158660888672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.445951461791992
-------------------------------
-------------------------------
model running time:  7.819136142730713
-------------------------------
-------------------------------
model running time:  31.091712951660156
-------------------------------
-------------------------------
model running time:  9.696255683898926
-------------------------------
-------------------------------
model running time:  26.007551193237305
-------------------------------
Vision time :  85.58073425292969
Action time :  107.19641876220703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.87945556640625
-------------------------------
-------------------------------
model running time:  7.930880069732666
-------------------------------
-------------------------------
model running time:  26.281984329223633
-------------------------------
-------------------------------
model running time:  9.753600120544434
-------------------------------
-------------------------------
model running time:  25.94099235534668
-------------------------------
Vision time :  85.51692962646484
Action time :  107.7422103881836
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.227840423583984
-------------------------------
-------------------------------
model running time:  7.85203218460083
-------------------------------
-------------------------------
model running time:  26.22368049621582
-------------------------------
-------------------------------
model running time:  13.461503982543945
-------------------------------
-------------------------------
model running time:  27.852800369262695
-------------------------------
Vision time :  85.52448272705078
Action time :  107.67565155029297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.346752166748047
-------------------------------
-------------------------------
model running time:  7.812160015106201
-------------------------------
-------------------------------
model running time:  25.887744903564453
-------------------------------
-------------------------------
model running time:  9.657471656799316
-------------------------------
-------------------------------
model running time:  25.6942081451416
-------------------------------
Vision time :  85.52349090576172
Action time :  101.47315216064453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.09644889831543
-------------------------------
-------------------------------
model running time:  10.75216007232666
-------------------------------
-------------------------------
model running time:  26.039295196533203
-------------------------------
-------------------------------
model running time:  9.635007858276367
-------------------------------
-------------------------------
model running time:  25.8734073638916
-------------------------------
Vision time :  87.06947326660156
Action time :  108.45990753173828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.129535675048828
-------------------------------
-------------------------------
model running time:  7.845888137817383
-------------------------------
-------------------------------
model running time:  25.884672164916992
-------------------------------
-------------------------------
model running time:  9.630847930908203
-------------------------------
-------------------------------
model running time:  25.804800033569336
-------------------------------
Vision time :  85.50572967529297
Action time :  101.02272033691406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952


  4%|â–         | 1/25 [00:05<02:03,  5.13s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.19526481628418
-------------------------------
-------------------------------
model running time:  7.788544178009033
-------------------------------
-------------------------------
model running time:  26.070016860961914
-------------------------------
-------------------------------
model running time:  9.62559986114502
-------------------------------
-------------------------------
model running time:  25.869279861450195
-------------------------------
Vision time :  85.52777862548828
Action time :  106.378173828125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.317951202392578
-------------------------------
-------------------------------
model running time:  11.292672157287598
-------------------------------
-------------------------------
model running time:  26.231807708740234
-------------------------------
-------------------------------
model running time:  9.615360260009766
-------------------------------
-------------------------------
model running time:  25.746431350708008
-------------------------------
Vision time :  85.50316619873047
Action time :  110.25698852539062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.204288482666016
-------------------------------
-------------------------------
model running time:  7.803904056549072
-------------------------------
-------------------------------
model running time:  25.816064834594727
-------------------------------
-------------------------------
model running time:  9.571328163146973
-------------------------------
-------------------------------
model running time:  25.662464141845703
-------------------------------
Vision time :  85.5185317993164
Action time :  101.02774047851562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.542207717895508
-------------------------------
-------------------------------
model running time:  7.833536148071289
-------------------------------
-------------------------------
model running time:  26.76838493347168
-------------------------------
-------------------------------
model running time:  9.652223587036133
-------------------------------
-------------------------------
model running time:  25.96454429626465
-------------------------------
Vision time :  85.55443572998047
Action time :  102.91187286376953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.802623748779297
-------------------------------
-------------------------------
model running time:  7.8397440910339355
-------------------------------
-------------------------------
model running time:  26.10688018798828
-------------------------------
-------------------------------
model running time:  9.664511680603027
-------------------------------
-------------------------------
model running time:  25.95635223388672
-------------------------------
Vision time :  85.51689910888672
Action time :  105.26105499267578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.689088821411133
-------------------------------
-------------------------------
model running time:  7.792640209197998
-------------------------------
-------------------------------
model running time:  25.92473602294922
-------------------------------
-------------------------------
model running time:  9.663488388061523
-------------------------------
-------------------------------
model running time:  25.779199600219727
-------------------------------
Vision time :  85.50588989257812
Action time :  102.8210220336914
Trial 1 finished, success: tensor([True]), steps: 223
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.285184860229492
-------------------------------
-------------------------------
model running time:  7.811071872711182
-------------------------------
-------------------------------
model running time:  28.33510398864746
-------------------------------
-------------------------------
model running time:  9.615360260009766
-------------------------------
-------------------------------
model running time:  25.95840072631836
-------------------------------
Vision time :  85.52671813964844
Action time :  103.8407974243164
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.717632293701172
-------------------------------
-------------------------------
model running time:  7.828479766845703
-------------------------------
-------------------------------
model running time:  26.431488037109375
-------------------------------
-------------------------------
model running time:  9.639936447143555
-------------------------------
-------------------------------
model running time:  35.57785415649414
-------------------------------
Vision time :  85.5223388671875
Action time :  115.06687927246094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.327295303344727
-------------------------------
-------------------------------
model running time:  7.83462381362915
-------------------------------
-------------------------------
model running time:  26.11510467529297
-------------------------------
-------------------------------
model running time:  9.647104263305664
-------------------------------
-------------------------------
model running time:  25.983999252319336
-------------------------------
Vision time :  85.52595520019531
Action time :  101.95148468017578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.832895278930664
-------------------------------
-------------------------------
model running time:  7.8540802001953125
-------------------------------
-------------------------------
model running time:  34.22630310058594
-------------------------------
-------------------------------
model running time:  9.607168197631836
-------------------------------
-------------------------------
model running time:  25.94713592529297
-------------------------------
Vision time :  85.52175903320312
Action time :  110.4764175415039
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.663360595703125
-------------------------------
-------------------------------
model running time:  7.791776180267334
-------------------------------
-------------------------------
model running time:  26.11404800415039
-------------------------------
-------------------------------
model running time:  11.13702392578125
-------------------------------
-------------------------------
model running time:  26.055679321289062
-------------------------------
Vision time :  85.5318374633789
Action time :  106.73664093017578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.214111328125
-------------------------------
-------------------------------
model running time:  7.833600044250488
-------------------------------
-------------------------------
model running time:  26.032127380371094
-------------------------------
-------------------------------
model running time:  9.638751983642578
-------------------------------
-------------------------------
model running time:  25.746431350708008
-------------------------------
Vision time :  85.52934265136719
Action time :  105.33171081542969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.03446388244629
-------------------------------
-------------------------------
model running time:  7.781375885009766
-------------------------------
-------------------------------
model running time:  25.92563247680664
-------------------------------
-------------------------------
model running time:  9.5928316116333
-------------------------------
-------------------------------
model running time:  25.775007247924805
-------------------------------
Vision time :  85.5208969116211
Action time :  105.75872039794922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.017791748046875
-------------------------------
-------------------------------
model running time:  7.968768119812012
-------------------------------
-------------------------------
model running time:  25.93484878540039
-------------------------------
-------------------------------
model running time:  9.641983985900879
-------------------------------
-------------------------------
model running time:  28.481536865234375
-------------------------------
Vision time :  85.50950622558594
Action time :  105.87443542480469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.260576248168945
-------------------------------
-------------------------------
model running time:  7.821311950683594
-------------------------------
-------------------------------
model running time:  29.96531105041504
-------------------------------
-------------------------------
model running time:  9.705471992492676
-------------------------------
-------------------------------
model running time:  25.95123291015625
-------------------------------
Vision time :  85.54444885253906
Action time :  106.60249328613281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.27801513671875
-------------------------------
-------------------------------
model running time:  7.7691521644592285
-------------------------------
-------------------------------
model running time:  25.961471557617188
-------------------------------
-------------------------------
model running time:  9.653247833251953
-------------------------------
-------------------------------
model running time:  25.8918399810791
-------------------------------
Vision time :  85.56102752685547
Action time :  101.27875518798828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.646080017089844
-------------------------------
-------------------------------
model running time:  8.034208297729492
-------------------------------
-------------------------------
model running time:  26.46233558654785
-------------------------------
-------------------------------
model running time:  9.759743690490723
-------------------------------
-------------------------------
model running time:  25.95840072631836
-------------------------------
Vision time :  85.60018920898438
Action time :  103.95750427246094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.004671096801758
-------------------------------
-------------------------------
model running time:  7.827455997467041
-------------------------------
-------------------------------
model running time:  26.150911331176758
-------------------------------
-------------------------------
model running time:  9.631744384765625
-------------------------------
-------------------------------
model running time:  25.983104705810547
-------------------------------
Vision time :  85.58758544921875
Action time :  108.46412658691406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.75833511352539
-------------------------------
-------------------------------
model running time:  7.7649922370910645
-------------------------------
-------------------------------
model running time:  26.078176498413086
-------------------------------
-------------------------------
model running time:  9.656384468078613
-------------------------------
-------------------------------
model running time:  25.90719985961914
-------------------------------
Vision time :  85.59190368652344
Action time :  109.05497741699219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.012832641601562
-------------------------------
-------------------------------
model running time:  7.780447959899902
-------------------------------
-------------------------------
model running time:  25.988096237182617
-------------------------------
-------------------------------
model running time:  9.649151802062988
-------------------------------
-------------------------------
model running time:  25.837568283081055
-------------------------------
Vision time :  85.50003051757812
Action time :  106.08534240722656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.08755111694336
-------------------------------
-------------------------------
model running time:  7.7854719161987305
-------------------------------
-------------------------------
model running time:  31.248384475708008
-------------------------------
-------------------------------
model running time:  9.5928316116333
-------------------------------
-------------------------------
model running time:  25.756671905517578
-------------------------------
Vision time :  85.5373764038086
Action time :  106.17855834960938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.120319366455078
-------------------------------
-------------------------------
model running time:  7.781375885009766
-------------------------------
-------------------------------
model running time:  25.89081573486328
-------------------------------
-------------------------------
model running time:  12.882944107055664
-------------------------------
-------------------------------
model running time:  25.777151107788086
-------------------------------
Vision time :  85.5307846069336
Action time :  105.60307312011719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.30463981628418
-------------------------------
-------------------------------
model running time:  7.789728164672852
-------------------------------
-------------------------------
model running time:  26.028032302856445
-------------------------------
-------------------------------
model running time:  9.598976135253906
-------------------------------
-------------------------------
model running time:  26.265600204467773
-------------------------------
Vision time :  85.53689575195312
Action time :  101.96685028076172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.34662437438965
-------------------------------
-------------------------------
model running time:  7.816192150115967
-------------------------------
-------------------------------
model running time:  25.91436767578125
-------------------------------
-------------------------------
model running time:  9.595968246459961
-------------------------------
-------------------------------
model running time:  25.7761287689209
-------------------------------
Vision time :  85.54537963867188
Action time :  101.24694061279297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.228864669799805


  8%|â–Š         | 2/25 [00:14<02:50,  7.43s/it][A[A-------------------------------
-------------------------------
model running time:  7.835648059844971
-------------------------------
-------------------------------
model running time:  25.927711486816406
-------------------------------
-------------------------------
model running time:  9.629695892333984
-------------------------------
-------------------------------
model running time:  25.9051513671875
-------------------------------
Vision time :  85.5367660522461
Action time :  101.41081237792969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.33945655822754
-------------------------------
-------------------------------
model running time:  7.828479766845703
-------------------------------
-------------------------------
model running time:  25.967647552490234
-------------------------------
-------------------------------
model running time:  9.640064239501953
-------------------------------
-------------------------------
model running time:  25.91651153564453
-------------------------------
Vision time :  85.53794860839844
Action time :  101.4097900390625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.897504806518555
-------------------------------
-------------------------------
model running time:  7.862271785736084
-------------------------------
-------------------------------
model running time:  26.18067169189453
-------------------------------
-------------------------------
model running time:  9.650176048278809
-------------------------------
-------------------------------
model running time:  26.207231521606445
-------------------------------
Vision time :  85.5987548828125
Action time :  108.48767852783203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.315807342529297
-------------------------------
-------------------------------
model running time:  7.757823944091797
-------------------------------
-------------------------------
model running time:  25.865087509155273
-------------------------------
-------------------------------
model running time:  9.688096046447754
-------------------------------
-------------------------------
model running time:  26.184831619262695
-------------------------------
Vision time :  85.5745620727539
Action time :  101.75794982910156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.360000610351562
-------------------------------
-------------------------------
model running time:  7.803904056549072
-------------------------------
-------------------------------
model running time:  27.157440185546875
-------------------------------
-------------------------------
model running time:  14.67801570892334
-------------------------------
-------------------------------
model running time:  25.99839973449707
-------------------------------
Vision time :  85.56806182861328
Action time :  109.33135986328125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.374303817749023
-------------------------------
-------------------------------
model running time:  7.8243842124938965
-------------------------------
-------------------------------
model running time:  26.044416427612305
-------------------------------
-------------------------------
model running time:  9.660415649414062
-------------------------------
-------------------------------
model running time:  25.796607971191406
-------------------------------
Vision time :  85.5417251586914
Action time :  101.6473617553711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.373247146606445
-------------------------------
-------------------------------
model running time:  7.80185604095459
-------------------------------
-------------------------------
model running time:  26.08844757080078
-------------------------------
-------------------------------
model running time:  9.656319618225098
-------------------------------
-------------------------------
model running time:  32.059425354003906
-------------------------------
Vision time :  85.52409362792969
Action time :  107.82403564453125
Trial 2 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.249343872070312
-------------------------------
-------------------------------
model running time:  7.826432228088379
-------------------------------
-------------------------------
model running time:  25.953279495239258
-------------------------------
-------------------------------
model running time:  10.20911979675293
-------------------------------
-------------------------------
model running time:  25.765888214111328
-------------------------------
Vision time :  85.50972747802734
Action time :  102.54742431640625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.1889591217041
-------------------------------
-------------------------------


 12%|â–ˆâ–        | 3/25 [00:16<01:50,  5.01s/it][A[Amodel running time:  7.796576023101807
-------------------------------
-------------------------------
model running time:  26.070016860961914
-------------------------------
-------------------------------
model running time:  9.710592269897461
-------------------------------
-------------------------------
model running time:  25.773056030273438
-------------------------------
Vision time :  85.53187561035156
Action time :  106.61068725585938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.392704010009766
-------------------------------
-------------------------------
model running time:  7.856031894683838
-------------------------------
-------------------------------
model running time:  26.73049545288086
-------------------------------
-------------------------------
model running time:  9.771007537841797
-------------------------------
-------------------------------
model running time:  25.806751251220703
-------------------------------
Vision time :  85.53580474853516
Action time :  102.43276977539062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.220672607421875
-------------------------------
-------------------------------
model running time:  7.8151679039001465
-------------------------------
-------------------------------
model running time:  30.49465560913086
-------------------------------
-------------------------------
model running time:  9.593855857849121
-------------------------------
-------------------------------
model running time:  25.75872039794922
-------------------------------
Vision time :  85.55801391601562
Action time :  105.84371185302734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.221696853637695
-------------------------------
-------------------------------
model running time:  7.784448146820068
-------------------------------
-------------------------------
model running time:  25.888736724853516
-------------------------------
-------------------------------
model running time:  9.655232429504395
-------------------------------
-------------------------------
model running time:  26.265600204467773
-------------------------------
Vision time :  85.53584289550781
Action time :  103.71481323242188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.60748863220215
-------------------------------
-------------------------------
model running time:  7.818240165710449
-------------------------------
-------------------------------
model running time:  26.036224365234375
-------------------------------
-------------------------------
model running time:  9.657343864440918
-------------------------------
-------------------------------
model running time:  25.833471298217773
-------------------------------
Vision time :  85.54441833496094
Action time :  107.76576232910156
Trial 3 finished, success: tensor([True]), steps: 96
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.48588752746582
-------------------------------
-------------------------------
model running time:  7.782271862030029
-------------------------------
-------------------------------
model running time:  30.060447692871094
-------------------------------
-------------------------------
model running time:  9.671680450439453
-------------------------------
-------------------------------
model running time:  26.1529598236084
-------------------------------
Vision time :  85.52735900878906
Action time :  106.27568054199219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.337312698364258
-------------------------------
-------------------------------
model running time:  10.863615989685059
-------------------------------
-------------------------------
model running time:  26.374143600463867
-------------------------------
-------------------------------
model running time:  9.746432304382324
-------------------------------
-------------------------------
model running time:  26.029184341430664
-------------------------------
Vision time :  85.55072021484375
Action time :  105.24262237548828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.367103576660156
-------------------------------
-------------------------------
model running time:  7.860288143157959
-------------------------------
-------------------------------
model running time:  25.846784591674805
-------------------------------
-------------------------------
model running time:  9.586688041687012
-------------------------------
-------------------------------
model running time:  25.682912826538086
-------------------------------
Vision time :  85.54208374023438
Action time :  101.3205795288086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.32819175720215
-------------------------------
-------------------------------
model running time:  7.853055953979492
-------------------------------
-------------------------------
model running time:  26.037248611450195
-------------------------------
-------------------------------
model running time:  9.656319618225098
-------------------------------
-------------------------------
model running time:  26.73766326904297
-------------------------------
Vision time :  85.55465698242188
Action time :  102.71743774414062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.412160873413086
-------------------------------
-------------------------------
model running time:  7.856128215789795
-------------------------------
-------------------------------
model running time:  25.945087432861328
-------------------------------
-------------------------------
model running time:  9.674752235412598
-------------------------------
-------------------------------
model running time:  25.72991943359375
-------------------------------
Vision time :  85.54496002197266
Action time :  101.56556701660156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.886272430419922
-------------------------------
-------------------------------
model running time:  7.824351787567139
-------------------------------
-------------------------------
model running time:  26.272768020629883
-------------------------------
-------------------------------
model running time:  9.72492790222168
-------------------------------
-------------------------------
model running time:  26.390527725219727
-------------------------------
Vision time :  85.55078125
Action time :  103.47007751464844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.344512939453125
-------------------------------
-------------------------------
model running time:  7.872416019439697
-------------------------------
-------------------------------
model running time:  26.101760864257812
-------------------------------
-------------------------------
model running time:  9.744383811950684
-------------------------------
-------------------------------
model running time:  26.108928680419922
-------------------------------
Vision time :  85.58319854736328
Action time :  102.36518096923828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.47260856628418
-------------------------------
-------------------------------
model running time:  7.8305277824401855
-------------------------------
-------------------------------
model running time:  26.058752059936523
-------------------------------
-------------------------------
model running time:  9.641119956970215
-------------------------------
-------------------------------
model running time:  25.981952667236328
-------------------------------
Vision time :  85.54940795898438
Action time :  101.97926330566406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.11404800415039
-------------------------------
-------------------------------
model running time:  7.837696075439453
-------------------------------
-------------------------------
model running time:  25.825279235839844
-------------------------------
-------------------------------
model running time:  9.665535926818848
-------------------------------
-------------------------------
model running time:  25.738239288330078
-------------------------------
Vision time :  85.54073333740234
Action time :  101.00121307373047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.252416610717773
-------------------------------
-------------------------------
model running time:  7.817376136779785
-------------------------------
-------------------------------
model running time:  25.733055114746094
-------------------------------
-------------------------------
model running time:  9.61843204498291
-------------------------------
-------------------------------
model running time:  25.664512634277344
-------------------------------
Vision time :  87.12163543701172
Action time :  100.96947479248047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.166400909423828
-------------------------------
-------------------------------
model running time:  7.829504013061523
-------------------------------
-------------------------------
model running time:  25.793535232543945
-------------------------------
-------------------------------
model running time:  9.626688003540039
-------------------------------
-------------------------------
model running time:  25.72390365600586
-------------------------------
Vision time :  85.56070709228516
Action time :  100.92851257324219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.456192016601562
-------------------------------
-------------------------------
model running time:  7.8540802001953125
-------------------------------
-------------------------------
model running time:  25.91334342956543
-------------------------------
-------------------------------
model running time:  9.677824020385742
-------------------------------
-------------------------------
model running time:  32.084991455078125
-------------------------------
Vision time :  85.61622619628906
Action time :  108.92390441894531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.26367950439453
-------------------------------
-------------------------------
model running time:  8.068096160888672
-------------------------------
-------------------------------
model running time:  25.809919357299805
-------------------------------
-------------------------------
model running time:  12.937215805053711
-------------------------------
-------------------------------
model running time:  25.71059226989746
-------------------------------
Vision time :  85.55677032470703
Action time :  104.63641357421875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.389631271362305
-------------------------------
-------------------------------
model running time:  7.829408168792725
-------------------------------
-------------------------------
model running time:  25.94611167907715
-------------------------------
-------------------------------
model running time:  12.552191734313965
-------------------------------
-------------------------------
model running time:  25.979904174804688
-------------------------------
Vision time :  85.5384292602539
Action time :  105.1371841430664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.051136016845703
-------------------------------
-------------------------------
model running time:  7.894015789031982
-------------------------------
-------------------------------
model running time:  26.005504608154297
-------------------------------
-------------------------------
model running time:  9.657343864440918
-------------------------------
-------------------------------
model running time:  30.76697540283203
-------------------------------
Vision time :  85.67001342773438
Action time :  107.57222747802734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.1276798248291
-------------------------------
-------------------------------
model running time:  7.860223770141602
-------------------------------
-------------------------------
model running time:  25.997312545776367
-------------------------------
-------------------------------
model running time:  9.683903694152832
-------------------------------
-------------------------------
model running time:  25.9071044921875
-------------------------------
Vision time :  85.71424102783203
Action time :  106.26969909667969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.24627113342285
-------------------------------
-------------------------------
model running time:  7.865344047546387
-------------------------------
-------------------------------
model running time:  25.96659278869629
-------------------------------
-------------------------------
model running time:  9.63584041595459
-------------------------------
-------------------------------
model running time:  29.9202880859375
-------------------------------
Vision time :  85.60899353027344
Action time :  105.64812469482422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.266752243041992
-------------------------------
-------------------------------
model running time:  7.864319801330566
-------------------------------
-------------------------------
model running time:  25.825279235839844
-------------------------------
-------------------------------
model running time:  9.6112642288208
-------------------------------
-------------------------------
model running time:  25.749664306640625
-------------------------------
Vision time :  85.5150375366211
Action time :  101.03910064697266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.427520751953125
-------------------------------
-------------------------------
model running time:  7.868415832519531
-------------------------------
-------------------------------
model running time:  26.75814437866211
-------------------------------
-------------------------------
model running time:  9.71776008605957
-------------------------------
-------------------------------
model running time:  30.017663955688477
-------------------------------
Vision time :  85.531005859375
Action time :  106.90662384033203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.41302490234375
-------------------------------
-------------------------------
model running time:  7.871488094329834
-------------------------------
-------------------------------
model running time:  33.32112121582031
-------------------------------
-------------------------------
model running time:  9.674752235412598
-------------------------------
-------------------------------
model running time:  

 16%|â–ˆâ–Œ        | 4/25 [00:25<02:18,  6.59s/it][A[A25.94304084777832
-------------------------------
Vision time :  85.57170867919922
Action time :  109.39596557617188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.15590476989746
-------------------------------
-------------------------------
model running time:  7.896063804626465
-------------------------------
-------------------------------
model running time:  26.984447479248047
-------------------------------
-------------------------------
model running time:  9.720831871032715
-------------------------------
-------------------------------
model running time:  25.775104522705078
-------------------------------
Vision time :  85.54204559326172
Action time :  106.2481918334961
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.816064834594727
-------------------------------
-------------------------------
model running time:  7.846911907196045
-------------------------------
-------------------------------
model running time:  25.818111419677734
-------------------------------
-------------------------------
model running time:  9.696255683898926
-------------------------------
-------------------------------
model running time:  25.71980857849121
-------------------------------
Vision time :  85.56582641601562
Action time :  102.68978881835938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.135679244995117
-------------------------------
-------------------------------
model running time:  7.821343898773193
-------------------------------
-------------------------------
model running time:  25.7761287689209
-------------------------------
-------------------------------
model running time:  9.680895805358887
-------------------------------
-------------------------------
model running time:  25.71366310119629
-------------------------------
Vision time :  85.54518127441406
Action time :  100.91007995605469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.151039123535156
-------------------------------
-------------------------------
model running time:  7.857183933258057
-------------------------------
-------------------------------
model running time:  25.867263793945312
-------------------------------
-------------------------------
model running time:  9.658368110656738
-------------------------------
-------------------------------
model running time:  25.74950408935547
-------------------------------
Vision time :  85.561279296875
Action time :  100.99906921386719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.755840301513672
-------------------------------
-------------------------------
model running time:  7.871583938598633
-------------------------------
-------------------------------
model running time:  26.070016860961914
-------------------------------
-------------------------------
model running time:  9.656319618225098
-------------------------------
-------------------------------
model running time:  30.32067108154297
-------------------------------
Vision time :  85.56537628173828
Action time :  112.69427490234375
Trial 4 finished, success: tensor([True]), steps: 399
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.293376922607422
-------------------------------
-------------------------------
model running time:  7.8745598793029785
-------------------------------
-------------------------------
model running time:  25.894943237304688
-------------------------------
-------------------------------
model running time:  9.677824020385742
-------------------------------
-------------------------------
model running time:  28.011520385742188
-------------------------------
Vision time :  85.5689926147461
Action time :  103.55712127685547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.33545684814453
-------------------------------
-------------------------------
model running time:  7.876607894897461
-------------------------------
-------------------------------
model running time:  26.10688018798828
-------------------------------
-------------------------------
model running time:  9.663423538208008
-------------------------------
-------------------------------
model running time:  25.816064834594727
-------------------------------
Vision time :  85.66937255859375
Action time :  101.57465362548828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.297344207763672
-------------------------------
-------------------------------
model running time:  7.856128215789795
-------------------------------
-------------------------------
model running time:  25.993215560913086
-------------------------------
-------------------------------
model running time:  10.481663703918457
-------------------------------
-------------------------------
model running time:  25.967744827270508
-------------------------------
Vision time :  85.65846252441406
Action time :  102.35801696777344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.345600128173828
-------------------------------
-------------------------------
model running time:  7.842751979827881
-------------------------------
-------------------------------
model running time:  34.55692672729492
-------------------------------
-------------------------------
model running time:  9.656319618225098
-------------------------------
-------------------------------
model running time:  25.82521629333496
-------------------------------
Vision time :  85.68585968017578
Action time :  110.060546875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.12224006652832
-------------------------------
-------------------------------
model running time:  7.769184112548828
-------------------------------
-------------------------------
model running time:  25.69932746887207
-------------------------------
-------------------------------
model running time:  9.646080017089844
-------------------------------
-------------------------------
model running time:  31.518720626831055
-------------------------------
Vision time :  85.55136108398438
Action time :  106.50006103515625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.257568359375
-------------------------------
-------------------------------
model running time:  7.873536109924316
-------------------------------
-------------------------------
model running time:  25.80873680114746
-------------------------------
-------------------------------
model running time:  9.714688301086426
-------------------------------
-------------------------------
model running time:  25.632768630981445
-------------------------------
Vision time :  85.55766296386719
Action time :  101.14252471923828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.301055908203125
-------------------------------
-------------------------------
model running time:  7.827455997467041
-------------------------------
-------------------------------
model running time:  25.774080276489258
-------------------------------
-------------------------------
model running time:  9.645055770874023
-------------------------------
-------------------------------
model running time:  25.605119705200195
-------------------------------
Vision time :  85.67308807373047
Action time :  102.03750610351562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.365055084228516
-------------------------------
-------------------------------
model running time:  7.857151985168457
-------------------------------
-------------------------------
model running time:  25.74950408935547
-------------------------------
-------------------------------
model running time:  9.608192443847656
-------------------------------
-------------------------------
model running time:  25.651199340820312
-------------------------------
Vision time :  85.66175842285156
Action time :  101.06470489501953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.90015983581543
-------------------------------
-------------------------------
model running time:  7.851903915405273
-------------------------------
-------------------------------
model running time:  25.686016082763672
-------------------------------
-------------------------------
model running time:  9.611295700073242
-------------------------------
-------------------------------
model running time:  25.994239807128906
-------------------------------
Vision time :  85.67935943603516
Action time :  100.62950134277344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.205312728881836
-------------------------------
-------------------------------
model running time:  7.85100793838501
-------------------------------
-------------------------------
model running time:  25.745407104492188
-------------------------------
-------------------------------
model running time:  9.600000381469727
-------------------------------
-------------------------------
model running time:  25.73516845703125
-------------------------------
Vision time :  85.53298950195312
Action time :  100.85775756835938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.766016006469727
-------------------------------
-------------------------------
model running time:  9.148415565490723
-------------------------------
-------------------------------
model running time:  25.806848526000977
-------------------------------
-------------------------------
model running time:  9.6461763381958
-------------------------------
-------------------------------
model running time:  25.825279235839844
-------------------------------
Vision time :  85.67823791503906
Action time :  101.72211456298828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.170047760009766
-------------------------------
-------------------------------
model running time:  7.813119888305664
-------------------------------
-------------------------------
model running time:  25.84998321533203
-------------------------------
-------------------------------
model running time:  9.604096412658691
-------------------------------
-------------------------------
model running time:  25.804800033569336
-------------------------------
Vision time :  85.68902587890625
Action time :  107.05203247070312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.213600158691406
-------------------------------
-------------------------------
model running time:  7.814144134521484
-------------------------------
-------------------------------
model running time:  25.930784225463867
-------------------------------
-------------------------------
model running time:  9.640959739685059
-------------------------------
-------------------------------
model running time:  25.781248092651367
-------------------------------
Vision time :  85.69219207763672
Action time :  101.17427062988281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.70400047302246
-------------------------------
-------------------------------
model running time:  7.826591968536377
-------------------------------
-------------------------------
model running time:  25.92255973815918
-------------------------------
-------------------------------
model running time:  9.664575576782227
-------------------------------
-------------------------------
model running time:  25.871360778808594
-------------------------------
Vision time :  85.69116973876953
Action time :  102.02521514892578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.29849624633789
-------------------------------
-------------------------------
model running time:  7.83568000793457
-------------------------------
-------------------------------
model running time:  34.88051223754883
-------------------------------
-------------------------------
model running time:  9.71878433227539
-------------------------------
-------------------------------
model running time:  26.061824798583984
-------------------------------
Vision time :  85.66339111328125
Action time :  110.61759948730469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.426240921020508
-------------------------------
-------------------------------
model running time:  7.9185919761657715
-------------------------------
-------------------------------
model running time:  26.038272857666016
-------------------------------
-------------------------------
model running time:  9.696255683898926
-------------------------------
-------------------------------
model running time:  25.705503463745117
-------------------------------
Vision time :  85.70416259765625
Action time :  105.54073333740234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.136703491210938
-------------------------------
-------------------------------
model running time:  7.85203218460083
-------------------------------
-------------------------------
model running time:  25.748384475708008
-------------------------------
-------------------------------
model running time:  9.622528076171875
-------------------------------
-------------------------------
model running time:  25.637887954711914
-------------------------------
Vision time :  85.68447875976562
Action time :  108.7825927734375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.143871307373047
-------------------------------
-------------------------------
model running time:  7.799808025360107
-------------------------------
-------------------------------
model running time:  25.892864227294922
-------------------------------
-------------------------------
model running time:  9.6080961227417
-------------------------------
-------------------------------
model running time:  25.763839721679688
-------------------------------
Vision time :  85.67756652832031
Action time :  101.18246459960938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.142847061157227
-------------------------------
-------------------------------
model running time:  7.8172478675842285
-------------------------------
-------------------------------
model running time:  25.73731231689453
-------------------------------
-------------------------------
model running time:  9.591808319091797
-------------------------------
-------------------------------
model running time:  25.61440086364746
-------------------------------
Vision time :  85.67436981201172
Action time :  100.66124725341797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 


 20%|â–ˆâ–ˆ        | 5/25 [00:34<02:27,  7.40s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.783615112304688
-------------------------------
-------------------------------
model running time:  7.829504013061523
-------------------------------
-------------------------------
model running time:  25.885696411132812
-------------------------------
-------------------------------
model running time:  9.690112113952637
-------------------------------
-------------------------------
model running time:  27.429887771606445
-------------------------------
Vision time :  85.6824951171875
Action time :  107.40735626220703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.147008895874023
-------------------------------
-------------------------------
model running time:  7.797696113586426
-------------------------------
-------------------------------
model running time:  25.840639114379883
-------------------------------
-------------------------------
model running time:  9.63980770111084
-------------------------------
-------------------------------
model running time:  25.654272079467773
-------------------------------
Vision time :  85.6904296875
Action time :  100.95513916015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.123455047607422
-------------------------------
-------------------------------
model running time:  7.789567947387695
-------------------------------
-------------------------------
model running time:  32.42086410522461
-------------------------------
-------------------------------
model running time:  9.63481616973877
-------------------------------
-------------------------------
model running time:  25.631744384765625
-------------------------------
Vision time :  85.66989135742188
Action time :  107.45750427246094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.996416091918945
-------------------------------
-------------------------------
model running time:  7.822271823883057
-------------------------------
-------------------------------
model running time:  25.76691246032715
-------------------------------
-------------------------------
model running time:  14.69644832611084
-------------------------------
-------------------------------
model running time:  25.641984939575195
-------------------------------
Vision time :  85.68489837646484
Action time :  105.77606201171875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.199167251586914
-------------------------------
-------------------------------
model running time:  7.810912132263184
-------------------------------
-------------------------------
model running time:  25.73107147216797
-------------------------------
-------------------------------
model running time:  9.62662410736084
-------------------------------
-------------------------------
model running time:  26.824735641479492
-------------------------------
Vision time :  85.6794204711914
Action time :  101.9494400024414
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.30771255493164
-------------------------------
-------------------------------
model running time:  7.8654398918151855
-------------------------------
-------------------------------
model running time:  25.93382453918457
-------------------------------
-------------------------------
model running time:  9.679871559143066
-------------------------------
-------------------------------
model running time:  26.223615646362305
-------------------------------
Vision time :  85.66556549072266
Action time :  101.87264251708984
Trial 5 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.351776123046875
-------------------------------
-------------------------------
model running time:  7.90937614440918
-------------------------------
-------------------------------
model running time:  26.017791748046875
-------------------------------
-------------------------------
model running time:  9.670495986938477
-------------------------------
-------------------------------
model running time:  33.202110290527344
-------------------------------
Vision time :  85.6437759399414
Action time :  109.01094055175781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.48793601989746
-------------------------------
-------------------------------
model running time:  7.902207851409912
-------------------------------
-------------------------------
model running time:  26.434560775756836
-------------------------------
-------------------------------
model running time:  9.72390365600586
-------------------------------
-------------------------------
model running time:  29.241344451904297
-------------------------------
Vision time :  85.54902648925781
Action time :  105.71161651611328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.354816436767578
-------------------------------
-------------------------------
model running time:  7.897088050842285
-------------------------------
-------------------------------
model running time:  26.053632736206055
-------------------------------
-------------------------------
model running time:  9.690112113952637
-------------------------------
-------------------------------
model running time:  25.787391662597656
-------------------------------
Vision time :  85.64028930664062
Action time :  101.65760040283203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.572927474975586
-------------------------------
-------------------------------
model running time:  7.85203218460083
-------------------------------
-------------------------------
model running time:  26.262527465820312
-------------------------------
-------------------------------
model running time:  9.70854377746582
-------------------------------
-------------------------------
model running time:  26.064960479736328
-------------------------------
Vision time :  85.68390655517578
Action time :  102.29350280761719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.374271392822266
-------------------------------
-------------------------------
model running time:  7.903232097625732
-------------------------------
-------------------------------
model running time:  26.257408142089844
-------------------------------
-------------------------------
model running time:  9.736191749572754
-------------------------------
-------------------------------
model running time:  26.020864486694336
-------------------------------
Vision time :  85.68025970458984
Action time :  102.26278686523438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.4899845123291
-------------------------------
-------------------------------
model running time:  7.873631954193115
-------------------------------
-------------------------------
model running time:  26.30963134765625
-------------------------------
-------------------------------
model running time:  9.653247833251953
-------------------------------
-------------------------------
model running time:  25.805824279785156
-------------------------------
Vision time :  85.70671844482422
Action time :  102.05184173583984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.171615600585938
-------------------------------
-------------------------------
model running time:  8.062975883483887
-------------------------------
-------------------------------
model running time:  26.12825584411621
-------------------------------
-------------------------------
model running time:  9.71673583984375
-------------------------------
-------------------------------
model running time:  25.94915199279785
-------------------------------
Vision time :  85.67203521728516
Action time :  105.75663757324219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.52422332763672
-------------------------------
-------------------------------
model running time:  7.917568206787109
-------------------------------
-------------------------------
model running time:  26.244096755981445
-------------------------------
-------------------------------
model running time:  9.769984245300293
-------------------------------
-------------------------------
model running time:  27.667455673217773
-------------------------------
Vision time :  85.68534088134766
Action time :  108.55136108398438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.250368118286133
-------------------------------
-------------------------------
model running time:  7.820288181304932
-------------------------------
-------------------------------
model running time:  26.155136108398438
-------------------------------
-------------------------------
model running time:  9.7291841506958
-------------------------------
-------------------------------
model running time:  25.73311996459961
-------------------------------
Vision time :  85.74313354492188
Action time :  101.7159652709961
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.222719192504883
-------------------------------
-------------------------------
model running time:  11.743231773376465
-------------------------------
-------------------------------
model running time:  27.93574333190918
-------------------------------
-------------------------------
model running time:  9.83244800567627
-------------------------------
-------------------------------
model running time:  26.13248062133789
-------------------------------
Vision time :  85.69129943847656
Action time :  110.35852813720703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.30771255493164
-------------------------------
-------------------------------
model running time:  7.884799957275391
-------------------------------
-------------------------------
model running time:  26.052608489990234
-------------------------------
-------------------------------
model running time:  9.70032024383545
-------------------------------
-------------------------------
model running time:  30.402559280395508
-------------------------------
Vision time :  85.72402954101562
Action time :  106.38540649414062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.365055084228516
-------------------------------
-------------------------------
model running time:  7.863455772399902
-------------------------------
-------------------------------
model running time:  25.869312286376953
-------------------------------
-------------------------------
model running time:  16.358400344848633
-------------------------------
-------------------------------
model running time:  25.634815216064453
-------------------------------
Vision time :  85.68946838378906
Action time :  107.863037109375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.465408325195312
-------------------------------
-------------------------------
model running time:  7.833600044250488
-------------------------------
-------------------------------
model running time:  26.044479370117188
-------------------------------
-------------------------------
model running time:  9.663488388061523
-------------------------------
-------------------------------
model running time:  25.644031524658203
-------------------------------
Vision time :  85.68345642089844
Action time :  101.8081283569336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.325183868408203
-------------------------------
-------------------------------
model running time:  7.845888137817383
-------------------------------
-------------------------------
model running time:  25.712543487548828
-------------------------------
-------------------------------
model running time:  9.6245756149292
-------------------------------
-------------------------------
model running time:  25.598976135253906
-------------------------------
Vision time :  85.706787109375
Action time :  107.85183715820312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.251392364501953
-------------------------------
-------------------------------
model running time:  7.774208068847656
-------------------------------
-------------------------------
model running time:  27.4902400970459
-------------------------------
-------------------------------
model running time:  9.62764835357666
-------------------------------
-------------------------------
model running time:  29.908992767333984
-------------------------------
Vision time :  85.678466796875
Action time :  106.87907409667969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.606719970703125
-------------------------------
-------------------------------
model running time:  7.809023857116699
-------------------------------
-------------------------------
model running time:  25.91231918334961
-------------------------------
-------------------------------
model running time:  9.62764835357666
-------------------------------
-------------------------------
model running time:  31.349760055541992
-------------------------------
Vision time :  85.69554901123047
Action time :  107.17081451416016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.24127960205078
-------------------------------
-------------------------------
model running time:  7.8089280128479
-------------------------------
-------------------------------
model running time:  25.951168060302734
-------------------------------
-------------------------------
model running time:  9.652223587036133
-------------------------------
-------------------------------
model running time:  25.810943603515625
-------------------------------
Vision time :  85.68547058105469
Action time :  106.16835021972656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.47769546508789
-------------------------------
-------------------------------
model running time:  7.841760158538818
-------------------------------
-------------------------------
model running time:  25.9737606048584
-------------------------------
-------------------------------
model running time:  9.6778564453125
-------------------------------
-------------------------------
model running time:  25.785472869873047
-------------------------------
Vision time :  85.67603302001953
Action time :  101.65974426269531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.240127563476562
-------------------------------
-------------------------------
model running time:  

 24%|â–ˆâ–ˆâ–       | 6/25 [00:43<02:30,  7.89s/it][A[A7.8438401222229
-------------------------------
-------------------------------
model running time:  26.011648178100586
-------------------------------
-------------------------------
model running time:  9.644031524658203
-------------------------------
-------------------------------
model running time:  25.856000900268555
-------------------------------
Vision time :  85.70787048339844
Action time :  101.56134033203125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.31283187866211
-------------------------------
-------------------------------
model running time:  7.8438401222229
-------------------------------
-------------------------------
model running time:  26.063871383666992
-------------------------------
-------------------------------
model running time:  9.652223587036133
-------------------------------
-------------------------------
model running time:  25.805728912353516
-------------------------------
Vision time :  85.65625762939453
Action time :  101.44255828857422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.33228874206543
-------------------------------
-------------------------------
model running time:  7.80790376663208
-------------------------------
-------------------------------
model running time:  28.197887420654297
-------------------------------
-------------------------------
model running time:  9.681920051574707
-------------------------------
-------------------------------
model running time:  25.884639739990234
-------------------------------
Vision time :  85.6994857788086
Action time :  103.84178924560547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.436735153198242
-------------------------------
-------------------------------
model running time:  7.8448638916015625
-------------------------------
-------------------------------
model running time:  26.019807815551758
-------------------------------
-------------------------------
model running time:  9.701375961303711
-------------------------------
-------------------------------
model running time:  25.815967559814453
-------------------------------
Vision time :  85.6833267211914
Action time :  101.76188659667969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.284160614013672
-------------------------------
-------------------------------
model running time:  7.810976028442383
-------------------------------
-------------------------------
model running time:  26.070016860961914
-------------------------------
-------------------------------
model running time:  11.743231773376465
-------------------------------
-------------------------------
model running time:  25.903104782104492
-------------------------------
Vision time :  85.68899536132812
Action time :  104.26367950439453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.369152069091797
-------------------------------
-------------------------------
model running time:  7.8438401222229
-------------------------------
-------------------------------
model running time:  31.36409568786621
-------------------------------
-------------------------------
model running time:  9.699328422546387
-------------------------------
-------------------------------
model running time:  25.877504348754883
-------------------------------
Vision time :  85.70259094238281
Action time :  106.91686248779297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.156160354614258
-------------------------------
-------------------------------
model running time:  7.7854719161987305
-------------------------------
-------------------------------
model running time:  25.95737648010254
-------------------------------
-------------------------------
model running time:  9.678784370422363
-------------------------------
-------------------------------
model running time:  27.35206413269043
-------------------------------
Vision time :  85.68230438232422
Action time :  104.14591979980469
Trial 6 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.31180763244629
-------------------------------
-------------------------------
model running time:  7.788544178009033
-------------------------------
-------------------------------
model running time:  25.90617561340332
-------------------------------
-------------------------------
model running time:  9.68393611907959
-------------------------------
-------------------------------
model running time:  25.765888214111328
-------------------------------
Vision time :  85.68233489990234
Action time :  101.4128646850586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.225791931152344
-------------------------------
-------------------------------
model running time:  7.882751941680908
-------------------------------
-------------------------------
model running time:  26.264575958251953
-------------------------------
-------------------------------
model running time:  9.645055770874023
-------------------------------
-------------------------------
model running time:  25.870336532592773
-------------------------------
Vision time :  85.71759796142578
Action time :  101.8050537109375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.47974395751953
-------------------------------
-------------------------------
model running time:  11.158368110656738
-------------------------------
-------------------------------
model running time:  26.023807525634766
-------------------------------
-------------------------------
model running time:  9.730048179626465
-------------------------------
-------------------------------
model running time:  25.93280029296875
-------------------------------
Vision time :  85.69091033935547
Action time :  105.23747253417969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.381343841552734
-------------------------------
-------------------------------
model running time:  7.8785600662231445
-------------------------------
-------------------------------
model running time:  25.981088638305664
-------------------------------
-------------------------------
model running time:  9.720831871032715
-------------------------------
-------------------------------
model running time:  34.1288948059082
-------------------------------
Vision time :  85.68156433105469
Action time :  109.94483184814453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.11827278137207
-------------------------------
-------------------------------
model running time:  7.848959922790527
-------------------------------
-------------------------------
model running time:  25.75052833557129
-------------------------------
-------------------------------
model running time:  9.674752235412598
-------------------------------
-------------------------------
model running time:  25.707584381103516
-------------------------------
Vision time :  85.67081451416016
Action time :  100.93247985839844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.190048217773438
-------------------------------
-------------------------------
model running time:  7.80185604095459
-------------------------------
-------------------------------
model running time:  25.876480102539062
-------------------------------
-------------------------------
model running time:  9.978879928588867
-------------------------------
-------------------------------
model running time:  25.74950408935547
-------------------------------
Vision time :  85.68342590332031
Action time :  101.3707504272461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.334272384643555
-------------------------------
-------------------------------
model running time:  7.861248016357422
-------------------------------
-------------------------------
model running time:  25.887744903564453
-------------------------------
-------------------------------
model running time:  9.638912200927734
-------------------------------
-------------------------------
model running time:  25.831424713134766
-------------------------------
Vision time :  85.70381164550781
Action time :  101.45587158203125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.421375274658203
-------------------------------
-------------------------------
model running time:  7.8745598793029785
-------------------------------
-------------------------------
model running time:  25.96659278869629
-------------------------------
-------------------------------
model running time:  9.63584041595459
-------------------------------
-------------------------------
model running time:  33.82271957397461
-------------------------------
Vision time :  85.72185516357422
Action time :  109.66118621826172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.375455856323242
-------------------------------
-------------------------------
model running time:  7.837696075439453
-------------------------------
-------------------------------
model running time:  25.93280029296875
-------------------------------
-------------------------------
model running time:  9.649056434631348
-------------------------------
-------------------------------
model running time:  25.799680709838867
-------------------------------
Vision time :  85.68777465820312
Action time :  102.39180755615234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.35980796813965
-------------------------------
-------------------------------
model running time:  7.848959922790527
-------------------------------
-------------------------------
model running time:  25.954368591308594
-------------------------------
-------------------------------
model running time:  9.647104263305664
-------------------------------
-------------------------------
model running time:  25.774080276489258
-------------------------------
Vision time :  85.6928939819336
Action time :  103.5704345703125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.870912551879883
-------------------------------
-------------------------------
model running time:  7.938047885894775
-------------------------------
-------------------------------
model running time:  26.51238441467285
-------------------------------
-------------------------------
model running time:  9.692159652709961
-------------------------------
-------------------------------
model running time:  26.373119354248047
-------------------------------
Vision time :  85.70944213867188
Action time :  103.3677749633789
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.90163230895996
-------------------------------
-------------------------------
model running time:  7.911359786987305
-------------------------------
-------------------------------
model running time:  26.53900718688965
-------------------------------
-------------------------------
model running time:  9.755647659301758
-------------------------------
-------------------------------
model running time:  26.445823669433594
-------------------------------
Vision time :  85.67088317871094
Action time :  103.6052474975586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.82694435119629
-------------------------------
-------------------------------
model running time:  7.91539192199707
-------------------------------
-------------------------------
model running time:  26.3874568939209
-------------------------------
-------------------------------
model running time:  9.696096420288086
-------------------------------
-------------------------------
model running time:  26.29324722290039
-------------------------------
Vision time :  85.70393371582031
Action time :  103.25299072265625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.808351516723633
-------------------------------
-------------------------------
model running time:  7.913568019866943
-------------------------------
-------------------------------
model running time:  33.02912139892578
-------------------------------
-------------------------------
model running time:  9.71878433227539
-------------------------------
-------------------------------
model running time:  26.177568435668945
-------------------------------
Vision time :  85.5889892578125
Action time :  109.77279663085938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.993375778198242
-------------------------------
-------------------------------
model running time:  7.872543811798096
-------------------------------
-------------------------------
model running time:  26.182655334472656
-------------------------------
-------------------------------
model running time:  9.736191749572754
-------------------------------
-------------------------------
model running time:  26.187776565551758
-------------------------------
Vision time :  85.6852798461914
Action time :  108.86540985107422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.677248001098633
-------------------------------
-------------------------------
model running time:  7.906303882598877
-------------------------------
-------------------------------
model running time:  26.22265625
-------------------------------
-------------------------------
model running time:  9.70035171508789
-------------------------------
-------------------------------
model running time:  26.09766387939453
-------------------------------
Vision time :  85.72345733642578
Action time :  102.64166259765625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.885120391845703
-------------------------------
-------------------------------
model running time:  7.9185919761657715
-------------------------------
-------------------------------
model running time:  26.459135055541992
-------------------------------
-------------------------------
model running time:  9.710592269897461
-------------------------------
-------------------------------
model running time:  26.30860710144043
-------------------------------
Vision time :  85.73104095458984
Action time :  105.51808166503906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.70604705810547
-------------------------------
-------------------------------
model running time:  7.883840084075928
-------------------------------
-------------------------------
model running time:  26.43459129333496
-------------------------------
-------------------------------
model running time:  9.694208145141602
-------------------------------
-------------------------------
model running time:  26.29324722290039
-------------------------------
Vision time :  

 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:51<02:23,  7.97s/it][A[A85.72166442871094
Action time :  103.05741119384766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.69580841064453
-------------------------------
-------------------------------
model running time:  8.115039825439453
-------------------------------
-------------------------------
model running time:  26.32383918762207
-------------------------------
-------------------------------
model running time:  9.759743690490723
-------------------------------
-------------------------------
model running time:  26.265600204467773
-------------------------------
Vision time :  85.7056655883789
Action time :  102.99286651611328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.62006378173828
-------------------------------
-------------------------------
model running time:  7.886847972869873
-------------------------------
-------------------------------
model running time:  26.30143928527832
-------------------------------
-------------------------------
model running time:  9.712639808654785
-------------------------------
-------------------------------
model running time:  26.183679580688477
-------------------------------
Vision time :  85.67804718017578
Action time :  102.687744140625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.595455169677734
-------------------------------
-------------------------------
model running time:  7.90937614440918
-------------------------------
-------------------------------
model running time:  30.925823211669922
-------------------------------
-------------------------------
model running time:  9.744383811950684
-------------------------------
-------------------------------
model running time:  26.15500831604004
-------------------------------
Vision time :  85.69206237792969
Action time :  107.35308837890625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.6844482421875
-------------------------------
-------------------------------
model running time:  7.917568206787109
-------------------------------
-------------------------------
model running time:  26.356735229492188
-------------------------------
-------------------------------
model running time:  9.738080024719238
-------------------------------
-------------------------------
model running time:  26.17945671081543
-------------------------------
Vision time :  85.70902252197266
Action time :  102.99603271484375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.625152587890625
-------------------------------
-------------------------------
model running time:  7.910399913787842
-------------------------------
-------------------------------
model running time:  26.283008575439453
-------------------------------
-------------------------------
model running time:  9.70751953125
-------------------------------
-------------------------------
model running time:  26.154943466186523
-------------------------------
Vision time :  85.72621154785156
Action time :  102.88025665283203
Trial 7 finished, success: tensor([True]), steps: 367
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.773632049560547
-------------------------------
-------------------------------
model running time:  7.9339518547058105
-------------------------------
-------------------------------
model running time:  26.53705596923828
-------------------------------
-------------------------------
model running time:  14.434176445007324
-------------------------------
-------------------------------
model running time:  26.542240142822266
-------------------------------
Vision time :  85.6984634399414
Action time :  108.261474609375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.60691261291504
-------------------------------
-------------------------------
model running time:  7.91648006439209
-------------------------------
-------------------------------
model running time:  26.70796775817871
-------------------------------
-------------------------------
model running time:  9.740320205688477
-------------------------------
-------------------------------
model running time:  26.372095108032227
-------------------------------
Vision time :  85.74845123291016
Action time :  108.40473937988281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.65996742248535
-------------------------------
-------------------------------
model running time:  7.911424160003662
-------------------------------
-------------------------------
model running time:  26.429439544677734
-------------------------------
-------------------------------
model running time:  9.71555233001709
-------------------------------
-------------------------------
model running time:  26.402816772460938
-------------------------------
Vision time :  85.72994995117188
Action time :  103.17603302001953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.71468734741211
-------------------------------
-------------------------------
model running time:  8.102911949157715
-------------------------------
-------------------------------
model running time:  32.66873550415039
-------------------------------
-------------------------------
model running time:  9.710592269897461
-------------------------------
-------------------------------
model running time:  26.191776275634766
-------------------------------
Vision time :  85.73836517333984
Action time :  110.38412475585938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.386560440063477
-------------------------------
-------------------------------
model running time:  7.903103828430176
-------------------------------
-------------------------------
model running time:  26.260480880737305
-------------------------------
-------------------------------
model running time:  16.337919235229492
-------------------------------
-------------------------------
model running time:  26.179584503173828
-------------------------------
Vision time :  85.7833251953125
Action time :  109.10918426513672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.69990348815918
-------------------------------
-------------------------------
model running time:  7.8592000007629395
-------------------------------
-------------------------------
model running time:  26.14067268371582
-------------------------------
-------------------------------
model running time:  9.691136360168457
-------------------------------
-------------------------------
model running time:  34.38393783569336
-------------------------------
Vision time :  85.71647644042969
Action time :  110.85196685791016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.93132781982422
-------------------------------
-------------------------------
model running time:  7.984255790710449
-------------------------------
-------------------------------
model running time:  26.76838493347168
-------------------------------
-------------------------------
model running time:  9.7608642578125
-------------------------------
-------------------------------
model running time:  28.949504852294922
-------------------------------
Vision time :  85.77056121826172
Action time :  106.78272247314453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.626176834106445
-------------------------------
-------------------------------
model running time:  7.890944004058838
-------------------------------
-------------------------------
model running time:  27.077632904052734
-------------------------------
-------------------------------
model running time:  9.734016418457031
-------------------------------
-------------------------------
model running time:  26.295167922973633
-------------------------------
Vision time :  85.72589111328125
Action time :  103.76908874511719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.430591583251953
-------------------------------
-------------------------------
model running time:  7.895936012268066
-------------------------------
-------------------------------
model running time:  26.36185646057129
-------------------------------
-------------------------------
model running time:  9.719807624816895
-------------------------------
-------------------------------
model running time:  26.149887084960938
-------------------------------
Vision time :  85.7175064086914
Action time :  102.61913299560547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.548351287841797
-------------------------------
-------------------------------
model running time:  7.855167865753174
-------------------------------
-------------------------------
model running time:  26.119136810302734
-------------------------------
-------------------------------
model running time:  9.647104263305664
-------------------------------
-------------------------------
model running time:  28.4006404876709
-------------------------------
Vision time :  85.72438049316406
Action time :  104.57103729248047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.451072692871094
-------------------------------
-------------------------------
model running time:  7.8438401222229
-------------------------------
-------------------------------
model running time:  26.044416427612305
-------------------------------
-------------------------------
model running time:  9.667584419250488
-------------------------------
-------------------------------
model running time:  26.072128295898438
-------------------------------
Vision time :  85.75059509277344
Action time :  101.98210906982422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.443904876708984
-------------------------------
-------------------------------
model running time:  7.837696075439453
-------------------------------
-------------------------------
model running time:  26.094688415527344
-------------------------------
-------------------------------
model running time:  9.644031524658203
-------------------------------
-------------------------------
model running time:  25.997312545776367
-------------------------------
Vision time :  85.7279052734375
Action time :  101.92998504638672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.45417594909668
-------------------------------
-------------------------------
model running time:  7.832575798034668
-------------------------------
-------------------------------
model running time:  26.075136184692383
-------------------------------
-------------------------------
model running time:  9.670656204223633
-------------------------------
-------------------------------
model running time:  38.258689880371094
-------------------------------
Vision time :  85.74425506591797
Action time :  114.4053726196289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.630239486694336
-------------------------------
-------------------------------
model running time:  7.839680194854736
-------------------------------
-------------------------------
model running time:  26.167327880859375
-------------------------------
-------------------------------
model running time:  9.686016082763672
-------------------------------
-------------------------------
model running time:  26.022911071777344
-------------------------------
Vision time :  85.72614288330078
Action time :  102.3815689086914
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.389728546142578
-------------------------------
-------------------------------
model running time:  7.835648059844971
-------------------------------
-------------------------------
model running time:  26.13043212890625
-------------------------------
-------------------------------
model running time:  9.703424453735352
-------------------------------
-------------------------------
model running time:  36.03353500366211
-------------------------------
Vision time :  85.71347045898438
Action time :  112.09113311767578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.719423294067383
-------------------------------
-------------------------------
model running time:  7.872511863708496
-------------------------------
-------------------------------
model running time:  26.168256759643555
-------------------------------
-------------------------------
model running time:  9.62559986114502
-------------------------------
-------------------------------
model running time:  25.989120483398438
-------------------------------
Vision time :  85.72054290771484
Action time :  102.63756561279297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.33024024963379
-------------------------------
-------------------------------
model running time:  7.871647834777832
-------------------------------
-------------------------------
model running time:  35.48169708251953
-------------------------------
-------------------------------
model running time:  9.688128471374512
-------------------------------
-------------------------------
model running time:  25.93984031677246
-------------------------------
Vision time :  85.75132751464844
Action time :  111.16441345214844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.167423248291016
-------------------------------
-------------------------------
model running time:  7.827455997467041
-------------------------------
-------------------------------
model running time:  25.865215301513672
-------------------------------
-------------------------------
model running time:  9.610143661499023
-------------------------------
-------------------------------
model running time:  25.88262367248535
-------------------------------
Vision time :  85.70909118652344
Action time :  100.91417694091797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.930879592895508
-------------------------------
-------------------------------
model running time:  7.797760009765625
-------------------------------
-------------------------------
model running time:  25.814016342163086
-------------------------------
-------------------------------
model running time:  9.608063697814941
-------------------------------
-------------------------------
model running time:  27.618303298950195
-------------------------------
Vision time :  85.70934295654297
Action time :  102.30271911621094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:59<02:20,  8.25s/it][A[Aimg_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.54528045654297
-------------------------------
-------------------------------
model running time:  7.879839897155762
-------------------------------
-------------------------------
model running time:  26.062944412231445
-------------------------------
-------------------------------
model running time:  9.658368110656738
-------------------------------
-------------------------------
model running time:  26.063871383666992
-------------------------------
Vision time :  85.72659301757812
Action time :  102.10816192626953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.579072952270508
-------------------------------
-------------------------------
model running time:  7.9185919761657715
-------------------------------
-------------------------------
model running time:  26.457056045532227
-------------------------------
-------------------------------
model running time:  9.73737621307373
-------------------------------
-------------------------------
model running time:  26.38528060913086
-------------------------------
Vision time :  85.73273468017578
Action time :  102.97241973876953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.439680099487305
-------------------------------
-------------------------------
model running time:  7.820288181304932
-------------------------------
-------------------------------
model running time:  26.772480010986328
-------------------------------
-------------------------------
model running time:  9.795583724975586
-------------------------------
-------------------------------
model running time:  26.39244842529297
-------------------------------
Vision time :  85.69811248779297
Action time :  103.05535888671875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.161279678344727
-------------------------------
-------------------------------
model running time:  7.8397440910339355
-------------------------------
-------------------------------
model running time:  26.31679916381836
-------------------------------
-------------------------------
model running time:  9.703424453735352
-------------------------------
-------------------------------
model running time:  26.31158447265625
-------------------------------
Vision time :  85.69760131835938
Action time :  102.0917739868164
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.341407775878906
-------------------------------
-------------------------------
model running time:  7.83673620223999
-------------------------------
-------------------------------
model running time:  26.36083221435547
-------------------------------
-------------------------------
model running time:  9.737215995788574
-------------------------------
-------------------------------
model running time:  26.29529571533203
-------------------------------
Vision time :  85.68911743164062
Action time :  102.2892837524414
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.27903938293457
-------------------------------
-------------------------------
model running time:  7.8438401222229
-------------------------------
-------------------------------
model running time:  26.312768936157227
-------------------------------
-------------------------------
model running time:  9.711487770080566
-------------------------------
-------------------------------
model running time:  26.389503479003906
-------------------------------
Vision time :  85.71318054199219
Action time :  102.28018951416016
Trial 8 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.873023986816406
-------------------------------
-------------------------------
model running time:  7.8961920738220215
-------------------------------
-------------------------------
model running time:  34.62758255004883
-------------------------------
-------------------------------
model running time:  9.729023933410645
-------------------------------
-------------------------------
model running time:  26.419200897216797
-------------------------------
Vision time :  85.69481658935547
Action time :  111.66310119628906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.49510383605957
-------------------------------
-------------------------------
model running time:  7.840864181518555
-------------------------------
-------------------------------
model running time:  26.56972885131836
-------------------------------
-------------------------------
model running time:  9.770112037658691
-------------------------------
-------------------------------
model running time:  26.167360305786133
-------------------------------
Vision time :  85.74454498291016
Action time :  102.75122833251953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.248319625854492
-------------------------------
-------------------------------
model running time:  7.762944221496582
-------------------------------
-------------------------------
model running time:  26.260448455810547
-------------------------------
-------------------------------
model running time:  9.652223587036133
-------------------------------
-------------------------------
model running time:  26.792959213256836
-------------------------------
Vision time :  85.72067260742188
Action time :  102.62528228759766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.374271392822266
-------------------------------
-------------------------------
model running time:  7.781375885009766
-------------------------------
-------------------------------
model running time:  26.13363265991211
-------------------------------
-------------------------------
model running time:  9.640959739685059
-------------------------------
-------------------------------
model running time:  26.320959091186523
-------------------------------
Vision time :  85.70845031738281
Action time :  101.99654388427734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.335359573364258
-------------------------------
-------------------------------
model running time:  7.819263935089111
-------------------------------
-------------------------------
model running time:  26.260480880737305
-------------------------------
-------------------------------
model running time:  9.714688301086426
-------------------------------
-------------------------------
model running time:  26.052608489990234
-------------------------------
Vision time :  85.71903991699219
Action time :  102.16448211669922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.210432052612305
-------------------------------
-------------------------------
model running time:  7.761919975280762
-------------------------------
-------------------------------
model running time:  26.193920135498047
-------------------------------
-------------------------------
model running time:  9.653247833251953
-------------------------------
-------------------------------
model running time:  26.014720916748047
-------------------------------
Vision time :  85.73212432861328
Action time :  101.6371841430664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.289247512817383
-------------------------------
-------------------------------
model running time:  7.8151679039001465
-------------------------------
-------------------------------
model running time:  26.414079666137695
-------------------------------
-------------------------------
model running time:  9.7259521484375
-------------------------------
-------------------------------
model running time:  26.346336364746094
-------------------------------
Vision time :  85.68131256103516
Action time :  102.32422637939453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.731647491455078
-------------------------------
-------------------------------
model running time:  7.8919677734375
-------------------------------
-------------------------------
model running time:  26.411008834838867
-------------------------------
-------------------------------
model running time:  9.713664054870605
-------------------------------
-------------------------------
model running time:  26.2040958404541
-------------------------------
Vision time :  85.68755340576172
Action time :  102.8884506225586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.351743698120117
-------------------------------
-------------------------------
model running time:  7.790592193603516
-------------------------------
-------------------------------
model running time:  26.34342384338379
-------------------------------
-------------------------------
model running time:  9.661439895629883
-------------------------------
-------------------------------
model running time:  26.186752319335938
-------------------------------
Vision time :  85.7209243774414
Action time :  102.04978942871094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.478687286376953
-------------------------------
-------------------------------
model running time:  7.822336196899414
-------------------------------
-------------------------------
model running time:  26.247167587280273
-------------------------------
-------------------------------
model running time:  9.668671607971191
-------------------------------
-------------------------------
model running time:  26.120128631591797
-------------------------------
Vision time :  85.69554901123047
Action time :  102.0426254272461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.10393524169922
-------------------------------
-------------------------------
model running time:  7.821311950683594
-------------------------------
-------------------------------
model running time:  26.179584503173828
-------------------------------
-------------------------------
model running time:  9.662464141845703
-------------------------------
-------------------------------
model running time:  26.066944122314453
-------------------------------
Vision time :  85.70006561279297
Action time :  101.56028747558594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.051712036132812
-------------------------------
-------------------------------
model running time:  7.834527969360352
-------------------------------
-------------------------------
model running time:  26.17241668701172
-------------------------------
-------------------------------
model running time:  9.750399589538574
-------------------------------
-------------------------------
model running time:  26.195104598999023
-------------------------------
Vision time :  85.68614196777344
Action time :  101.57158660888672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.335359573364258
-------------------------------
-------------------------------
model running time:  7.828479766845703
-------------------------------
-------------------------------
model running time:  26.370176315307617
-------------------------------
-------------------------------
model running time:  9.71571159362793
-------------------------------
-------------------------------
model running time:  26.1529598236084
-------------------------------
Vision time :  85.67123413085938
Action time :  102.26790618896484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.6507511138916
-------------------------------
-------------------------------
model running time:  7.8448638916015625
-------------------------------
-------------------------------
model running time:  26.12531280517578
-------------------------------
-------------------------------
model running time:  9.644031524658203
-------------------------------
-------------------------------
model running time:  25.914464950561523
-------------------------------
Vision time :  85.7168960571289
Action time :  101.99756622314453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.365055084228516
-------------------------------
-------------------------------
model running time:  7.881760120391846
-------------------------------
-------------------------------
model running time:  26.15500831604004
-------------------------------
-------------------------------
model running time:  9.662431716918945
-------------------------------
-------------------------------
model running time:  26.044416427612305
-------------------------------
Vision time :  85.6951675415039
Action time :  102.00486755371094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.292415618896484
-------------------------------
-------------------------------
model running time:  7.877632141113281
-------------------------------
-------------------------------
model running time:  26.067968368530273
-------------------------------
-------------------------------
model running time:  9.682944297790527
-------------------------------
-------------------------------
model running time:  25.89593505859375
-------------------------------
Vision time :  85.69789123535156
Action time :  101.60537719726562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.11212730407715
-------------------------------
-------------------------------
model running time:  7.809023857116699
-------------------------------
-------------------------------
model running time:  25.960447311401367
-------------------------------
-------------------------------
model running time:  9.642080307006836
-------------------------------
-------------------------------
model running time:  25.879552841186523
-------------------------------
Vision time :  85.74400329589844
Action time :  101.11711883544922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.885663986206055
-------------------------------
-------------------------------
model running time:  7.818240165710449
-------------------------------
-------------------------------
model running time:  25.96454429626465
-------------------------------
-------------------------------
model running time:  9.657183647155762
-------------------------------
-------------------------------
model running time:  25.854976654052734
-------------------------------
Vision time :  85.7059555053711
Action time :  100.76876831054688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.764480590820312
-------------------------------
-------------------------------
model running time:  

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [01:08<02:15,  8.45s/it][A[A7.831552028656006
-------------------------------
-------------------------------
model running time:  26.18060874938965
-------------------------------
-------------------------------
model running time:  9.696255683898926
-------------------------------
-------------------------------
model running time:  25.979904174804688
-------------------------------
Vision time :  85.71068572998047
Action time :  102.55769348144531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.233983993530273
-------------------------------
-------------------------------
model running time:  7.840767860412598
-------------------------------
-------------------------------
model running time:  26.17046356201172
-------------------------------
-------------------------------
model running time:  9.689087867736816
-------------------------------
-------------------------------
model running time:  26.007423400878906
-------------------------------
Vision time :  85.72281646728516
Action time :  101.63906860351562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.197120666503906
-------------------------------
-------------------------------
model running time:  7.868256092071533
-------------------------------
-------------------------------
model running time:  26.29427146911621
-------------------------------
-------------------------------
model running time:  9.71571159362793
-------------------------------
-------------------------------
model running time:  26.17241668701172
-------------------------------
Vision time :  85.74966430664062
Action time :  102.02515411376953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.118240356445312
-------------------------------
-------------------------------
model running time:  7.829376220703125
-------------------------------
-------------------------------
model running time:  25.976703643798828
-------------------------------
-------------------------------
model running time:  9.679871559143066
-------------------------------
-------------------------------
model running time:  25.827327728271484
-------------------------------
Vision time :  85.70745849609375
Action time :  101.283935546875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.837696075439453
-------------------------------
-------------------------------
model running time:  7.772160053253174
-------------------------------
-------------------------------
model running time:  25.764863967895508
-------------------------------
-------------------------------
model running time:  9.628671646118164
-------------------------------
-------------------------------
model running time:  25.658367156982422
-------------------------------
Vision time :  85.69996643066406
Action time :  100.3141098022461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.424448013305664
-------------------------------
-------------------------------
model running time:  7.837696075439453
-------------------------------
-------------------------------
model running time:  26.3055362701416
-------------------------------
-------------------------------
model running time:  9.7391357421875
-------------------------------
-------------------------------
model running time:  26.14374351501465
-------------------------------
Vision time :  85.73312377929688
Action time :  102.2086410522461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.592384338378906
-------------------------------
-------------------------------
model running time:  7.875455856323242
-------------------------------
-------------------------------
model running time:  26.674175262451172
-------------------------------
-------------------------------
model running time:  9.764863967895508
-------------------------------
-------------------------------
model running time:  26.195968627929688
-------------------------------
Vision time :  85.72259521484375
Action time :  103.0830078125
Trial 9 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.447040557861328
-------------------------------
-------------------------------
model running time:  7.884799957275391
-------------------------------
-------------------------------
model running time:  26.347455978393555
-------------------------------
-------------------------------
model running time:  9.777183532714844
-------------------------------
-------------------------------
model running time:  26.34124755859375
-------------------------------
Vision time :  85.72953796386719
Action time :  102.77375793457031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.406015396118164
-------------------------------
-------------------------------
model running time:  7.858047962188721
-------------------------------


 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [01:10<01:37,  6.48s/it][A[A-------------------------------
model running time:  26.464256286621094
-------------------------------
-------------------------------
model running time:  9.838591575622559
-------------------------------
-------------------------------
model running time:  29.447168350219727
-------------------------------
Vision time :  85.73612976074219
Action time :  106.0146255493164
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.639551162719727
-------------------------------
-------------------------------
model running time:  7.845888137817383
-------------------------------
-------------------------------
model running time:  26.433536529541016
-------------------------------
-------------------------------
model running time:  9.70854377746582
-------------------------------
-------------------------------
model running time:  26.278911590576172
-------------------------------
Vision time :  85.76850891113281
Action time :  110.03801727294922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.835071563720703
-------------------------------
-------------------------------
model running time:  7.877632141113281
-------------------------------
-------------------------------
model running time:  26.555360794067383
-------------------------------
-------------------------------
model running time:  9.843711853027344
-------------------------------
-------------------------------
model running time:  26.5216007232666
-------------------------------
Vision time :  85.7252197265625
Action time :  103.68204498291016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.76652717590332
-------------------------------
-------------------------------
model running time:  7.896063804626465
-------------------------------
-------------------------------
model running time:  26.55846405029297
-------------------------------
-------------------------------
model running time:  9.750528335571289
-------------------------------
-------------------------------
model running time:  26.402816772460938
-------------------------------
Vision time :  85.7204818725586
Action time :  103.43936157226562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.630271911621094
-------------------------------
-------------------------------
model running time:  7.894015789031982
-------------------------------
-------------------------------
model running time:  26.35366439819336
-------------------------------
-------------------------------
model running time:  9.758720397949219
-------------------------------
-------------------------------
model running time:  26.352767944335938
-------------------------------
Vision time :  85.73430633544922
Action time :  102.95398712158203
Trial 10 finished, success: tensor([True]), steps: 85
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.410112380981445
-------------------------------
-------------------------------
model running time:  7.865312099456787
-------------------------------
-------------------------------
model running time:  26.37926483154297
-------------------------------
-------------------------------
model running time:  9.71571159362793
-------------------------------
-------------------------------
model running time:  26.5512638092041
-------------------------------
Vision time :  85.73324584960938
Action time :  102.69388580322266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.369152069091797
-------------------------------
-------------------------------
model running time:  7.865344047546387
-------------------------------
-------------------------------
model running time:  26.571775436401367
-------------------------------
-------------------------------
model running time:  9.71571159362793
-------------------------------
-------------------------------
model running time:  26.434560775756836
-------------------------------
Vision time :  85.74185943603516
Action time :  102.64575958251953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.599552154541016
-------------------------------
-------------------------------
model running time:  7.860223770141602
-------------------------------
-------------------------------
model running time:  26.29529571533203
-------------------------------
-------------------------------
model running time:  9.749504089355469
-------------------------------
-------------------------------
model running time:  26.233856201171875
-------------------------------
Vision time :  85.74419403076172
Action time :  102.76249694824219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.69580841064453
-------------------------------
-------------------------------
model running time:  7.913440227508545
-------------------------------
-------------------------------
model running time:  34.725887298583984
-------------------------------
-------------------------------
model running time:  10.012672424316406
-------------------------------
-------------------------------
model running time:  26.438720703125
-------------------------------
Vision time :  85.80182647705078
Action time :  112.0890884399414
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.51353645324707
-------------------------------
-------------------------------
model running time:  8.481792449951172
-------------------------------
-------------------------------
model running time:  26.390527725219727
-------------------------------
-------------------------------
model running time:  9.721856117248535
-------------------------------
-------------------------------
model running time:  31.534143447875977
-------------------------------
Vision time :  85.87155151367188
Action time :  108.86144256591797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.128671646118164
-------------------------------
-------------------------------
model running time:  7.830592155456543
-------------------------------
-------------------------------
model running time:  26.177536010742188
-------------------------------
-------------------------------
model running time:  9.696255683898926
-------------------------------
-------------------------------
model running time:  29.977760314941406
-------------------------------
Vision time :  85.81059265136719
Action time :  110.96781158447266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.70310401916504
-------------------------------
-------------------------------
model running time:  7.988224029541016
-------------------------------
-------------------------------
model running time:  26.250272750854492
-------------------------------
-------------------------------
model running time:  9.766912460327148
-------------------------------
-------------------------------
model running time:  29.77791976928711
-------------------------------
Vision time :  85.74400329589844
Action time :  107.21382141113281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.568864822387695
-------------------------------
-------------------------------
model running time:  7.804927825927734
-------------------------------
-------------------------------
model running time:  26.702943801879883
-------------------------------
-------------------------------
model running time:  9.702400207519531
-------------------------------
-------------------------------
model running time:  25.863168716430664
-------------------------------
Vision time :  85.78518676757812
Action time :  103.22144317626953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.13516616821289
-------------------------------
-------------------------------
model running time:  7.877632141113281
-------------------------------
-------------------------------
model running time:  26.09561538696289
-------------------------------
-------------------------------
model running time:  9.71174430847168
-------------------------------
-------------------------------
model running time:  26.14169692993164
-------------------------------
Vision time :  85.70992279052734
Action time :  109.76563262939453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.631296157836914
-------------------------------
-------------------------------
model running time:  7.87446403503418
-------------------------------
-------------------------------
model running time:  26.1079044342041
-------------------------------
-------------------------------
model running time:  9.738240242004395
-------------------------------
-------------------------------
model running time:  26.082304000854492
-------------------------------
Vision time :  85.74447631835938
Action time :  102.73280334472656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.465791702270508
-------------------------------
-------------------------------
model running time:  7.908224105834961
-------------------------------
-------------------------------
model running time:  26.37004852294922
-------------------------------
-------------------------------
model running time:  9.759743690490723
-------------------------------
-------------------------------
model running time:  26.261503219604492
-------------------------------
Vision time :  85.8430404663086
Action time :  103.91142272949219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.636415481567383
-------------------------------
-------------------------------
model running time:  8.450048446655273
-------------------------------
-------------------------------
model running time:  28.772480010986328
-------------------------------
-------------------------------
model running time:  9.739295959472656
-------------------------------
-------------------------------
model running time:  26.374143600463867
-------------------------------
Vision time :  85.8183364868164
Action time :  106.3219223022461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.230335235595703
-------------------------------
-------------------------------
model running time:  7.910399913787842
-------------------------------
-------------------------------
model running time:  31.698944091796875
-------------------------------
-------------------------------
model running time:  9.660256385803223
-------------------------------
-------------------------------
model running time:  26.11609649658203
-------------------------------
Vision time :  86.79216003417969
Action time :  108.83174133300781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.856576919555664
-------------------------------
-------------------------------
model running time:  7.90937614440918
-------------------------------
-------------------------------
model running time:  26.28505516052246
-------------------------------
-------------------------------
model running time:  9.70956802368164
-------------------------------
-------------------------------
model running time:  26.194944381713867
-------------------------------
Vision time :  85.7248306274414
Action time :  103.0297622680664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.826879501342773
-------------------------------
-------------------------------
model running time:  7.910560131072998
-------------------------------
-------------------------------
model running time:  26.392576217651367
-------------------------------
-------------------------------
model running time:  9.705471992492676
-------------------------------
-------------------------------
model running time:  26.611711502075195
-------------------------------
Vision time :  85.74761962890625
Action time :  103.5499496459961
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.69887924194336
-------------------------------
-------------------------------
model running time:  7.857151985168457
-------------------------------
-------------------------------
model running time:  26.413055419921875
-------------------------------
-------------------------------
model running time:  9.81503963470459
-------------------------------
-------------------------------
model running time:  31.677440643310547
-------------------------------
Vision time :  85.7586898803711
Action time :  108.43222045898438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.620031356811523
-------------------------------
-------------------------------
model running time:  7.889920234680176
-------------------------------
-------------------------------
model running time:  34.583553314208984
-------------------------------
-------------------------------
model running time:  10.496000289916992
-------------------------------
-------------------------------
model running time:  26.261503219604492
-------------------------------
Vision time :  85.73782348632812
Action time :  111.92524719238281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.072383880615234
-------------------------------
-------------------------------
model running time:  7.862368106842041
-------------------------------
-------------------------------
model running time:  26.443775177001953
-------------------------------
-------------------------------
model running time:  9.71776008605957
-------------------------------
-------------------------------
model running time:  26.12735939025879
-------------------------------
Vision time :  85.73149108886719
Action time :  106.99472045898438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.13759994506836
-------------------------------
-------------------------------
model running time:  7.999551773071289
-------------------------------
-------------------------------
model running time:  26.6812801361084
-------------------------------
-------------------------------
model running time:  9.692159652709961
-------------------------------
-------------------------------
model running time:  26.32703971862793
-------------------------------
Vision time :  85.75174713134766
Action time :  104.93746948242188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.000991821289062
-------------------------------
-------------------------------
model running time:  7.952383995056152
-------------------------------
-------------------------------
model running time:  26.394655227661133
-------------------------------
-------------------------------
model running time:  9.73311996459961
-------------------------------
-------------------------------
model running time:  26.291200637817383
-------------------------------
Vision time :  85.88861083984375
Action time :  

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [01:19<01:41,  7.26s/it][A[A110.8479995727539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.1013126373291
-------------------------------
-------------------------------
model running time:  7.915359973907471
-------------------------------
-------------------------------
model running time:  26.50511932373047
-------------------------------
-------------------------------
model running time:  9.71452808380127
-------------------------------
-------------------------------
model running time:  26.238975524902344
-------------------------------
Vision time :  85.76051330566406
Action time :  103.65424346923828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.18022537231445
-------------------------------
-------------------------------
model running time:  7.952383995056152
-------------------------------
-------------------------------
model running time:  26.438655853271484
-------------------------------
-------------------------------
model running time:  9.714688301086426
-------------------------------
-------------------------------
model running time:  26.298208236694336
-------------------------------
Vision time :  85.73820495605469
Action time :  110.5970230102539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.69820785522461
-------------------------------
-------------------------------
model running time:  7.955327987670898
-------------------------------
-------------------------------
model running time:  31.517696380615234
-------------------------------
-------------------------------
model running time:  9.819135665893555
-------------------------------
-------------------------------
model running time:  26.51955223083496
-------------------------------
Vision time :  85.75769805908203
Action time :  109.81478118896484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.961023330688477
-------------------------------
-------------------------------
model running time:  7.9626240730285645
-------------------------------
-------------------------------
model running time:  26.92300796508789
-------------------------------
-------------------------------
model running time:  9.742176055908203
-------------------------------
-------------------------------
model running time:  26.044416427612305
-------------------------------
Vision time :  85.89299011230469
Action time :  103.73734283447266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.013248443603516
-------------------------------
-------------------------------
model running time:  7.939072132110596
-------------------------------
-------------------------------
model running time:  26.620927810668945
-------------------------------
-------------------------------
model running time:  9.846783638000488
-------------------------------
-------------------------------
model running time:  26.457088470458984
-------------------------------
Vision time :  85.75532531738281
Action time :  104.07014465332031
Trial 11 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.87500762939453
-------------------------------
-------------------------------
model running time:  7.957503795623779
-------------------------------
-------------------------------
model running time:  26.596351623535156
-------------------------------
-------------------------------
model running time:  9.80684757232666
-------------------------------
-------------------------------
model running time:  26.69055938720703
-------------------------------
Vision time :  85.73161315917969
Action time :  103.91741180419922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.465408325195312
-------------------------------
-------------------------------
model running time:  7.884799957275391
-------------------------------
-------------------------------
model running time:  26.358783721923828
-------------------------------
-------------------------------
model running time:  9.71776008605957
-------------------------------
-------------------------------
model running time:  28.56243133544922
-------------------------------
Vision time :  85.76806640625
Action time :  104.89250946044922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.329248428344727
-------------------------------
-------------------------------
model running time:  7.8438401222229
-------------------------------
-------------------------------
model running time:  26.0710391998291
-------------------------------
-------------------------------
model running time:  9.676799774169922
-------------------------------
-------------------------------
model running time:  25.9051513671875
-------------------------------
Vision time :  85.75161743164062
Action time :  101.59001922607422
before pruning: 


 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [01:22<01:13,  5.68s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.516704559326172
-------------------------------
-------------------------------
model running time:  14.083200454711914
-------------------------------
-------------------------------
model running time:  26.12633514404297
-------------------------------
-------------------------------
model running time:  9.612288475036621
-------------------------------
-------------------------------
model running time:  25.978879928588867
-------------------------------
Vision time :  85.75910186767578
Action time :  108.23577880859375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.352767944335938
-------------------------------
-------------------------------
model running time:  7.937024116516113
-------------------------------
-------------------------------
model running time:  26.195968627929688
-------------------------------
-------------------------------
model running time:  9.70751953125
-------------------------------
-------------------------------
model running time:  32.552799224853516
-------------------------------
Vision time :  85.75078582763672
Action time :  108.74687957763672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.566783905029297
-------------------------------
-------------------------------
model running time:  7.822336196899414
-------------------------------
-------------------------------
model running time:  26.192895889282227
-------------------------------
-------------------------------
model running time:  9.711647987365723
-------------------------------
-------------------------------
model running time:  28.463071823120117
-------------------------------
Vision time :  85.75638580322266
Action time :  104.75830078125
Trial 12 finished, success: tensor([True]), steps: 82
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.27084732055664
-------------------------------
-------------------------------
model running time:  7.803904056549072
-------------------------------
-------------------------------
model running time:  32.69513702392578
-------------------------------
-------------------------------
model running time:  9.756671905517578
-------------------------------
-------------------------------
model running time:  25.867263793945312
-------------------------------
Vision time :  85.75174713134766
Action time :  108.27273559570312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.31692886352539
-------------------------------
-------------------------------
model running time:  8.008607864379883
-------------------------------
-------------------------------
model running time:  26.182655334472656
-------------------------------
-------------------------------
model running time:  12.77132797241211
-------------------------------
-------------------------------
model running time:  25.91935920715332
-------------------------------
Vision time :  85.76573181152344
Action time :  105.01427459716797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.130720138549805
-------------------------------
-------------------------------
model running time:  7.825407981872559
-------------------------------
-------------------------------
model running time:  25.91744041442871
-------------------------------
-------------------------------
model running time:  9.662464141845703
-------------------------------
-------------------------------
model running time:  26.013824462890625
-------------------------------
Vision time :  85.7547836303711
Action time :  101.30738830566406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.844287872314453
-------------------------------
-------------------------------
model running time:  13.110272407531738
-------------------------------
-------------------------------
model running time:  26.159135818481445
-------------------------------
-------------------------------
model running time:  9.680895805358887
-------------------------------
-------------------------------
model running time:  25.967552185058594
-------------------------------
Vision time :  85.78166198730469
Action time :  107.55583953857422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.364032745361328
-------------------------------
-------------------------------
model running time:  7.805952072143555
-------------------------------
-------------------------------
model running time:  29.800575256347656
-------------------------------
-------------------------------
model running time:  11.497471809387207
-------------------------------
-------------------------------
model running time:  25.967615127563477
-------------------------------
Vision time :  85.77686309814453
Action time :  107.44217681884766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.761791229248047
-------------------------------
-------------------------------
model running time:  7.873536109924316
-------------------------------
-------------------------------
model running time:  26.134592056274414
-------------------------------
-------------------------------
model running time:  9.721983909606934
-------------------------------
-------------------------------
model running time:  27.48099136352539
-------------------------------
Vision time :  85.86454772949219
Action time :  105.85606384277344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.664064407348633
-------------------------------
-------------------------------
model running time:  7.86732816696167
-------------------------------
-------------------------------
model running time:  26.152063369750977
-------------------------------
-------------------------------
model running time:  9.637887954711914
-------------------------------
-------------------------------
model running time:  25.72287940979004
-------------------------------
Vision time :  85.787841796875
Action time :  102.7225570678711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.624128341674805
-------------------------------
-------------------------------
model running time:  8.208383560180664
-------------------------------
-------------------------------
model running time:  26.024959564208984
-------------------------------
-------------------------------
model running time:  9.659392356872559
-------------------------------
-------------------------------
model running time:  25.82431983947754
-------------------------------
Vision time :  85.7844467163086
Action time :  104.52262115478516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.403968811035156
-------------------------------
-------------------------------
model running time:  7.865503787994385
-------------------------------
-------------------------------
model running time:  30.428159713745117
-------------------------------
-------------------------------
model running time:  9.621503829956055
-------------------------------
-------------------------------
model running time:  25.85919952392578
-------------------------------
Vision time :  85.77001953125
Action time :  106.14460754394531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.031679153442383
-------------------------------
-------------------------------
model running time:  7.85100793838501
-------------------------------
-------------------------------
model running time:  25.92665672302246
-------------------------------
-------------------------------
model running time:  9.626720428466797
-------------------------------
-------------------------------
model running time:  30.772127151489258
-------------------------------
Vision time :  85.74038696289062
Action time :  107.07762908935547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.389728546142578
-------------------------------
-------------------------------
model running time:  7.899136066436768
-------------------------------
-------------------------------
model running time:  26.109952926635742
-------------------------------
-------------------------------
model running time:  9.673791885375977
-------------------------------
-------------------------------
model running time:  26.285152435302734
-------------------------------
Vision time :  85.74729919433594
Action time :  104.31385803222656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.627296447753906
-------------------------------
-------------------------------
model running time:  7.8592000007629395
-------------------------------
-------------------------------
model running time:  26.060800552368164
-------------------------------
-------------------------------
model running time:  9.644031524658203
-------------------------------
-------------------------------
model running time:  25.944063186645508
-------------------------------
Vision time :  85.71395111083984
Action time :  102.0057601928711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.293439865112305
-------------------------------
-------------------------------
model running time:  7.861343860626221
-------------------------------
-------------------------------
model running time:  26.183679580688477
-------------------------------
-------------------------------
model running time:  9.669631958007812
-------------------------------
-------------------------------
model running time:  32.41471862792969
-------------------------------
Vision time :  85.73023986816406
Action time :  108.09651184082031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.359935760498047
-------------------------------
-------------------------------
model running time:  7.845888137817383
-------------------------------
-------------------------------
model running time:  25.91436767578125
-------------------------------
-------------------------------
model running time:  11.94803237915039
-------------------------------
-------------------------------
model running time:  25.879711151123047
-------------------------------
Vision time :  85.73897552490234
Action time :  103.80902099609375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.353792190551758
-------------------------------
-------------------------------
model running time:  7.891104221343994
-------------------------------
-------------------------------
model running time:  25.993215560913086
-------------------------------
-------------------------------
model running time:  9.688063621520996
-------------------------------
-------------------------------
model running time:  26.052608489990234
-------------------------------
Vision time :  85.76118469238281
Action time :  105.45356750488281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.66713523864746
-------------------------------
-------------------------------
model running time:  7.928832054138184
-------------------------------
-------------------------------
model running time:  28.3371524810791
-------------------------------
-------------------------------
model running time:  9.707488059997559
-------------------------------
-------------------------------
model running time:  26.028032302856445
-------------------------------
Vision time :  85.77494049072266
Action time :  104.62726593017578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.164928436279297
-------------------------------
-------------------------------
model running time:  7.8397440910339355
-------------------------------
-------------------------------
model running time:  28.627967834472656
-------------------------------
-------------------------------
model running time:  10.61683177947998
-------------------------------
-------------------------------
model running time:  26.182655334472656
-------------------------------
Vision time :  85.85424041748047
Action time :  106.62509155273438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.740863800048828
-------------------------------
-------------------------------
model running time:  7.879680156707764
-------------------------------
-------------------------------
model running time:  26.12428855895996
-------------------------------
-------------------------------
model running time:  11.678720474243164
-------------------------------
-------------------------------
model running time:  25.961471557617188
-------------------------------
Vision time :  85.75846099853516
Action time :  104.71836853027344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.773632049560547
-------------------------------
-------------------------------
model running time:  7.894015789031982
-------------------------------
-------------------------------
model running time:  26.148000717163086
-------------------------------
-------------------------------
model running time:  9.656288146972656
-------------------------------
-------------------------------
model running time:  25.935871124267578
-------------------------------
Vision time :  85.8166732788086
Action time :  102.46656036376953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.977407455444336
-------------------------------
-------------------------------
model running time:  8.753151893615723
-------------------------------
-------------------------------
model running time:  26.69158363342285
-------------------------------
-------------------------------
model running time:  9.703424453735352
-------------------------------
-------------------------------
model running time:  26.307392120361328
-------------------------------
Vision time :  85.76620483398438
Action time :  106.78169250488281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.801183700561523
-------------------------------
-------------------------------
model running time:  7.928671836853027
-------------------------------
-------------------------------
model running time:  29.037567138671875
-------------------------------
-------------------------------
model running time:  9.754624366760254
-------------------------------
-------------------------------
model running time:  26.51535987854004
-------------------------------
Vision time :  85.7570571899414
Action time :  106.12617492675781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416


 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [01:30<01:19,  6.66s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.040895462036133
-------------------------------
-------------------------------
model running time:  7.930880069732666
-------------------------------
-------------------------------
model running time:  26.629119873046875
-------------------------------
-------------------------------
model running time:  9.72697639465332
-------------------------------
-------------------------------
model running time:  26.50943946838379
-------------------------------
Vision time :  85.76473236083984
Action time :  103.95033264160156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.991743087768555
-------------------------------
-------------------------------
model running time:  7.939040184020996
-------------------------------
-------------------------------
model running time:  26.49087905883789
-------------------------------
-------------------------------
model running time:  9.929727554321289
-------------------------------
-------------------------------
model running time:  26.5164794921875
-------------------------------
Vision time :  85.7547836303711
Action time :  104.00358581542969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.965024948120117
-------------------------------
-------------------------------
model running time:  7.889887809753418
-------------------------------
-------------------------------
model running time:  26.514432907104492
-------------------------------
-------------------------------
model running time:  9.783295631408691
-------------------------------
-------------------------------
model running time:  26.327199935913086
-------------------------------
Vision time :  85.75724792480469
Action time :  105.38495635986328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.03539276123047
-------------------------------
-------------------------------
model running time:  7.897119998931885
-------------------------------
-------------------------------
model running time:  26.30348777770996
-------------------------------
-------------------------------
model running time:  9.687040328979492
-------------------------------
-------------------------------
model running time:  26.185728073120117
-------------------------------
Vision time :  85.74566650390625
Action time :  109.3437728881836
Trial 13 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.738815307617188
-------------------------------
-------------------------------
model running time:  7.941120147705078
-------------------------------
-------------------------------
model running time:  26.435583114624023
-------------------------------
-------------------------------
model running time:  9.793536186218262
-------------------------------
-------------------------------
model running time:  26.382335662841797
-------------------------------
Vision time :  85.71929931640625
Action time :  103.35852813720703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.612735748291016
-------------------------------
-------------------------------
model running time:  7.85100793838501
-------------------------------
-------------------------------
model running time:  26.422143936157227
-------------------------------
-------------------------------
model running time:  9.738240242004395
-------------------------------
-------------------------------
model running time:  26.13555145263672
-------------------------------
Vision time :  85.7376937866211
Action time :  104.74598693847656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.73971176147461
-------------------------------
-------------------------------
model running time:  7.836671829223633
-------------------------------
-------------------------------
model running time:  26.473472595214844
-------------------------------
-------------------------------
model running time:  9.798784255981445
-------------------------------
-------------------------------
model running time:  27.35513687133789
-------------------------------
Vision time :  85.74444580078125
Action time :  104.26866912841797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.838272094726562
-------------------------------
-------------------------------
model running time:  7.885824203491211
-------------------------------
-------------------------------
model running time:  26.51126480102539
-------------------------------
-------------------------------
model running time:  9.697343826293945
-------------------------------
-------------------------------
model running time:  26.217472076416016
-------------------------------
Vision time :  85.75193786621094
Action time :  103.26319885253906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.79916763305664
-------------------------------
-------------------------------
model running time:  7.923711776733398
-------------------------------
-------------------------------
model running time:  26.239999771118164
-------------------------------
-------------------------------
model running time:  9.692159652709961
-------------------------------
-------------------------------
model running time:  26.002431869506836
-------------------------------
Vision time :  85.85167694091797
Action time :  111.73587036132812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.169919967651367
-------------------------------
-------------------------------
model running time:  7.955455780029297
-------------------------------
-------------------------------
model running time:  26.720256805419922
-------------------------------
-------------------------------
model running time:  9.810943603515625
-------------------------------
-------------------------------
model running time:  26.498048782348633
-------------------------------
Vision time :  85.78214263916016
Action time :  104.64153289794922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.14022445678711
-------------------------------
-------------------------------
model running time:  7.916543960571289
-------------------------------
-------------------------------
model running time:  26.53913688659668
-------------------------------
-------------------------------
model running time:  9.834495544433594
-------------------------------
-------------------------------
model running time:  26.183679580688477
-------------------------------
Vision time :  85.77356719970703
Action time :  103.80083465576172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.802303314208984
-------------------------------
-------------------------------
model running time:  7.895040035247803
-------------------------------
-------------------------------
model running time:  26.31270408630371
-------------------------------
-------------------------------
model running time:  9.703359603881836
-------------------------------
-------------------------------
model running time:  26.14374351501465
-------------------------------
Vision time :  85.76761627197266
Action time :  102.88333129882812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.91289520263672
-------------------------------
-------------------------------
model running time:  7.968768119812012
-------------------------------
-------------------------------
model running time:  26.568832397460938
-------------------------------
-------------------------------
model running time:  9.809920310974121
-------------------------------
-------------------------------
model running time:  26.384384155273438
-------------------------------
Vision time :  85.7452163696289
Action time :  103.64313507080078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.9487361907959
-------------------------------
-------------------------------
model running time:  7.990272045135498
-------------------------------
-------------------------------
model running time:  26.792959213256836
-------------------------------
-------------------------------
model running time:  9.910271644592285
-------------------------------
-------------------------------
model running time:  26.67024040222168
-------------------------------
Vision time :  85.74588775634766
Action time :  104.23296356201172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.398752212524414
-------------------------------
-------------------------------
model running time:  7.79366397857666
-------------------------------
-------------------------------
model running time:  26.12428855895996
-------------------------------
-------------------------------
model running time:  9.703424453735352
-------------------------------
-------------------------------
model running time:  25.66655921936035
-------------------------------
Vision time :  85.75676727294922
Action time :  101.61254119873047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.193023681640625
-------------------------------
-------------------------------
model running time:  7.796735763549805
-------------------------------
-------------------------------
model running time:  34.95414352416992
-------------------------------
-------------------------------
model running time:  9.661439895629883
-------------------------------
-------------------------------
model running time:  26.766399383544922
-------------------------------
Vision time :  85.74256134033203
Action time :  111.09069061279297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.89036750793457
-------------------------------
-------------------------------
model running time:  7.804927825927734
-------------------------------
-------------------------------
model running time:  26.228736877441406
-------------------------------
-------------------------------
model running time:  9.612288475036621
-------------------------------
-------------------------------
model running time:  25.68819236755371
-------------------------------
Vision time :  85.76211547851562
Action time :  104.62207794189453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.776704788208008
-------------------------------
-------------------------------
model running time:  12.345343589782715
-------------------------------
-------------------------------
model running time:  26.042367935180664
-------------------------------
-------------------------------
model running time:  9.653247833251953
-------------------------------
-------------------------------
model running time:  25.82111930847168
-------------------------------
Vision time :  85.77056121826172
Action time :  107.34899139404297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.406047821044922
-------------------------------
-------------------------------
model running time:  7.8008317947387695
-------------------------------
-------------------------------
model running time:  26.03126335144043
-------------------------------
-------------------------------
model running time:  9.630623817443848
-------------------------------
-------------------------------
model running time:  25.788415908813477
-------------------------------
Vision time :  85.73458862304688
Action time :  101.60128021240234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.504255294799805
-------------------------------
-------------------------------
model running time:  7.8438401222229
-------------------------------
-------------------------------
model running time:  26.217472076416016
-------------------------------
-------------------------------
model running time:  9.70035171508789
-------------------------------
-------------------------------
model running time:  25.963520050048828
-------------------------------
Vision time :  85.74649810791016
Action time :  102.0087661743164
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.49203109741211
-------------------------------
-------------------------------
model running time:  7.831552028656006
-------------------------------
-------------------------------
model running time:  26.301536560058594
-------------------------------
-------------------------------
model running time:  9.72390365600586
-------------------------------
-------------------------------
model running time:  25.96454429626465
-------------------------------
Vision time :  85.74066925048828
Action time :  102.150146484375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.209407806396484
-------------------------------
-------------------------------
model running time:  7.855103969573975
-------------------------------
-------------------------------
model running time:  30.6976318359375
-------------------------------
-------------------------------
model running time:  9.687040328979492
-------------------------------
-------------------------------
model running time:  26.01158332824707
-------------------------------
Vision time :  85.7457275390625
Action time :  106.13455963134766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.44483184814453
-------------------------------
-------------------------------
model running time:  7.8448638916015625
-------------------------------
-------------------------------
model running time:  26.12224006652832
-------------------------------
-------------------------------
model running time:  9.644031524658203
-------------------------------
-------------------------------
model running time:  28.73855972290039
-------------------------------
Vision time :  85.77859497070312
Action time :  104.79206085205078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.601600646972656
-------------------------------
-------------------------------
model running time:  7.809023857116699
-------------------------------
-------------------------------
model running time:  26.103904724121094
-------------------------------
-------------------------------
model running time:  9.696255683898926
-------------------------------
-------------------------------
model running time:  25.960447311401367
-------------------------------
Vision time :  85.75116729736328
Action time :  102.17378997802734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.975360870361328
-------------------------------
-------------------------------
model running time:  7.813119888305664
-------------------------------
-------------------------------
model running time:  31.187999725341797
-------------------------------


 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [01:39<01:20,  7.33s/it][A[A-------------------------------
model running time:  13.469696044921875
-------------------------------
-------------------------------
model running time:  26.95475196838379
-------------------------------
Vision time :  85.84690856933594
Action time :  114.65216064453125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.432640075683594
-------------------------------
-------------------------------
model running time:  7.8592000007629395
-------------------------------
-------------------------------
model running time:  26.054655075073242
-------------------------------
-------------------------------
model running time:  9.660415649414062
-------------------------------
-------------------------------
model running time:  25.90822410583496
-------------------------------
Vision time :  85.80963134765625
Action time :  101.88082885742188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.382463455200195
-------------------------------
-------------------------------
model running time:  7.814144134521484
-------------------------------
-------------------------------
model running time:  33.163265228271484
-------------------------------
-------------------------------
model running time:  9.61952018737793
-------------------------------
-------------------------------
model running time:  25.678848266601562
-------------------------------
Vision time :  85.7943344116211
Action time :  108.64947509765625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.592384338378906
-------------------------------
-------------------------------
model running time:  7.842879772186279
-------------------------------
-------------------------------
model running time:  25.867263793945312
-------------------------------
-------------------------------
model running time:  9.621503829956055
-------------------------------
-------------------------------
model running time:  25.68396759033203
-------------------------------
Vision time :  85.72876739501953
Action time :  101.60128021240234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.284160614013672
-------------------------------
-------------------------------
model running time:  16.187360763549805
-------------------------------
-------------------------------
model running time:  26.192895889282227
-------------------------------
-------------------------------
model running time:  9.664511680603027
-------------------------------
-------------------------------
model running time:  25.94918441772461
-------------------------------
Vision time :  85.72438049316406
Action time :  110.24476623535156
Trial 14 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.49510383605957
-------------------------------
-------------------------------
model running time:  8.579071998596191
-------------------------------
-------------------------------
model running time:  27.092927932739258
-------------------------------
-------------------------------
model running time:  9.620479583740234
-------------------------------
-------------------------------
model running time:  26.028032302856445
-------------------------------
Vision time :  85.75334167480469
Action time :  103.89590454101562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.350528717041016
-------------------------------
-------------------------------
model running time:  7.835648059844971
-------------------------------
-------------------------------
model running time:  26.11302375793457
-------------------------------
-------------------------------
model running time:  9.648127555847168
-------------------------------
-------------------------------
model running time:  25.785375595092773
-------------------------------
Vision time :  85.7356185913086
Action time :  101.68524932861328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.46950340270996
-------------------------------
-------------------------------
model running time:  7.806975841522217
-------------------------------
-------------------------------
model running time:  29.938688278198242
-------------------------------
-------------------------------
model running time:  9.672703742980957
-------------------------------
-------------------------------
model running time:  25.989120483398438
-------------------------------
Vision time :  85.82157135009766
Action time :  105.88671875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.249248504638672
-------------------------------
-------------------------------
model running time:  8.612895965576172
-------------------------------
-------------------------------
model running time:  32.48332977294922
-------------------------------
-------------------------------
model running time:  

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [01:43<01:01,  6.11s/it][A[A9.730048179626465
-------------------------------
-------------------------------
model running time:  26.052608489990234
-------------------------------
Vision time :  85.73951721191406
Action time :  108.92082977294922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.241151809692383
-------------------------------
-------------------------------
model running time:  7.834496021270752
-------------------------------
-------------------------------
model running time:  26.263391494750977
-------------------------------
-------------------------------
model running time:  9.615519523620605
-------------------------------
-------------------------------
model running time:  25.90617561340332
-------------------------------
Vision time :  85.75542449951172
Action time :  101.66783905029297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.534015655517578
-------------------------------
-------------------------------
model running time:  7.976960182189941
-------------------------------
-------------------------------
model running time:  26.023935317993164
-------------------------------
-------------------------------
model running time:  10.43455982208252
-------------------------------
-------------------------------
model running time:  26.08025550842285
-------------------------------
Vision time :  85.77494049072266
Action time :  104.11212921142578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.300384521484375
-------------------------------
-------------------------------
model running time:  7.836671829223633
-------------------------------
-------------------------------
model running time:  25.992191314697266
-------------------------------
-------------------------------
model running time:  9.6430082321167
-------------------------------
-------------------------------
model running time:  25.886720657348633
-------------------------------
Vision time :  85.80300903320312
Action time :  101.65641784667969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.844287872314453
-------------------------------
-------------------------------
model running time:  8.004608154296875
-------------------------------
-------------------------------
model running time:  26.09779167175293
-------------------------------
-------------------------------
model running time:  9.667584419250488
-------------------------------
-------------------------------
model running time:  33.150047302246094
-------------------------------
Vision time :  85.7805404663086
Action time :  109.73388671875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.29132843017578
-------------------------------
-------------------------------
model running time:  7.868415832519531
-------------------------------
-------------------------------
model running time:  26.015743255615234
-------------------------------
-------------------------------
model running time:  9.72492790222168
-------------------------------
-------------------------------
model running time:  25.910303115844727
-------------------------------
Vision time :  85.7768325805664
Action time :  101.56748962402344
Trial 15 finished, success: tensor([True]), steps: 141
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.75948715209961
-------------------------------
-------------------------------
model running time:  7.903359889984131
-------------------------------
-------------------------------
model running time:  26.165119171142578
-------------------------------
-------------------------------
model running time:  9.7259521484375
-------------------------------
-------------------------------
model running time:  25.967744827270508
-------------------------------
Vision time :  85.76751708984375
Action time :  107.3642578125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.885311126708984
-------------------------------
-------------------------------
model running time:  7.905280113220215
-------------------------------
-------------------------------
model running time:  26.141759872436523
-------------------------------
-------------------------------
model running time:  9.665535926818848
-------------------------------
-------------------------------
model running time:  26.248191833496094
-------------------------------
Vision time :  85.75218963623047
Action time :  109.61820983886719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.849023818969727
-------------------------------
-------------------------------
model running time:  7.86729621887207
-------------------------------
-------------------------------
model running time:  26.109952926635742
-------------------------------
-------------------------------
model running time:  9.652223587036133
-------------------------------
-------------------------------
model running time:  25.932767868041992
-------------------------------
Vision time :  85.74422454833984
Action time :  108.39859008789062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.482751846313477
-------------------------------
-------------------------------
model running time:  7.873536109924316
-------------------------------
-------------------------------
model running time:  26.042495727539062
-------------------------------
-------------------------------
model running time:  9.678848266601562
-------------------------------
-------------------------------
model running time:  25.977855682373047
-------------------------------
Vision time :  85.73993682861328
Action time :  101.84703826904297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.09721565246582
-------------------------------
-------------------------------
model running time:  16.328704833984375
-------------------------------
-------------------------------
model running time:  27.874176025390625
-------------------------------
-------------------------------
model running time:  9.7259521484375
-------------------------------
-------------------------------
model running time:  25.912416458129883
-------------------------------
Vision time :  85.866943359375
Action time :  113.11820983886719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.601600646972656
-------------------------------
-------------------------------
model running time:  7.84281587600708
-------------------------------
-------------------------------
model running time:  26.13043212890625
-------------------------------
-------------------------------
model running time:  9.945088386535645
-------------------------------
-------------------------------
model running time:  26.046464920043945
-------------------------------
Vision time :  85.73999786376953
Action time :  102.70822143554688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.989696502685547
-------------------------------
-------------------------------
model running time:  13.124608039855957
-------------------------------
-------------------------------
model running time:  26.339231491088867
-------------------------------
-------------------------------
model running time:  9.691136360168457
-------------------------------
-------------------------------
model running time:  26.212352752685547
-------------------------------
Vision time :  85.76435089111328
Action time :  108.49689483642578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.72876739501953
-------------------------------
-------------------------------
model running time:  7.89299201965332
-------------------------------
-------------------------------
model running time:  26.143840789794922
-------------------------------
-------------------------------
model running time:  9.69222354888916
-------------------------------
-------------------------------
model running time:  26.027008056640625
-------------------------------
Vision time :  85.7600326538086
Action time :  107.4382095336914
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.716320037841797
-------------------------------
-------------------------------
model running time:  13.040639877319336
-------------------------------
-------------------------------
model running time:  26.960960388183594
-------------------------------
-------------------------------
model running time:  9.682815551757812
-------------------------------
-------------------------------
model running time:  26.076160430908203
-------------------------------
Vision time :  85.75859069824219
Action time :  109.85062408447266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.13043212890625
-------------------------------
-------------------------------
model running time:  7.870528221130371
-------------------------------
-------------------------------
model running time:  26.0894718170166
-------------------------------
-------------------------------
model running time:  9.732095718383789
-------------------------------
-------------------------------
model running time:  25.97056007385254
-------------------------------
Vision time :  85.75599670410156
Action time :  103.75577545166016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.434688568115234
-------------------------------
-------------------------------
model running time:  7.897088050842285
-------------------------------
-------------------------------
model running time:  25.94816017150879
-------------------------------
-------------------------------
model running time:  9.668607711791992
-------------------------------
-------------------------------
model running time:  25.884735107421875
-------------------------------
Vision time :  85.7624282836914
Action time :  

 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [01:48<00:52,  5.85s/it][A[A101.76000213623047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.418304443359375
-------------------------------
-------------------------------
model running time:  12.568575859069824
-------------------------------
-------------------------------
model running time:  26.125375747680664
-------------------------------
-------------------------------
model running time:  9.63599967956543
-------------------------------
-------------------------------
model running time:  26.432512283325195
-------------------------------
Vision time :  85.77417755126953
Action time :  107.08879852294922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.29654312133789
-------------------------------
-------------------------------
model running time:  7.833600044250488
-------------------------------
-------------------------------
model running time:  25.810943603515625
-------------------------------
-------------------------------
model running time:  9.6245756149292
-------------------------------
-------------------------------
model running time:  28.941312789916992
-------------------------------
Vision time :  85.72892761230469
Action time :  104.44902038574219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.455039978027344
-------------------------------
-------------------------------
model running time:  7.841792106628418
-------------------------------
-------------------------------
model running time:  30.16396713256836
-------------------------------
-------------------------------
model running time:  9.660415649414062
-------------------------------
-------------------------------
model running time:  26.070112228393555
-------------------------------
Vision time :  85.72704315185547
Action time :  105.9768295288086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.176639556884766
-------------------------------
-------------------------------
model running time:  7.812096118927002
-------------------------------
-------------------------------
model running time:  25.844736099243164
-------------------------------
-------------------------------
model running time:  9.675775527954102
-------------------------------
-------------------------------
model running time:  31.35590362548828
-------------------------------
Vision time :  85.75228881835938
Action time :  106.63423919677734
Trial 16 finished, success: tensor([True]), steps: 236
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.58176040649414
-------------------------------
-------------------------------
model running time:  7.845888137817383
-------------------------------
-------------------------------
model running time:  25.996416091918945
-------------------------------
-------------------------------
model running time:  9.628671646118164
-------------------------------
-------------------------------
model running time:  26.364896774291992
-------------------------------
Vision time :  85.74361419677734
Action time :  106.39462280273438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.361984252929688
-------------------------------
-------------------------------
model running time:  7.809023857116699
-------------------------------
-------------------------------
model running time:  26.202112197875977
-------------------------------
-------------------------------
model running time:  9.641983985900879
-------------------------------
-------------------------------
model running time:  31.555583953857422
-------------------------------
Vision time :  85.76486206054688
Action time :  107.57222747802734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.642623901367188
-------------------------------
-------------------------------
model running time:  7.818175792694092
-------------------------------
-------------------------------
model running time:  26.12838363647461
-------------------------------
-------------------------------
model running time:  9.644031524658203
-------------------------------
-------------------------------
model running time:  26.054655075073242
-------------------------------
Vision time :  85.74739074707031
Action time :  109.1052474975586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.380416870117188
-------------------------------
-------------------------------
model running time:  7.790463924407959
-------------------------------
-------------------------------
model running time:  26.100736618041992
-------------------------------
-------------------------------
model running time:  9.649151802062988
-------------------------------
-------------------------------
model running time:  25.80886459350586
-------------------------------
Vision time :  85.75353240966797
Action time :  106.3680648803711
before pruning: 


 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [01:50<00:38,  4.84s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.34774398803711
-------------------------------
-------------------------------
model running time:  7.812096118927002
-------------------------------
-------------------------------
model running time:  26.864639282226562
-------------------------------
-------------------------------
model running time:  9.65334415435791
-------------------------------
-------------------------------
model running time:  25.902080535888672
-------------------------------
Vision time :  85.74979400634766
Action time :  102.59257507324219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.180736541748047
-------------------------------
-------------------------------
model running time:  7.804927825927734
-------------------------------
-------------------------------
model running time:  29.1265926361084
-------------------------------
-------------------------------
model running time:  9.666560173034668
-------------------------------
-------------------------------
model running time:  25.7761287689209
-------------------------------
Vision time :  85.73712158203125
Action time :  104.36198425292969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.178688049316406
-------------------------------
-------------------------------
model running time:  7.840767860412598
-------------------------------
-------------------------------
model running time:  25.9051513671875
-------------------------------
-------------------------------
model running time:  17.967103958129883
-------------------------------
-------------------------------
model running time:  25.797632217407227
-------------------------------
Vision time :  85.77648162841797
Action time :  109.70620727539062
Trial 17 finished, success: tensor([True]), steps: 108
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.27903938293457
-------------------------------
-------------------------------
model running time:  7.812160015106201
-------------------------------
-------------------------------
model running time:  26.262527465820312
-------------------------------
-------------------------------
model running time:  9.679871559143066
-------------------------------
-------------------------------
model running time:  33.18681716918945
-------------------------------
Vision time :  85.77295684814453
Action time :  109.0508804321289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.445951461791992
-------------------------------
-------------------------------
model running time:  7.885824203491211
-------------------------------
-------------------------------
model running time:  26.090496063232422
-------------------------------
-------------------------------
model running time:  9.624544143676758
-------------------------------
-------------------------------
model running time:  25.921600341796875
-------------------------------
Vision time :  85.75945281982422
Action time :  101.970947265625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.473600387573242
-------------------------------
-------------------------------
model running time:  7.8592000007629395
-------------------------------
-------------------------------
model running time:  26.01353645324707
-------------------------------
-------------------------------
model running time:  10.503168106079102
-------------------------------
-------------------------------
model running time:  27.325439453125
-------------------------------
Vision time :  85.7540512084961
Action time :  104.31692504882812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.983552932739258
-------------------------------
-------------------------------
model running time:  7.986176013946533
-------------------------------
-------------------------------
model running time:  33.086463928222656
-------------------------------
-------------------------------
model running time:  9.761792182922363
-------------------------------
-------------------------------
model running time:  26.414079666137695
-------------------------------
Vision time :  85.82575988769531
Action time :  110.31136322021484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.91904067993164
-------------------------------
-------------------------------
model running time:  7.919616222381592
-------------------------------
-------------------------------
model running time:  26.439552307128906
-------------------------------
-------------------------------
model running time:  9.741312026977539
-------------------------------
-------------------------------
model running time:  27.068416595458984
-------------------------------
Vision time :  85.79110717773438
Action time :  104.25856018066406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.324480056762695
-------------------------------
-------------------------------
model running time:  8.073216438293457
-------------------------------
-------------------------------
model running time:  32.537601470947266
-------------------------------
-------------------------------
model running time:  9.727999687194824
-------------------------------
-------------------------------
model running time:  26.22140884399414
-------------------------------
Vision time :  85.76860809326172
Action time :  110.08102416992188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.648704528808594
-------------------------------
-------------------------------
model running time:  7.887872219085693
-------------------------------
-------------------------------
model running time:  26.272768020629883
-------------------------------
-------------------------------
model running time:  9.706496238708496
-------------------------------
-------------------------------
model running time:  26.17241668701172
-------------------------------
Vision time :  85.80313873291016
Action time :  102.89561462402344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.558015823364258
-------------------------------
-------------------------------
model running time:  7.887936115264893
-------------------------------
-------------------------------
model running time:  26.283103942871094
-------------------------------
-------------------------------
model running time:  9.697407722473145
-------------------------------
-------------------------------
model running time:  29.201440811157227
-------------------------------
Vision time :  85.75440216064453
Action time :  106.71308898925781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.7324161529541
-------------------------------
-------------------------------
model running time:  7.926784038543701
-------------------------------
-------------------------------
model running time:  26.264575958251953
-------------------------------
-------------------------------
model running time:  9.729023933410645
-------------------------------
-------------------------------
model running time:  36.028480529785156
-------------------------------
Vision time :  85.75382232666016
Action time :  116.71849822998047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.852096557617188
-------------------------------
-------------------------------
model running time:  7.931903839111328
-------------------------------
-------------------------------
model running time:  26.474496841430664
-------------------------------
-------------------------------
model running time:  9.778176307678223
-------------------------------
-------------------------------
model running time:  26.401792526245117
-------------------------------
Vision time :  85.77212524414062
Action time :  109.38162994384766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.473087310791016
-------------------------------
-------------------------------
model running time:  7.877632141113281
-------------------------------
-------------------------------
model running time:  26.183679580688477
-------------------------------
-------------------------------
model running time:  9.67580795288086
-------------------------------
-------------------------------
model running time:  26.101760864257812
-------------------------------
Vision time :  85.77721405029297
Action time :  110.26534271240234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.235008239746094
-------------------------------
-------------------------------
model running time:  7.861184120178223
-------------------------------
-------------------------------
model running time:  26.102783203125
-------------------------------
-------------------------------
model running time:  9.722880363464355
-------------------------------
-------------------------------
model running time:  26.067968368530273
-------------------------------
Vision time :  85.74441528320312
Action time :  101.80198669433594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.67635154724121
-------------------------------
-------------------------------
model running time:  7.8888959884643555
-------------------------------
-------------------------------
model running time:  26.33932876586914
-------------------------------
-------------------------------
model running time:  9.713664054870605
-------------------------------
-------------------------------
model running time:  26.229759216308594
-------------------------------
Vision time :  85.76592254638672
Action time :  102.96729278564453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.71628761291504
-------------------------------
-------------------------------
model running time:  7.888735771179199
-------------------------------
-------------------------------
model running time:  26.450944900512695
-------------------------------
-------------------------------
model running time:  9.729023933410645
-------------------------------
-------------------------------
model running time:  31.51046371459961
-------------------------------
Vision time :  85.7490234375
Action time :  108.34022521972656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.768672943115234
-------------------------------
-------------------------------
model running time:  7.897215843200684
-------------------------------
-------------------------------
model running time:  26.303552627563477
-------------------------------
-------------------------------
model running time:  9.691136360168457
-------------------------------
-------------------------------
model running time:  26.204160690307617
-------------------------------
Vision time :  85.74765014648438
Action time :  106.90774536132812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.88876724243164
-------------------------------
-------------------------------
model running time:  7.923776149749756
-------------------------------
-------------------------------
model running time:  26.52364730834961
-------------------------------
-------------------------------
model running time:  9.741312026977539
-------------------------------
-------------------------------
model running time:  26.33718490600586
-------------------------------
Vision time :  85.78294372558594
Action time :  104.5381088256836
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.02128028869629
-------------------------------
-------------------------------
model running time:  7.932928085327148
-------------------------------
-------------------------------
model running time:  26.413055419921875
-------------------------------
-------------------------------
model running time:  9.706496238708496
-------------------------------
-------------------------------
model running time:  30.1823673248291
-------------------------------
Vision time :  85.75174713134766
Action time :  107.43196868896484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.782848358154297
-------------------------------
-------------------------------
model running time:  7.912384033203125
-------------------------------
-------------------------------
model running time:  26.51033592224121
-------------------------------
-------------------------------
model running time:  9.727999687194824
-------------------------------
-------------------------------
model running time:  26.454015731811523
-------------------------------
Vision time :  85.77276611328125
Action time :  103.33695983886719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.929407119750977
-------------------------------
-------------------------------
model running time:  7.893951892852783
-------------------------------
-------------------------------
model running time:  26.49190330505371
-------------------------------
-------------------------------
model running time:  9.766912460327148
-------------------------------
-------------------------------
model running time:  27.08678436279297
-------------------------------
Vision time :  85.76326751708984
Action time :  104.26777648925781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.896575927734375
-------------------------------
-------------------------------
model running time:  8.112128257751465
-------------------------------
-------------------------------
model running time:  26.9486083984375
-------------------------------
-------------------------------
model running time:  9.848832130432129
-------------------------------
-------------------------------
model running time:  26.792959213256836
-------------------------------
Vision time :  85.76156616210938
Action time :  111.6211166381836
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.66217613220215
-------------------------------
-------------------------------
model running time:  13.088768005371094
-------------------------------
-------------------------------
model running time:  26.56051254272461
-------------------------------
-------------------------------
model running time:  9.740287780761719
-------------------------------
-------------------------------
model running time:  26.514432907104492
-------------------------------
Vision time :  85.7520980834961
Action time :  108.44979095458984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416


 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [01:59<00:42,  6.07s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.769535064697266
-------------------------------
-------------------------------
model running time:  7.932928085327148
-------------------------------
-------------------------------
model running time:  26.377216339111328
-------------------------------
-------------------------------
model running time:  9.689984321594238
-------------------------------
-------------------------------
model running time:  26.52774429321289
-------------------------------
Vision time :  85.77442932128906
Action time :  103.43417358398438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.275264739990234
-------------------------------
-------------------------------
model running time:  7.924736022949219
-------------------------------
-------------------------------
model running time:  26.399808883666992
-------------------------------
-------------------------------
model running time:  9.899904251098633
-------------------------------
-------------------------------
model running time:  26.0545597076416
-------------------------------
Vision time :  85.7705307006836
Action time :  105.65734100341797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.633344650268555
-------------------------------
-------------------------------
model running time:  7.875552177429199
-------------------------------
-------------------------------
model running time:  26.216480255126953
-------------------------------
-------------------------------
model running time:  9.711615562438965
-------------------------------
-------------------------------
model running time:  26.10688018798828
-------------------------------
Vision time :  85.78479766845703
Action time :  102.60787200927734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.679359436035156
-------------------------------
-------------------------------
model running time:  7.873536109924316
-------------------------------
-------------------------------
model running time:  26.271743774414062
-------------------------------
-------------------------------
model running time:  9.899007797241211
-------------------------------
-------------------------------
model running time:  26.759103775024414
-------------------------------
Vision time :  85.72259521484375
Action time :  103.72198486328125
Trial 18 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.740863800048828
-------------------------------
-------------------------------
model running time:  7.95033597946167
-------------------------------
-------------------------------
model running time:  27.51590347290039
-------------------------------
-------------------------------
model running time:  9.8088960647583
-------------------------------
-------------------------------
model running time:  26.910720825195312
-------------------------------
Vision time :  85.72665405273438
Action time :  105.05216217041016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.52992057800293
-------------------------------
-------------------------------
model running time:  15.013888359069824
-------------------------------
-------------------------------
model running time:  26.49907112121582
-------------------------------
-------------------------------
model running time:  9.658368110656738
-------------------------------
-------------------------------
model running time:  26.031103134155273
-------------------------------
Vision time :  85.7557144165039
Action time :  109.90684509277344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.36809539794922
-------------------------------
-------------------------------
model running time:  7.799808025360107
-------------------------------
-------------------------------
model running time:  26.588159561157227
-------------------------------
-------------------------------
model running time:  9.656319618225098
-------------------------------
-------------------------------
model running time:  25.968639373779297
-------------------------------
Vision time :  85.77203369140625
Action time :  102.24537658691406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.51571273803711
-------------------------------
-------------------------------
model running time:  20.620128631591797
-------------------------------
-------------------------------
model running time:  26.214303970336914
-------------------------------
-------------------------------
model running time:  9.63584041595459
-------------------------------
-------------------------------
model running time:  26.002431869506836
-------------------------------
Vision time :  85.74781036376953
Action time :  114.86003112792969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048


 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [02:01<00:29,  4.88s/it][A[A-------------------------------
model running time:  25.14944076538086
-------------------------------
-------------------------------
model running time:  7.856128215789795
-------------------------------
-------------------------------
model running time:  26.196992874145508
-------------------------------
-------------------------------
model running time:  9.646080017089844
-------------------------------
-------------------------------
model running time:  29.807615280151367
-------------------------------
Vision time :  85.83859252929688
Action time :  106.82061004638672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.651775360107422
-------------------------------
-------------------------------
model running time:  7.862271785736084
-------------------------------
-------------------------------
model running time:  33.48787307739258
-------------------------------
-------------------------------
model running time:  9.690112113952637
-------------------------------
-------------------------------
model running time:  26.08025550842285
-------------------------------
Vision time :  85.76815795898438
Action time :  110.0943374633789
Trial 19 finished, success: tensor([True]), steps: 86
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.888320922851562
-------------------------------
-------------------------------
model running time:  7.963551998138428
-------------------------------
-------------------------------
model running time:  26.756160736083984
-------------------------------
-------------------------------
model running time:  16.848896026611328
-------------------------------
-------------------------------
model running time:  26.12544059753418
-------------------------------
Vision time :  85.7873306274414
Action time :  110.59097290039062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.785919189453125
-------------------------------
-------------------------------
model running time:  7.838719844818115
-------------------------------
-------------------------------
model running time:  26.36390495300293
-------------------------------
-------------------------------
model running time:  9.662464141845703
-------------------------------
-------------------------------
model running time:  26.105695724487305
-------------------------------
Vision time :  85.76127624511719
Action time :  105.491455078125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.24928092956543
-------------------------------
-------------------------------
model running time:  7.857312202453613
-------------------------------
-------------------------------
model running time:  32.59801483154297
-------------------------------
-------------------------------
model running time:  9.63980770111084
-------------------------------
-------------------------------
model running time:  25.883647918701172
-------------------------------
Vision time :  85.78307342529297
Action time :  108.02288055419922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.77107238769531
-------------------------------
-------------------------------
model running time:  7.860223770141602
-------------------------------
-------------------------------
model running time:  26.14169692993164
-------------------------------
-------------------------------
model running time:  9.691136360168457
-------------------------------
-------------------------------
model running time:  25.914527893066406
-------------------------------
Vision time :  85.73289489746094
Action time :  110.48140716552734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.667455673217773
-------------------------------
-------------------------------
model running time:  7.849887847900391
-------------------------------
-------------------------------
model running time:  26.16227149963379
-------------------------------
-------------------------------
model running time:  9.61638355255127
-------------------------------
-------------------------------
model running time:  25.95849609375
-------------------------------
Vision time :  85.75475311279297
Action time :  105.11564636230469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.301599502563477
-------------------------------
-------------------------------
model running time:  7.816192150115967
-------------------------------
-------------------------------
model running time:  26.00752067565918
-------------------------------
-------------------------------
model running time:  9.641983985900879
-------------------------------
-------------------------------
model running time:  25.935871124267578
-------------------------------
Vision time :  85.75971221923828
Action time :  101.42412567138672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.285184860229492
-------------------------------
-------------------------------
model running time:  7.872511863708496
-------------------------------
-------------------------------
model running time:  26.200063705444336
-------------------------------
-------------------------------
model running time:  9.637887954711914
-------------------------------
-------------------------------
model running time:  26.16217613220215
-------------------------------
Vision time :  85.7257308959961
Action time :  102.00678253173828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.733760833740234
-------------------------------
-------------------------------
model running time:  7.887872219085693
-------------------------------
-------------------------------
model running time:  26.31475257873535
-------------------------------
-------------------------------
model running time:  9.667584419250488
-------------------------------
-------------------------------
model running time:  26.13350486755371
-------------------------------
Vision time :  85.77356719970703
Action time :  109.51990509033203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.731647491455078
-------------------------------
-------------------------------
model running time:  7.963551998138428
-------------------------------
-------------------------------
model running time:  26.612831115722656
-------------------------------
-------------------------------
model running time:  9.68892765045166
-------------------------------
-------------------------------
model running time:  26.27903938293457
-------------------------------
Vision time :  85.76387023925781
Action time :  103.29510498046875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.641599655151367
-------------------------------
-------------------------------
model running time:  7.917568206787109
-------------------------------
-------------------------------
model running time:  26.2871036529541
-------------------------------
-------------------------------
model running time:  9.661439895629883
-------------------------------
-------------------------------
model running time:  26.158079147338867
-------------------------------
Vision time :  85.77740478515625
Action time :  102.60275268554688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.417280197143555
-------------------------------
-------------------------------
model running time:  7.880703926086426
-------------------------------
-------------------------------
model running time:  26.31065559387207
-------------------------------
-------------------------------
model running time:  9.762816429138184
-------------------------------
-------------------------------
model running time:  31.02720069885254
-------------------------------
Vision time :  85.7672348022461
Action time :  107.20051574707031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.403839111328125
-------------------------------
-------------------------------
model running time:  7.841792106628418
-------------------------------
-------------------------------
model running time:  25.977855682373047
-------------------------------
-------------------------------
model running time:  9.600000381469727
-------------------------------
-------------------------------
model running time:  25.871360778808594
-------------------------------
Vision time :  85.76102447509766
Action time :  101.6147232055664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.320064544677734
-------------------------------
-------------------------------
model running time:  7.853055953979492
-------------------------------
-------------------------------
model running time:  26.077024459838867
-------------------------------
-------------------------------
model running time:  9.622655868530273
-------------------------------
-------------------------------
model running time:  25.93177604675293
-------------------------------
Vision time :  85.75894165039062
Action time :  102.40409851074219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.608192443847656
-------------------------------
-------------------------------
model running time:  8.09164810180664
-------------------------------
-------------------------------
model running time:  27.157440185546875
-------------------------------
-------------------------------
model running time:  9.88976001739502
-------------------------------
-------------------------------
model running time:  26.94963264465332
-------------------------------
Vision time :  85.8022689819336
Action time :  106.0474853515625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.32249641418457
-------------------------------
-------------------------------
model running time:  8.146944046020508
-------------------------------
-------------------------------
model running time:  27.455583572387695
-------------------------------
-------------------------------
model running time:  11.960320472717285
-------------------------------
-------------------------------
model running time:  26.615808486938477
-------------------------------
Vision time :  85.763427734375
Action time :  107.76576232910156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.644607543945312
-------------------------------
-------------------------------
model running time:  8.043456077575684
-------------------------------
-------------------------------
model running time:  27.197439193725586
-------------------------------
-------------------------------
model running time:  9.911423683166504
-------------------------------
-------------------------------
model running time:  26.93222427368164
-------------------------------
Vision time :  85.78102111816406
Action time :  104.64358520507812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.703744888305664
-------------------------------
-------------------------------
model running time:  7.885824203491211
-------------------------------
-------------------------------
model running time:  27.598848342895508
-------------------------------
-------------------------------
model running time:  9.80787181854248
-------------------------------
-------------------------------
model running time:  26.494815826416016
-------------------------------
Vision time :  85.7864990234375
Action time :  108.5818862915039
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.629375457763672
-------------------------------
-------------------------------
model running time:  7.884799957275391
-------------------------------
-------------------------------
model running time:  26.329120635986328
-------------------------------
-------------------------------
model running time:  9.697279930114746
-------------------------------
-------------------------------
model running time:  27.98896026611328
-------------------------------
Vision time :  85.73673248291016
Action time :  104.54425811767578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.035776138305664
-------------------------------
-------------------------------
model running time:  7.8397440910339355
-------------------------------
-------------------------------
model running time:  26.403839111328125
-------------------------------
-------------------------------
model running time:  9.758720397949219
-------------------------------
-------------------------------
model running time:  26.402816772460938
-------------------------------
Vision time :  85.76060485839844
Action time :  103.39737701416016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.50841522216797
-------------------------------
-------------------------------
model running time:  7.934815883636475
-------------------------------
-------------------------------
model running time:  26.364927291870117
-------------------------------
-------------------------------
model running time:  9.781248092651367
-------------------------------
-------------------------------
model running time:  26.429439544677734
-------------------------------
Vision time :  85.75142669677734
Action time :  102.81267547607422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.285280227661133
-------------------------------
-------------------------------
model running time:  7.889920234680176
-------------------------------
-------------------------------
model running time:  26.463232040405273
-------------------------------
-------------------------------
model running time:  9.749504089355469
-------------------------------
-------------------------------
model running time:  26.434560775756836
-------------------------------
Vision time :  85.75737762451172
Action time :  102.63346862792969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.425567626953125
-------------------------------
-------------------------------
model running time:  7.839903831481934
-------------------------------
-------------------------------
model running time:  26.27791976928711
-------------------------------
-------------------------------
model running time:  9.771007537841797
-------------------------------
-------------------------------
model running time:  26.345600128173828
-------------------------------
Vision time :  85.73200225830078
Action time :  102.40512084960938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.311840057373047
-------------------------------
-------------------------------
model running time:  7.883903980255127
-------------------------------
-------------------------------
model running time:  26.35148811340332
-------------------------------
-------------------------------


 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [02:10<00:30,  6.05s/it][A[Amodel running time:  9.71673583984375
-------------------------------
-------------------------------
model running time:  26.420223236083984
-------------------------------
Vision time :  85.73321533203125
Action time :  102.60991668701172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.474559783935547
-------------------------------
-------------------------------
model running time:  7.911520004272461
-------------------------------
-------------------------------
model running time:  26.480640411376953
-------------------------------
-------------------------------
model running time:  9.80684757232666
-------------------------------
-------------------------------
model running time:  26.43756866455078
-------------------------------
Vision time :  85.73014068603516
Action time :  102.90799713134766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.66815948486328
-------------------------------
-------------------------------
model running time:  7.910399913787842
-------------------------------
-------------------------------
model running time:  26.522560119628906
-------------------------------
-------------------------------
model running time:  9.761823654174805
-------------------------------
-------------------------------
model running time:  26.404800415039062
-------------------------------
Vision time :  85.75202941894531
Action time :  103.36358642578125
Trial 20 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.456127166748047
-------------------------------
-------------------------------
model running time:  7.876607894897461
-------------------------------
-------------------------------
model running time:  26.383359909057617
-------------------------------
-------------------------------
model running time:  9.693183898925781
-------------------------------
-------------------------------
model running time:  26.33830451965332
-------------------------------
Vision time :  85.75730895996094
Action time :  102.69900512695312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.5513916015625
-------------------------------
-------------------------------
model running time:  7.867392063140869
-------------------------------
-------------------------------
model running time:  26.77552032470703
-------------------------------
-------------------------------
model running time:  9.790559768676758
-------------------------------
-------------------------------
model running time:  26.48371124267578
-------------------------------
Vision time :  85.74307250976562
Action time :  103.47840118408203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.358911514282227
-------------------------------
-------------------------------
model running time:  7.8243842124938965
-------------------------------
-------------------------------
model running time:  26.36288070678711
-------------------------------
-------------------------------
model running time:  9.693183898925781
-------------------------------
-------------------------------
model running time:  26.202112197875977
-------------------------------
Vision time :  85.74537658691406
Action time :  102.21977233886719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.572927474975586
-------------------------------
-------------------------------
model running time:  7.814144134521484
-------------------------------
-------------------------------
model running time:  26.31065559387207
-------------------------------
-------------------------------
model running time:  9.71072006225586
-------------------------------
-------------------------------
model running time:  26.230783462524414
-------------------------------
Vision time :  85.76306915283203
Action time :  102.49830627441406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.49817657470703
-------------------------------
-------------------------------
model running time:  7.814144134521484
-------------------------------
-------------------------------
model running time:  26.32601547241211
-------------------------------
-------------------------------
model running time:  9.71571159362793
-------------------------------
-------------------------------
model running time:  26.219520568847656
-------------------------------
Vision time :  85.74566650390625
Action time :  102.42662048339844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.49504089355469
-------------------------------
-------------------------------
model running time:  7.872511863708496
-------------------------------
-------------------------------
model running time:  26.446847915649414
-------------------------------
-------------------------------
model running time:  9.70963191986084


 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [02:14<00:21,  5.32s/it][A[A-------------------------------
-------------------------------
model running time:  26.30246353149414
-------------------------------
Vision time :  85.83462524414062
Action time :  111.92626953125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.54630470275879
-------------------------------
-------------------------------
model running time:  8.892416000366211
-------------------------------
-------------------------------
model running time:  26.52672004699707
-------------------------------
-------------------------------
model running time:  9.713791847229004
-------------------------------
-------------------------------
model running time:  26.281984329223633
-------------------------------
Vision time :  85.74588775634766
Action time :  103.89913940429688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.37628746032715
-------------------------------
-------------------------------
model running time:  7.862271785736084
-------------------------------
-------------------------------
model running time:  26.36185646057129
-------------------------------
-------------------------------
model running time:  9.732095718383789
-------------------------------
-------------------------------
model running time:  26.348575592041016
-------------------------------
Vision time :  85.78364562988281
Action time :  102.61196899414062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.850303649902344
-------------------------------
-------------------------------
model running time:  8.51046371459961
-------------------------------
-------------------------------
model running time:  29.54547119140625
-------------------------------
-------------------------------
model running time:  9.802687644958496
-------------------------------
-------------------------------
model running time:  26.37004852294922
-------------------------------
Vision time :  85.80150604248047
Action time :  109.88236999511719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.396799087524414
-------------------------------
-------------------------------
model running time:  7.849984169006348
-------------------------------
-------------------------------
model running time:  26.2871036529541
-------------------------------
-------------------------------
model running time:  9.684991836547852
-------------------------------
-------------------------------
model running time:  26.28505516052246
-------------------------------
Vision time :  85.7936019897461
Action time :  102.35903930664062
Trial 21 finished, success: tensor([True]), steps: 154
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.446975708007812
-------------------------------
-------------------------------
model running time:  7.828320026397705
-------------------------------
-------------------------------
model running time:  26.54310417175293
-------------------------------
-------------------------------
model running time:  9.793375968933105
-------------------------------
-------------------------------
model running time:  26.395647048950195
-------------------------------
Vision time :  85.74246215820312
Action time :  102.80857849121094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.6823673248291
-------------------------------
-------------------------------
model running time:  7.869440078735352
-------------------------------
-------------------------------
model running time:  26.536832809448242
-------------------------------
-------------------------------
model running time:  9.679871559143066
-------------------------------
-------------------------------
model running time:  26.374303817749023
-------------------------------
Vision time :  85.7845458984375
Action time :  103.02464294433594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.077632904052734
-------------------------------
-------------------------------
model running time:  7.872511863708496
-------------------------------
-------------------------------
model running time:  26.50111961364746
-------------------------------
-------------------------------
model running time:  9.682944297790527
-------------------------------
-------------------------------
model running time:  26.220544815063477
-------------------------------
Vision time :  85.76089477539062
Action time :  105.44742584228516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.50739288330078
-------------------------------
-------------------------------
model running time:  7.855167865753174
-------------------------------
-------------------------------
model running time:  26.33420753479004
-------------------------------
-------------------------------
model running time:  9.694208145141602
-------------------------------
-------------------------------
model running time:  26.392576217651367
-------------------------------
Vision time :  85.74848175048828
Action time :  102.724609375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.424480438232422
-------------------------------
-------------------------------
model running time:  7.837535858154297
-------------------------------
-------------------------------
model running time:  26.340351104736328
-------------------------------
-------------------------------
model running time:  9.711615562438965
-------------------------------
-------------------------------
model running time:  26.20636749267578
-------------------------------
Vision time :  85.77180480957031
Action time :  102.26585388183594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.446975708007812
-------------------------------
-------------------------------
model running time:  7.817215919494629
-------------------------------
-------------------------------
model running time:  26.11302375793457
-------------------------------
-------------------------------
model running time:  9.768959999084473
-------------------------------
-------------------------------
model running time:  26.065919876098633
-------------------------------
Vision time :  85.74102020263672
Action time :  102.15408325195312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.288320541381836
-------------------------------
-------------------------------
model running time:  7.8243842124938965
-------------------------------
-------------------------------
model running time:  26.345600128173828
-------------------------------
-------------------------------
model running time:  9.71673583984375
-------------------------------
-------------------------------
model running time:  25.988224029541016
-------------------------------
Vision time :  85.75702667236328
Action time :  102.0549087524414
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.962047576904297
-------------------------------
-------------------------------
model running time:  7.8264641761779785
-------------------------------
-------------------------------
model running time:  26.194944381713867
-------------------------------
-------------------------------
model running time:  9.70854377746582
-------------------------------
-------------------------------
model running time:  26.057600021362305
-------------------------------
Vision time :  85.73184204101562
Action time :  102.50956726074219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.4051513671875
-------------------------------
-------------------------------
model running time:  7.825376033782959
-------------------------------
-------------------------------
model running time:  26.20195198059082
-------------------------------
-------------------------------
model running time:  9.714688301086426
-------------------------------
-------------------------------
model running time:  25.970687866210938
-------------------------------
Vision time :  85.73705291748047
Action time :  102.12556457519531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.235008239746094
-------------------------------
-------------------------------
model running time:  7.80185604095459
-------------------------------
-------------------------------
model running time:  26.10688018798828
-------------------------------
-------------------------------
model running time:  9.631744384765625
-------------------------------
-------------------------------
model running time:  34.162689208984375
-------------------------------
Vision time :  85.77494049072266
Action time :  109.87519836425781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.23583984375
-------------------------------
-------------------------------
model running time:  7.820288181304932
-------------------------------
-------------------------------
model running time:  26.35161590576172
-------------------------------
-------------------------------
model running time:  9.660415649414062
-------------------------------
-------------------------------
model running time:  26.264575958251953
-------------------------------
Vision time :  85.74105834960938
Action time :  102.02726745605469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.207359313964844
-------------------------------
-------------------------------
model running time:  7.829504013061523
-------------------------------
-------------------------------
model running time:  26.263551712036133
-------------------------------
-------------------------------
model running time:  9.70751953125
-------------------------------
-------------------------------
model running time:  26.198015213012695
-------------------------------
Vision time :  85.7564468383789
Action time :  101.78355407714844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.266752243041992
-------------------------------
-------------------------------
model running time:  7.7803521156311035
-------------------------------
-------------------------------
model running time:  26.23072052001953
-------------------------------
-------------------------------
model running time:  9.688063621520996
-------------------------------
-------------------------------
model running time:  26.208255767822266
-------------------------------
Vision time :  85.73820495605469
Action time :  101.9310073852539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.20515251159668
-------------------------------
-------------------------------
model running time:  7.858176231384277
-------------------------------
-------------------------------
model running time:  26.245119094848633
-------------------------------
-------------------------------
model running time:  9.666560173034668
-------------------------------
-------------------------------
model running time:  26.237951278686523
-------------------------------
Vision time :  85.72857666015625
Action time :  101.91871643066406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.30771255493164
-------------------------------
-------------------------------
model running time:  7.812096118927002
-------------------------------
-------------------------------
model running time:  26.175487518310547
-------------------------------
-------------------------------
model running time:  9.653247833251953
-------------------------------
-------------------------------
model running time:  26.18979263305664
-------------------------------
Vision time :  85.72621154785156
Action time :  101.9678726196289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.644607543945312
-------------------------------
-------------------------------
model running time:  7.948416233062744
-------------------------------
-------------------------------
model running time:  26.340351104736328
-------------------------------
-------------------------------
model running time:  9.63584041595459
-------------------------------
-------------------------------
model running time:  26.162208557128906
-------------------------------
Vision time :  85.74425506591797
Action time :  102.71846771240234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.613887786865234
-------------------------------
-------------------------------
model running time:  7.860223770141602
-------------------------------
-------------------------------
model running time:  29.644704818725586
-------------------------------
-------------------------------
model running time:  9.730079650878906
-------------------------------
-------------------------------
model running time:  26.239999771118164
-------------------------------
Vision time :  86.30438232421875
Action time :  108.48051452636719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.73676872253418
-------------------------------
-------------------------------
model running time:  7.875584125518799
-------------------------------
-------------------------------
model running time:  26.436607360839844
-------------------------------
-------------------------------
model running time:  9.729023933410645
-------------------------------
-------------------------------
model running time:  26.225664138793945
-------------------------------
Vision time :  85.74771118164062
Action time :  105.804931640625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.89344024658203
-------------------------------
-------------------------------
model running time:  7.968768119812012
-------------------------------
-------------------------------
model running time:  27.411455154418945
-------------------------------
-------------------------------
model running time:  9.758720397949219
-------------------------------
-------------------------------
model running time:  26.47439956665039
-------------------------------
Vision time :  85.75373077392578
Action time :  104.55955505371094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.71126365661621
-------------------------------
-------------------------------
model running time:  7.886847972869873
-------------------------------
-------------------------------
model running time:  26.476543426513672
-------------------------------
-------------------------------
model running time:  9.722880363464355
-------------------------------
-------------------------------
model running time:  26.190847396850586
-------------------------------
Vision time :  85.77161407470703
Action time :  102.88137817382812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952


 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [02:23<00:19,  6.41s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.401920318603516
-------------------------------
-------------------------------
model running time:  7.914495944976807
-------------------------------
-------------------------------
model running time:  26.31884765625
-------------------------------
-------------------------------
model running time:  9.688063621520996
-------------------------------
-------------------------------
model running time:  26.170368194580078
-------------------------------
Vision time :  85.73872375488281
Action time :  102.56486511230469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.48896026611328
-------------------------------
-------------------------------
model running time:  7.899136066436768
-------------------------------
-------------------------------
model running time:  26.402816772460938
-------------------------------
-------------------------------
model running time:  9.675775527954102
-------------------------------
-------------------------------
model running time:  26.253311157226562
-------------------------------
Vision time :  85.76057434082031
Action time :  102.61196899414062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.136703491210938
-------------------------------
-------------------------------
model running time:  7.842720031738281
-------------------------------
-------------------------------
model running time:  30.57868766784668
-------------------------------
-------------------------------
model running time:  9.690112113952637
-------------------------------
-------------------------------
model running time:  25.93484878540039
-------------------------------
Vision time :  85.77101135253906
Action time :  105.96556854248047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.33126449584961
-------------------------------
-------------------------------
model running time:  7.820288181304932
-------------------------------
-------------------------------
model running time:  25.90924835205078
-------------------------------
-------------------------------
model running time:  9.571200370788574
-------------------------------
-------------------------------
model running time:  25.70240020751953
-------------------------------
Vision time :  85.7845458984375
Action time :  101.21609497070312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.098751068115234
-------------------------------
-------------------------------
model running time:  7.778304100036621
-------------------------------
-------------------------------
model running time:  25.865215301513672
-------------------------------
-------------------------------
model running time:  9.57750415802002
-------------------------------
-------------------------------
model running time:  25.76076889038086
-------------------------------
Vision time :  85.78060913085938
Action time :  100.81600189208984
Trial 22 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.612031936645508
-------------------------------
-------------------------------
model running time:  7.787519931793213
-------------------------------
-------------------------------
model running time:  25.919424057006836
-------------------------------
-------------------------------
model running time:  9.727999687194824
-------------------------------
-------------------------------
model running time:  25.887744903564453
-------------------------------
Vision time :  85.75904083251953
Action time :  106.64959716796875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.243200302124023
-------------------------------
-------------------------------
model running time:  7.806848049163818
-------------------------------
-------------------------------
model running time:  26.1345272064209
-------------------------------
-------------------------------
model running time:  9.6430082321167
-------------------------------
-------------------------------
model running time:  25.773056030273438
-------------------------------
Vision time :  85.73670196533203
Action time :  101.45791625976562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.652544021606445
-------------------------------
-------------------------------
model running time:  7.868544101715088
-------------------------------
-------------------------------
model running time:  26.245119094848633
-------------------------------
-------------------------------
model running time:  9.673727989196777
-------------------------------
-------------------------------
model running time:  31.250560760498047
-------------------------------
Vision time :  85.75737762451172
Action time :  113.30668640136719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.27187156677246
-------------------------------
-------------------------------
model running time:  7.811071872711182
-------------------------------
-------------------------------
model running time:  25.91846466064453
-------------------------------
-------------------------------
model running time:  9.629728317260742
-------------------------------
-------------------------------
model running time:  25.74028778076172
-------------------------------
Vision time :  85.76297760009766
Action time :  101.17222595214844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.099712371826172
-------------------------------
-------------------------------
model running time:  7.761919975280762
-------------------------------
-------------------------------
model running time:  25.961471557617188
-------------------------------
-------------------------------
model running time:  9.654272079467773
-------------------------------
-------------------------------
model running time:  25.780223846435547
-------------------------------
Vision time :  85.7479019165039
Action time :  101.11488342285156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.353792190551758
-------------------------------
-------------------------------
model running time:  7.811967849731445
-------------------------------
-------------------------------
model running time:  25.969568252563477
-------------------------------
-------------------------------
model running time:  9.69324779510498
-------------------------------
-------------------------------
model running time:  25.822208404541016
-------------------------------
Vision time :  85.76306915283203
Action time :  101.55827331542969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.104991912841797
-------------------------------
-------------------------------
model running time:  7.809023857116699
-------------------------------
-------------------------------
model running time:  30.409727096557617
-------------------------------
-------------------------------
model running time:  9.664511680603027
-------------------------------
-------------------------------
model running time:  25.846784591674805
-------------------------------
Vision time :  85.75555419921875
Action time :  105.64002990722656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.94361686706543
-------------------------------
-------------------------------
model running time:  7.848959922790527
-------------------------------
-------------------------------
model running time:  31.08550453186035
-------------------------------
-------------------------------
model running time:  9.61638355255127
-------------------------------
-------------------------------
model running time:  25.655296325683594
-------------------------------
Vision time :  85.88636779785156
Action time :  107.10221099853516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.9583683013916
-------------------------------
-------------------------------
model running time:  7.762944221496582
-------------------------------
-------------------------------
model running time:  25.812992095947266
-------------------------------
-------------------------------
model running time:  9.572352409362793
-------------------------------
-------------------------------
model running time:  25.548799514770508
-------------------------------
Vision time :  85.74009704589844
Action time :  100.36326599121094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.565759658813477
-------------------------------
-------------------------------
model running time:  14.331904411315918
-------------------------------
-------------------------------
model running time:  26.10483169555664
-------------------------------
-------------------------------
model running time:  9.621503829956055
-------------------------------
-------------------------------
model running time:  25.91846466064453
-------------------------------
Vision time :  85.75062561035156
Action time :  108.85939025878906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.31385612487793
-------------------------------
-------------------------------
model running time:  7.835648059844971
-------------------------------
-------------------------------
model running time:  31.76755142211914
-------------------------------
-------------------------------
model running time:  9.670623779296875
-------------------------------
-------------------------------
model running time:  25.845760345458984
-------------------------------
Vision time :  85.77436828613281
Action time :  107.21485137939453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.30361557006836
-------------------------------
-------------------------------
model running time:  7.803904056549072
-------------------------------
-------------------------------
model running time:  25.69318389892578
-------------------------------
-------------------------------
model running time:  9.615360260009766
-------------------------------
-------------------------------
model running time:  25.598880767822266
-------------------------------
Vision time :  85.7318115234375
Action time :  100.79644775390625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.773696899414062
-------------------------------
-------------------------------
model running time:  7.866208076477051
-------------------------------
-------------------------------
model running time:  26.063871383666992
-------------------------------
-------------------------------
model running time:  9.679871559143066
-------------------------------
-------------------------------
model running time:  25.86617660522461
-------------------------------
Vision time :  85.81251525878906
Action time :  109.45433807373047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.28108787536621
-------------------------------
-------------------------------
model running time:  7.813119888305664
-------------------------------
-------------------------------
model running time:  25.960416793823242
-------------------------------
-------------------------------
model running time:  9.672703742980957
-------------------------------
-------------------------------
model running time:  28.78976058959961
-------------------------------
Vision time :  85.76239776611328
Action time :  104.44287872314453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.168447494506836
-------------------------------
-------------------------------
model running time:  7.7946882247924805
-------------------------------
-------------------------------
model running time:  25.886720657348633
-------------------------------
-------------------------------
model running time:  9.656319618225098
-------------------------------
-------------------------------
model running time:  30.681087493896484
-------------------------------
Vision time :  85.74662780761719
Action time :  106.15900421142578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.63043212890625
-------------------------------
-------------------------------
model running time:  7.792640209197998
-------------------------------
-------------------------------
model running time:  25.92972755432129
-------------------------------
-------------------------------
model running time:  9.632767677307129
-------------------------------
-------------------------------
model running time:  25.840639114379883
-------------------------------
Vision time :  85.74777221679688
Action time :  101.80009460449219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.406015396118164
-------------------------------
-------------------------------
model running time:  7.787519931793213
-------------------------------
-------------------------------
model running time:  25.94713592529297
-------------------------------
-------------------------------
model running time:  9.576448440551758
-------------------------------
-------------------------------
model running time:  27.529216766357422
-------------------------------
Vision time :  85.75536346435547
Action time :  103.193603515625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.929279327392578
-------------------------------
-------------------------------
model running time:  7.863296031951904
-------------------------------
-------------------------------
model running time:  25.860095977783203
-------------------------------
-------------------------------
model running time:  9.632767677307129
-------------------------------
-------------------------------
model running time:  31.230976104736328
-------------------------------
Vision time :  85.76121520996094
Action time :  107.33875274658203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.995391845703125
-------------------------------
-------------------------------
model running time:  7.831615924835205
-------------------------------
-------------------------------
model running time:  25.72902488708496
-------------------------------
-------------------------------
model running time:  9.606143951416016
-------------------------------
-------------------------------
model running time:  31.320064544677734
-------------------------------
Vision time :  85.73219299316406
Action time :  106.20928192138672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.028160095214844


 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [02:32<00:14,  7.13s/it][A[A-------------------------------
-------------------------------
model running time:  7.817215919494629
-------------------------------
-------------------------------
model running time:  28.627967834472656
-------------------------------
-------------------------------
model running time:  9.61945629119873
-------------------------------
-------------------------------
model running time:  25.7423038482666
-------------------------------
Vision time :  85.73107147216797
Action time :  103.57657623291016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.172544479370117
-------------------------------
-------------------------------
model running time:  7.782271862030029
-------------------------------
-------------------------------
model running time:  29.883392333984375
-------------------------------
-------------------------------
model running time:  9.629728317260742
-------------------------------
-------------------------------
model running time:  25.763872146606445
-------------------------------
Vision time :  85.75827026367188
Action time :  105.01119995117188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.185855865478516
-------------------------------
-------------------------------
model running time:  7.774208068847656
-------------------------------
-------------------------------
model running time:  25.884544372558594
-------------------------------
-------------------------------
model running time:  9.607168197631836
-------------------------------
-------------------------------
model running time:  25.71980857849121
-------------------------------
Vision time :  85.79596710205078
Action time :  100.84544372558594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.151039123535156
-------------------------------
-------------------------------
model running time:  7.809023857116699
-------------------------------
-------------------------------
model running time:  33.886207580566406
-------------------------------
-------------------------------
model running time:  9.693183898925781
-------------------------------
-------------------------------
model running time:  25.794591903686523
-------------------------------
Vision time :  85.75775909423828
Action time :  109.17683410644531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.507423400878906
-------------------------------
-------------------------------
model running time:  7.8592000007629395
-------------------------------
-------------------------------
model running time:  31.124479293823242
-------------------------------
-------------------------------
model running time:  9.713664054870605
-------------------------------
-------------------------------
model running time:  26.001407623291016
-------------------------------
Vision time :  85.7557144165039
Action time :  107.18822479248047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.311872482299805
-------------------------------
-------------------------------
model running time:  7.795711994171143
-------------------------------
-------------------------------
model running time:  26.012672424316406
-------------------------------
-------------------------------
model running time:  9.644031524658203
-------------------------------
-------------------------------
model running time:  32.310272216796875
-------------------------------
Vision time :  85.74246215820312
Action time :  108.00438690185547
Trial 23 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.08345603942871
-------------------------------
-------------------------------
model running time:  7.788544178009033
-------------------------------
-------------------------------
model running time:  25.883647918701172
-------------------------------
-------------------------------
model running time:  9.669631958007812
-------------------------------
-------------------------------
model running time:  26.489887237548828
-------------------------------
Vision time :  85.7384033203125
Action time :  101.7775650024414
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.31488037109375
-------------------------------
-------------------------------
model running time:  7.897119998931885
-------------------------------
-------------------------------
model running time:  26.142719268798828
-------------------------------
-------------------------------
model running time:  9.780223846435547
-------------------------------
-------------------------------
model running time:  28.808191299438477
-------------------------------
Vision time :  85.77171325683594
Action time :  106.1560287475586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.11212730407715
-------------------------------


 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [02:34<00:05,  5.65s/it][A[A-------------------------------
model running time:  7.774208068847656
-------------------------------
-------------------------------
model running time:  25.88979148864746
-------------------------------
-------------------------------
model running time:  9.645055770874023
-------------------------------
-------------------------------
model running time:  25.774080276489258
-------------------------------
Vision time :  85.76870727539062
Action time :  101.1118392944336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.989696502685547
-------------------------------
-------------------------------
model running time:  7.915487766265869
-------------------------------
-------------------------------
model running time:  26.461183547973633
-------------------------------
-------------------------------
model running time:  9.769984245300293
-------------------------------
-------------------------------
model running time:  26.36288070678711
-------------------------------
Vision time :  85.77986907958984
Action time :  103.57350158691406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.7142391204834
-------------------------------
-------------------------------
model running time:  7.928832054138184
-------------------------------
-------------------------------
model running time:  26.34556770324707
-------------------------------
-------------------------------
model running time:  9.69638442993164
-------------------------------
-------------------------------
model running time:  32.33894348144531
-------------------------------
Vision time :  85.75440216064453
Action time :  108.91366577148438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.549375534057617
-------------------------------
-------------------------------
model running time:  7.915520191192627
-------------------------------
-------------------------------
model running time:  26.18060874938965
-------------------------------
-------------------------------
model running time:  9.670656204223633
-------------------------------
-------------------------------
model running time:  32.74854278564453
-------------------------------
Vision time :  85.72509002685547
Action time :  108.94131469726562
Trial 24 finished, success: tensor([True]), steps: 95
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.65894317626953
-------------------------------
-------------------------------
model running time:  7.8612799644470215
-------------------------------
-------------------------------
model running time:  28.16102409362793
-------------------------------
-------------------------------
model running time:  9.713791847229004
-------------------------------
-------------------------------
model running time:  26.216447830200195
-------------------------------
Vision time :  85.74626922607422
Action time :  105.57440185546875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.447999954223633
-------------------------------
-------------------------------
model running time:  7.875584125518799
-------------------------------
-------------------------------
model running time:  26.2860164642334
-------------------------------
-------------------------------
model running time:  9.73414421081543
-------------------------------
-------------------------------
model running time:  26.082304000854492
-------------------------------
Vision time :  85.76553344726562
Action time :  102.39488220214844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.436735153198242
-------------------------------
-------------------------------
model running time:  7.834559917449951
-------------------------------
-------------------------------
model running time:  26.274816513061523
-------------------------------
-------------------------------
model running time:  9.755647659301758
-------------------------------
-------------------------------
model running time:  27.082687377929688
-------------------------------
Vision time :  85.78697967529297
Action time :  103.3359375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.542207717895508
-------------------------------
-------------------------------
model running time:  7.8592000007629395
-------------------------------
-------------------------------
model running time:  26.190847396850586
-------------------------------
-------------------------------
model running time:  9.760767936706543
-------------------------------
-------------------------------
model running time:  32.39014434814453
-------------------------------
Vision time :  85.75218963623047
Action time :  108.71501159667969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.79270362854004
-------------------------------
-------------------------------
model running time:  7.90015983581543
-------------------------------
-------------------------------
model running time:  26.209375381469727
-------------------------------
-------------------------------
model running time:  9.72492790222168
-------------------------------
-------------------------------
model running time:  26.076160430908203
-------------------------------
Vision time :  85.76678466796875
Action time :  108.67097473144531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.658367156982422
-------------------------------
-------------------------------
model running time:  7.864319801330566
-------------------------------
-------------------------------
model running time:  31.7491512298584
-------------------------------
-------------------------------
model running time:  9.690112113952637
-------------------------------
-------------------------------
model running time:  25.998336791992188
-------------------------------
Vision time :  85.78601837158203
Action time :  108.9260482788086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.574399948120117
-------------------------------
-------------------------------
model running time:  7.895040035247803
-------------------------------
-------------------------------
model running time:  26.248191833496094
-------------------------------
-------------------------------
model running time:  9.715776443481445
-------------------------------
-------------------------------
model running time:  26.13043212890625
-------------------------------
Vision time :  85.75497436523438
Action time :  103.59894561767578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.660991668701172
-------------------------------
-------------------------------
model running time:  7.889920234680176
-------------------------------
-------------------------------
model running time:  30.3319034576416
-------------------------------
-------------------------------
model running time:  9.68505573272705
-------------------------------
-------------------------------
model running time:  26.12531280517578
-------------------------------
Vision time :  85.76310729980469
Action time :  106.71308898925781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.57811164855957
-------------------------------
-------------------------------
model running time:  7.920639991760254
-------------------------------
-------------------------------
model running time:  26.33216094970703
-------------------------------
-------------------------------
model running time:  9.672703742980957
-------------------------------
-------------------------------
model running time:  26.191871643066406
-------------------------------
Vision time :  85.76547241210938
Action time :  102.65599822998047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.395488739013672
-------------------------------
-------------------------------
model running time:  7.916543960571289
-------------------------------
-------------------------------
model running time:  26.275840759277344
-------------------------------
-------------------------------
model running time:  9.6430082321167
-------------------------------
-------------------------------
model running time:  26.224639892578125
-------------------------------
Vision time :  85.78169250488281
Action time :  106.31785583496094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.588287353515625
-------------------------------
-------------------------------
model running time:  7.886847972869873
-------------------------------
-------------------------------
model running time:  26.236928939819336
-------------------------------
-------------------------------
model running time:  9.713664054870605
-------------------------------
-------------------------------
model running time:  26.166271209716797
-------------------------------
Vision time :  85.76640319824219
Action time :  107.6305923461914
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.713151931762695
-------------------------------
-------------------------------
model running time:  7.818240165710449
-------------------------------
-------------------------------
model running time:  34.229248046875
-------------------------------
-------------------------------
model running time:  9.70963191986084
-------------------------------
-------------------------------
model running time:  26.179584503173828
-------------------------------
Vision time :  85.76687622070312
Action time :  110.66060638427734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.523775100708008
-------------------------------
-------------------------------
model running time:  7.902207851409912
-------------------------------
-------------------------------
model running time:  26.34048080444336
-------------------------------
-------------------------------
model running time:  9.71673583984375
-------------------------------
-------------------------------
model running time:  26.264575958251953
-------------------------------
Vision time :  85.7786865234375
Action time :  102.83417510986328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.541183471679688
-------------------------------
-------------------------------
model running time:  7.835648059844971
-------------------------------
-------------------------------
model running time:  26.19385528564453
-------------------------------
-------------------------------
model running time:  9.763839721679688
-------------------------------
-------------------------------
model running time:  26.193920135498047
-------------------------------
Vision time :  85.75788879394531
Action time :  104.21453094482422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.475648880004883
-------------------------------
-------------------------------
model running time:  7.926784038543701
-------------------------------
-------------------------------
model running time:  26.216447830200195
-------------------------------
-------------------------------
model running time:  9.659392356872559
-------------------------------
-------------------------------
model running time:  26.11712074279785
-------------------------------
Vision time :  85.76188659667969
Action time :  102.45734405517578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.666112899780273
-------------------------------
-------------------------------
model running time:  7.880767822265625
-------------------------------
-------------------------------
model running time:  26.2871036529541
-------------------------------
-------------------------------
model running time:  9.657343864440918
-------------------------------
-------------------------------
model running time:  26.086559295654297
-------------------------------
Vision time :  85.78665924072266
Action time :  102.71846771240234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.48486328125
-------------------------------
-------------------------------
model running time:  7.882751941680908
-------------------------------
-------------------------------
model running time:  26.272768020629883
-------------------------------
-------------------------------
model running time:  10.356639862060547
-------------------------------
-------------------------------
model running time:  26.204160690307617
-------------------------------
Vision time :  85.77648162841797
Action time :  104.38873291015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.606719970703125
-------------------------------
-------------------------------
model running time:  7.862271785736084
-------------------------------
-------------------------------
model running time:  26.260480880737305
-------------------------------
-------------------------------
model running time:  9.695232391357422
-------------------------------
-------------------------------
model running time:  26.218463897705078
-------------------------------
Vision time :  85.75286102294922
Action time :  106.32089233398438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.797183990478516
-------------------------------
-------------------------------
model running time:  7.876607894897461
-------------------------------
-------------------------------
model running time:  26.35980796813965
-------------------------------
-------------------------------
model running time:  9.704319953918457
-------------------------------
-------------------------------
model running time:  26.97113609313965
-------------------------------
Vision time :  85.76461029052734
Action time :  106.9148178100586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.51599884033203
-------------------------------
-------------------------------
model running time:  7.8745598793029785
-------------------------------
-------------------------------
model running time:  26.35264015197754
-------------------------------
-------------------------------
model running time:  9.687040328979492
-------------------------------
-------------------------------
model running time:  26.219648361206055
-------------------------------
Vision time :  85.80290985107422
Action time :  110.62067413330078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.197120666503906
-------------------------------
-------------------------------
model running time:  7.791615962982178
-------------------------------
-------------------------------
model running time:  26.05379295349121
-------------------------------
-------------------------------
model running time:  9.683008193969727
-------------------------------
-------------------------------
model running time:  

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [02:42<00:00,  6.58s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [02:42<00:00,  6.52s/it]

 10%|â–ˆ         | 1/10 [02:42<24:26, 162.99s/it][A26.033151626586914
-------------------------------
Vision time :  85.76140594482422
Action time :  101.67097473144531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.71116828918457
-------------------------------
-------------------------------
model running time:  7.82044792175293
-------------------------------
-------------------------------
model running time:  26.083328247070312
-------------------------------
-------------------------------
model running time:  9.664511680603027
-------------------------------
-------------------------------
model running time:  25.916383743286133
-------------------------------
Vision time :  85.77776336669922
Action time :  102.74816131591797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.298816680908203
-------------------------------
-------------------------------
model running time:  7.8592000007629395
-------------------------------
-------------------------------
model running time:  26.32294464111328
-------------------------------
-------------------------------
model running time:  9.731072425842285
-------------------------------
-------------------------------
model running time:  28.094463348388672
-------------------------------
Vision time :  85.83462524414062
Action time :  105.39008331298828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.662015914916992
-------------------------------
-------------------------------
model running time:  7.953567981719971
-------------------------------
-------------------------------
model running time:  26.160127639770508
-------------------------------
-------------------------------
model running time:  9.70035171508789
-------------------------------
-------------------------------
model running time:  26.036224365234375
-------------------------------
Vision time :  85.75945281982422
Action time :  102.50956726074219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.591360092163086
-------------------------------
-------------------------------
model running time:  7.875584125518799
-------------------------------
-------------------------------
model running time:  27.617279052734375
-------------------------------
-------------------------------
model running time:  16.112640380859375
-------------------------------
-------------------------------
model running time:  26.355712890625
-------------------------------
Vision time :  85.76255798339844
Action time :  110.59302520751953
Trial 25 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
policy.alpha = 1.0policy.temp = 0.01
Success rate: 48.0%
Running trial with alpha=1.0, temp=0.01. Re-seeding with 20241201.


  0%|          | 0/25 [00:00<?, ?it/s][A[Abefore pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.582143783569336
-------------------------------
-------------------------------
model running time:  7.835648059844971
-------------------------------
-------------------------------
model running time:  31.17568016052246
-------------------------------
-------------------------------
model running time:  9.721887588500977
-------------------------------
-------------------------------
model running time:  26.207231521606445
-------------------------------
Vision time :  85.78876495361328
Action time :  107.652099609375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.235008239746094
-------------------------------
-------------------------------
model running time:  7.812032222747803
-------------------------------
-------------------------------
model running time:  26.187904357910156
-------------------------------
-------------------------------
model running time:  9.676799774169922
-------------------------------
-------------------------------
model running time:  31.706111907958984
-------------------------------
Vision time :  85.77804565429688
Action time :  108.548095703125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.399871826171875
-------------------------------
-------------------------------
model running time:  7.796735763549805
-------------------------------
-------------------------------
model running time:  26.137632369995117
-------------------------------
-------------------------------
model running time:  10.64140796661377
-------------------------------
-------------------------------
model running time:  26.399744033813477
-------------------------------
Vision time :  85.84569549560547
Action time :  103.59705352783203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.421344757080078
-------------------------------
-------------------------------
model running time:  7.827455997467041
-------------------------------
-------------------------------
model running time:  26.150911331176758
-------------------------------
-------------------------------
model running time:  9.632767677307129
-------------------------------
-------------------------------
model running time:  25.938976287841797
-------------------------------
Vision time :  85.75267028808594
Action time :  101.97392272949219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.35772705078125
-------------------------------
-------------------------------
model running time:  7.805952072143555
-------------------------------
-------------------------------
model running time:  26.182783126831055
-------------------------------
-------------------------------
model running time:  9.696255683898926
-------------------------------
-------------------------------
model running time:  26.04265594482422
-------------------------------
Vision time :  85.74201965332031
Action time :  102.09193420410156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.615936279296875
-------------------------------
-------------------------------
model running time:  7.862271785736084
-------------------------------
-------------------------------
model running time:  26.183679580688477
-------------------------------
-------------------------------
model running time:  9.675775527954102
-------------------------------
-------------------------------
model running time:  26.013696670532227
-------------------------------
Vision time :  85.74301147460938
Action time :  110.51634979248047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.3189754486084
-------------------------------
-------------------------------
model running time:  7.875584125518799
-------------------------------
-------------------------------
model running time:  35.40070343017578
-------------------------------
-------------------------------
model running time:  9.731072425842285
-------------------------------
-------------------------------
model running time:  25.89081573486328
-------------------------------
Vision time :  85.77200317382812
Action time :  111.07328033447266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.333375930786133
-------------------------------
-------------------------------
model running time:  7.884799957275391
-------------------------------
-------------------------------
model running time:  26.111967086791992
-------------------------------
-------------------------------
model running time:  9.745408058166504
-------------------------------
-------------------------------
model running time:  25.991167068481445
-------------------------------
Vision time :  85.77462768554688
Action time :  108.9250259399414
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.29644775390625
-------------------------------
-------------------------------
model running time:  7.809023857116699
-------------------------------
-------------------------------
model running time:  26.049535751342773
-------------------------------
-------------------------------
model running time:  9.634943962097168
-------------------------------
-------------------------------
model running time:  30.942304611206055
-------------------------------
Vision time :  85.76934051513672
Action time :  106.71820831298828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.52070426940918
-------------------------------
-------------------------------
model running time:  7.8151679039001465
-------------------------------
-------------------------------
model running time:  26.063871383666992
-------------------------------
-------------------------------
model running time:  9.607168197631836
-------------------------------
-------------------------------
model running time:  25.803775787353516
-------------------------------
Vision time :  85.7799072265625
Action time :  101.83987426757812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.372224807739258
-------------------------------
-------------------------------
model running time:  7.763967990875244
-------------------------------
-------------------------------
model running time:  31.101951599121094
-------------------------------
-------------------------------
model running time:  9.703424453735352
-------------------------------
-------------------------------
model running time:  25.772031784057617
-------------------------------
Vision time :  85.78710174560547
Action time :  106.66905975341797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.45417594909668
-------------------------------
-------------------------------
model running time:  7.821311950683594
-------------------------------
-------------------------------
model running time:  34.09715270996094
-------------------------------
-------------------------------
model running time:  9.70956802368164
-------------------------------
-------------------------------
model running time:  26.099712371826172
-------------------------------
Vision time :  85.77474975585938
Action time :  110.06873321533203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.660127639770508
-------------------------------
-------------------------------
model running time:  7.8079681396484375
-------------------------------
-------------------------------
model running time:  25.94918441772461
-------------------------------
-------------------------------
model running time:  9.603072166442871
-------------------------------
-------------------------------
model running time:  25.70342445373535
-------------------------------
Vision time :  85.7840347290039
Action time :  101.570556640625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.48486328125
-------------------------------
-------------------------------
model running time:  7.911424160003662
-------------------------------
-------------------------------
model running time:  29.34681510925293
-------------------------------
-------------------------------
model running time:  9.720831871032715
-------------------------------
-------------------------------
model running time:  25.871360778808594
-------------------------------
Vision time :  85.77954864501953
Action time :  105.28160095214844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.95792007446289
-------------------------------
-------------------------------
model running time:  7.836671829223633
-------------------------------
-------------------------------
model running time:  26.092544555664062
-------------------------------
-------------------------------
model running time:  9.70751953125
-------------------------------
-------------------------------
model running time:  25.845632553100586
-------------------------------
Vision time :  85.77302551269531
Action time :  104.21043395996094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.284160614013672
-------------------------------
-------------------------------
model running time:  7.816192150115967
-------------------------------
-------------------------------
model running time:  25.90617561340332
-------------------------------
-------------------------------
model running time:  9.61638355255127
-------------------------------
-------------------------------
model running time:  25.76896095275879
-------------------------------
Vision time :  85.75641632080078
Action time :  101.1435546875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.612863540649414
-------------------------------
-------------------------------
model running time:  7.9206719398498535
-------------------------------
-------------------------------
model running time:  26.33318328857422
-------------------------------
-------------------------------
model running time:  9.67471981048584
-------------------------------
-------------------------------
model running time:  26.177536010742188
-------------------------------
Vision time :  85.75823974609375
Action time :  102.69798278808594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.69171142578125
-------------------------------
-------------------------------
model running time:  7.817215919494629
-------------------------------
-------------------------------
model running time:  26.14169692993164
-------------------------------
-------------------------------
model running time:  9.703359603881836
-------------------------------
-------------------------------
model running time:  26.03228759765625
-------------------------------
Vision time :  85.79692840576172
Action time :  102.2033920288086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.348703384399414
-------------------------------
-------------------------------
model running time:  7.812096118927002
-------------------------------
-------------------------------
model running time:  26.52262306213379
-------------------------------
-------------------------------
model running time:  9.714688301086426
-------------------------------
-------------------------------
model running time:  26.269535064697266
-------------------------------
Vision time :  85.77910614013672
Action time :  102.9386215209961
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.88934326171875
-------------------------------
-------------------------------
model running time:  7.917568206787109
-------------------------------
-------------------------------
model running time:  26.385408401489258
-------------------------------
-------------------------------
model running time:  12.016639709472656
-------------------------------
-------------------------------
model running time:  26.323871612548828
-------------------------------
Vision time :  85.74368286132812
Action time :  105.65631866455078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.573888778686523
-------------------------------
-------------------------------
model running time:  7.844895839691162
-------------------------------
-------------------------------
model running time:  32.39628982543945
-------------------------------
-------------------------------
model running time:  9.678848266601562
-------------------------------
-------------------------------
model running time:  26.3239688873291
-------------------------------
Vision time :  85.7590103149414
Action time :  108.7856674194336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.780799865722656
-------------------------------
-------------------------------
model running time:  7.863296031951904
-------------------------------
-------------------------------
model running time:  26.35366439819336
-------------------------------
-------------------------------
model running time:  9.7259521484375
-------------------------------
-------------------------------
model running time:  26.161151885986328
-------------------------------
Vision time :  85.7837142944336
Action time :  102.91712188720703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.53606414794922
-------------------------------
-------------------------------
model running time:  7.8263678550720215
-------------------------------
-------------------------------
model running time:  34.737152099609375
-------------------------------
-------------------------------
model running time:  10.105855941772461
-------------------------------
-------------------------------
model running time:  26.204160690307617
-------------------------------
Vision time :  85.77200317382812
Action time :  111.36204528808594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.585407257080078
-------------------------------
-------------------------------
model running time:  7.911424160003662
-------------------------------
-------------------------------
model running time:  26.374143600463867
-------------------------------
-------------------------------
model running time:  9.692159652709961
-------------------------------
-------------------------------
model running time:  26.179584503173828
-------------------------------
Vision time :  85.78508758544922
Action time :  107.77804565429688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048


  4%|â–         | 1/25 [00:08<03:32,  8.84s/it][A[A

  8%|â–Š         | 2/25 [00:11<01:57,  5.12s/it][A[A-------------------------------
model running time:  24.51148796081543
-------------------------------
-------------------------------
model running time:  7.866528034210205
-------------------------------
-------------------------------
model running time:  26.28607940673828
-------------------------------
-------------------------------
model running time:  9.665535926818848
-------------------------------
-------------------------------
model running time:  26.185855865478516
-------------------------------
Vision time :  85.76461029052734
Action time :  102.52799987792969
Trial 1 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.45827293395996
-------------------------------
-------------------------------
model running time:  7.881728172302246
-------------------------------
-------------------------------
model running time:  30.256128311157227
-------------------------------
-------------------------------
model running time:  9.645055770874023
-------------------------------
-------------------------------
model running time:  26.116960525512695
-------------------------------
Vision time :  85.76588439941406
Action time :  106.26048278808594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.455167770385742
-------------------------------
-------------------------------
model running time:  7.845888137817383
-------------------------------
-------------------------------
model running time:  26.31270408630371
-------------------------------
-------------------------------
model running time:  9.687135696411133
-------------------------------
-------------------------------
model running time:  29.307903289794922
-------------------------------
Vision time :  85.7784652709961
Action time :  105.62137603759766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.412160873413086
-------------------------------
-------------------------------
model running time:  10.106880187988281
-------------------------------
-------------------------------
model running time:  32.154624938964844
-------------------------------
-------------------------------
model running time:  9.637887954711914
-------------------------------
-------------------------------
model running time:  26.027008056640625
-------------------------------
Vision time :  85.76156616210938
Action time :  113.9947509765625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  36.325374603271484
-------------------------------
-------------------------------
model running time:  11.43295955657959
-------------------------------
-------------------------------
model running time:  38.308895111083984
-------------------------------
-------------------------------
model running time:  25.547775268554688
-------------------------------
-------------------------------
model running time:  39.77113723754883
-------------------------------
Vision time :  85.74006652832031
Action time :  163.2163848876953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.30259132385254
-------------------------------
-------------------------------
model running time:  13.490303993225098
-------------------------------
-------------------------------
model running time:  26.035200119018555
-------------------------------
-------------------------------
model running time:  9.660415649414062
-------------------------------
-------------------------------
model running time:  25.892864227294922
-------------------------------
Vision time :  86.10848236083984
Action time :  107.2168960571289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.416383743286133
-------------------------------
-------------------------------
model running time:  7.822368144989014
-------------------------------
-------------------------------
model running time:  25.910207748413086
-------------------------------
-------------------------------
model running time:  9.82528018951416
-------------------------------
-------------------------------
model running time:  25.808895111083984
-------------------------------
Vision time :  85.76515197753906
Action time :  101.5367660522461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.067392349243164
-------------------------------
-------------------------------
model running time:  7.84281587600708
-------------------------------
-------------------------------
model running time:  25.942880630493164
-------------------------------
-------------------------------
model running time:  9.690208435058594
-------------------------------
-------------------------------
model running time:  25.8786563873291
-------------------------------
Vision time :  85.75392150878906
Action time :  104.1377944946289
Trial 2 finished, success: tensor([True]), steps: 109
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416


 12%|â–ˆâ–        | 3/25 [00:13<01:23,  3.81s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.180736541748047
-------------------------------
-------------------------------
model running time:  7.798783779144287
-------------------------------
-------------------------------
model running time:  26.657791137695312
-------------------------------
-------------------------------
model running time:  9.704383850097656
-------------------------------
-------------------------------
model running time:  31.143936157226562
-------------------------------
Vision time :  85.75033569335938
Action time :  107.28345489501953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.30259132385254
-------------------------------
-------------------------------
model running time:  7.841792106628418
-------------------------------
-------------------------------
model running time:  26.167295455932617
-------------------------------
-------------------------------
model running time:  9.703424453735352
-------------------------------
-------------------------------
model running time:  25.87238311767578
-------------------------------
Vision time :  85.77926635742188
Action time :  101.70777893066406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.624128341674805
-------------------------------
-------------------------------
model running time:  7.855967998504639
-------------------------------
-------------------------------
model running time:  26.185728073120117
-------------------------------
-------------------------------
model running time:  9.743359565734863
-------------------------------
-------------------------------
model running time:  30.093311309814453
-------------------------------
Vision time :  85.76809692382812
Action time :  106.4642562866211
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.559520721435547
-------------------------------
-------------------------------
model running time:  7.896063804626465
-------------------------------
-------------------------------
model running time:  30.282751083374023
-------------------------------
-------------------------------
model running time:  9.712639808654785
-------------------------------
-------------------------------
model running time:  26.275840759277344
-------------------------------
Vision time :  85.77113342285156
Action time :  106.72118377685547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.656896591186523
-------------------------------
-------------------------------
model running time:  7.85100793838501
-------------------------------
-------------------------------
model running time:  25.95123291015625
-------------------------------
-------------------------------
model running time:  9.658528327941895
-------------------------------
-------------------------------
model running time:  25.91744041442871
-------------------------------
Vision time :  85.7496337890625
Action time :  101.86943817138672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.381439208984375
-------------------------------
-------------------------------
model running time:  7.861248016357422
-------------------------------
-------------------------------
model running time:  26.066944122314453
-------------------------------
-------------------------------
model running time:  9.62764835357666
-------------------------------
-------------------------------
model running time:  25.95840072631836
-------------------------------
Vision time :  85.79491424560547
Action time :  101.90233612060547
Trial 3 finished, success: tensor([True]), steps: 96
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.242624282836914
-------------------------------
-------------------------------
model running time:  7.908192157745361
-------------------------------
-------------------------------
model running time:  26.468351364135742
-------------------------------
-------------------------------
model running time:  9.654272079467773
-------------------------------
-------------------------------
model running time:  26.220544815063477
-------------------------------
Vision time :  85.80131530761719
Action time :  103.68204498291016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.272512435913086
-------------------------------
-------------------------------
model running time:  7.8755202293396
-------------------------------
-------------------------------
model running time:  26.395647048950195
-------------------------------
-------------------------------
model running time:  9.656319618225098
-------------------------------
-------------------------------
model running time:  28.711936950683594
-------------------------------
Vision time :  86.54441833496094
Action time :  110.75977325439453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048


 16%|â–ˆâ–Œ        | 4/25 [00:16<01:08,  3.28s/it][A[A-------------------------------
model running time:  24.799327850341797
-------------------------------
-------------------------------
model running time:  7.820127964019775
-------------------------------
-------------------------------
model running time:  26.341312408447266
-------------------------------
-------------------------------
model running time:  9.689087867736816
-------------------------------
-------------------------------
model running time:  26.11622428894043
-------------------------------
Vision time :  85.76009368896484
Action time :  102.79219055175781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.77452850341797
-------------------------------
-------------------------------
model running time:  7.848959922790527
-------------------------------
-------------------------------
model running time:  26.444704055786133
-------------------------------
-------------------------------
model running time:  9.6245756149292
-------------------------------
-------------------------------
model running time:  26.09459114074707
-------------------------------
Vision time :  85.84076690673828
Action time :  106.80115509033203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.696895599365234
-------------------------------
-------------------------------
model running time:  7.8008317947387695
-------------------------------
-------------------------------
model running time:  26.24015998840332
-------------------------------
-------------------------------
model running time:  14.414719581604004
-------------------------------
-------------------------------
model running time:  26.16316795349121
-------------------------------
Vision time :  85.80054473876953
Action time :  107.54656219482422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.568832397460938
-------------------------------
-------------------------------
model running time:  7.821311950683594
-------------------------------
-------------------------------
model running time:  26.459104537963867
-------------------------------
-------------------------------
model running time:  9.660415649414062
-------------------------------
-------------------------------
model running time:  26.13555145263672
-------------------------------
Vision time :  85.75615692138672
Action time :  102.67648315429688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.896480560302734
-------------------------------
-------------------------------
model running time:  7.875584125518799
-------------------------------
-------------------------------
model running time:  26.50726318359375
-------------------------------
-------------------------------
model running time:  9.751551628112793
-------------------------------
-------------------------------
model running time:  26.33011245727539
-------------------------------
Vision time :  85.78953552246094
Action time :  103.4076156616211
Trial 4 finished, success: tensor([True]), steps: 110
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.994815826416016
-------------------------------
-------------------------------
model running time:  7.831552028656006
-------------------------------
-------------------------------
model running time:  26.421247482299805
-------------------------------
-------------------------------
model running time:  9.667584419250488
-------------------------------
-------------------------------
model running time:  33.712127685546875
-------------------------------
Vision time :  85.74752044677734
Action time :  110.79987335205078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.7326717376709
-------------------------------
-------------------------------
model running time:  11.472895622253418
-------------------------------
-------------------------------
model running time:  26.55027198791504
-------------------------------
-------------------------------
model running time:  9.792511940002441
-------------------------------
-------------------------------
model running time:  26.30246353149414
-------------------------------
Vision time :  85.77788543701172
Action time :  106.893310546875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.326143264770508
-------------------------------
-------------------------------
model running time:  14.37491226196289
-------------------------------
-------------------------------
model running time:  26.439680099487305
-------------------------------
-------------------------------
model running time:  9.690112113952637
-------------------------------
-------------------------------
model running time:  26.259456634521484
-------------------------------
Vision time :  85.74793243408203
Action time :  108.86656188964844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.724384307861328
-------------------------------
-------------------------------
model running time:  7.8919677734375
-------------------------------
-------------------------------
model running time:  26.31679916381836
-------------------------------
-------------------------------
model running time:  9.686112403869629
-------------------------------
-------------------------------
model running time:  26.192895889282227
-------------------------------
Vision time :  86.5600357055664
Action time :  102.80032348632812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.54729652404785
-------------------------------
-------------------------------
model running time:  7.871488094329834
-------------------------------
-------------------------------
model running time:  26.259456634521484
-------------------------------
-------------------------------
model running time:  9.708415985107422
-------------------------------
-------------------------------
model running time:  34.85286331176758
-------------------------------
Vision time :  85.740478515625
Action time :  111.16236877441406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.823680877685547
-------------------------------
-------------------------------
model running time:  7.886752128601074
-------------------------------
-------------------------------
model running time:  26.30348777770996
-------------------------------
-------------------------------
model running time:  9.71571159362793
-------------------------------
-------------------------------
model running time:  26.195999145507812
-------------------------------
Vision time :  85.78304290771484
Action time :  104.67533111572266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.631744384765625
-------------------------------
-------------------------------
model running time:  7.851039886474609
-------------------------------
-------------------------------
model running time:  26.33216094970703
-------------------------------
-------------------------------
model running time:  9.713664054870605
-------------------------------
-------------------------------
model running time:  26.19491195678711
-------------------------------
Vision time :  85.76959991455078
Action time :  103.63916778564453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.027584075927734
-------------------------------
-------------------------------
model running time:  7.861248016357422
-------------------------------
-------------------------------
model running time:  31.625215530395508
-------------------------------
-------------------------------
model running time:  9.653375625610352
-------------------------------
-------------------------------
model running time:  26.16320037841797
-------------------------------
Vision time :  85.80233764648438
Action time :  108.54195404052734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.565759658813477
-------------------------------
-------------------------------
model running time:  7.797760009765625
-------------------------------
-------------------------------
model running time:  26.206207275390625
-------------------------------
-------------------------------
model running time:  9.639936447143555
-------------------------------
-------------------------------
model running time:  26.13043212890625
-------------------------------
Vision time :  85.78067016601562
Action time :  104.05171203613281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.673152923583984
-------------------------------
-------------------------------
model running time:  7.831552028656006
-------------------------------
-------------------------------
model running time:  26.231807708740234
-------------------------------
-------------------------------
model running time:  9.714688301086426
-------------------------------
-------------------------------
model running time:  26.083328247070312
-------------------------------
Vision time :  85.77327728271484
Action time :  102.56690979003906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.438207626342773
-------------------------------
-------------------------------
model running time:  7.861120223999023
-------------------------------
-------------------------------
model running time:  26.3055362701416
-------------------------------
-------------------------------
model running time:  9.667584419250488
-------------------------------
-------------------------------
model running time:  26.174463272094727
-------------------------------
Vision time :  85.78530883789062
Action time :  103.29804992675781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.46028709411621
-------------------------------
-------------------------------
model running time:  7.8672637939453125
-------------------------------
-------------------------------
model running time:  26.172576904296875
-------------------------------
-------------------------------
model running time:  9.637887954711914
-------------------------------
-------------------------------
model running time:  27.193344116210938
-------------------------------
Vision time :  85.77526092529297
Action time :  103.20076751708984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.71116828918457
-------------------------------
-------------------------------
model running time:  7.866367816925049
-------------------------------
-------------------------------
model running time:  26.3055362701416
-------------------------------
-------------------------------
model running time:  9.682944297790527
-------------------------------
-------------------------------
model running time:  26.376192092895508
-------------------------------
Vision time :  85.77043151855469
Action time :  102.94374084472656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.72345542907715
-------------------------------
-------------------------------
model running time:  7.905280113220215
-------------------------------
-------------------------------
model running time:  26.3372802734375
-------------------------------
-------------------------------
model running time:  9.70854377746582
-------------------------------
-------------------------------
model running time:  26.15603256225586
-------------------------------
Vision time :  85.74857330322266
Action time :  105.6204833984375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.555519104003906
-------------------------------
-------------------------------
model running time:  7.895040035247803
-------------------------------
-------------------------------
model running time:  26.309471130371094
-------------------------------
-------------------------------
model running time:  9.722880363464355
-------------------------------
-------------------------------
model running time:  26.167295455932617
-------------------------------
Vision time :  85.75465393066406
Action time :  102.71641540527344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.781919479370117
-------------------------------
-------------------------------
model running time:  7.808000087738037
-------------------------------
-------------------------------
model running time:  26.246143341064453
-------------------------------
-------------------------------
model running time:  9.682944297790527
-------------------------------
-------------------------------
model running time:  26.189823150634766
-------------------------------
Vision time :  85.7708511352539
Action time :  102.74508666992188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.427520751953125
-------------------------------
-------------------------------
model running time:  7.83139181137085
-------------------------------
-------------------------------
model running time:  26.177536010742188
-------------------------------
-------------------------------
model running time:  9.650176048278809
-------------------------------
-------------------------------
model running time:  30.653440475463867
-------------------------------
Vision time :  87.01923370361328
Action time :  108.08013153076172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.70809555053711
-------------------------------
-------------------------------
model running time:  7.90118408203125
-------------------------------
-------------------------------
model running time:  26.187776565551758
-------------------------------
-------------------------------
model running time:  9.659392356872559
-------------------------------
-------------------------------
model running time:  26.048511505126953
-------------------------------
Vision time :  85.76204681396484
Action time :  102.6111068725586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.49715232849121
-------------------------------
-------------------------------
model running time:  7.884799957275391
-------------------------------
-------------------------------
model running time:  26.187776565551758
-------------------------------
-------------------------------
model running time:  9.665535926818848
-------------------------------
-------------------------------
model running time:  30.073856353759766
-------------------------------
Vision time :  85.77420806884766
Action time :  106.28300476074219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.68659210205078
-------------------------------
-------------------------------
model running time:  7.853055953979492
-------------------------------
-------------------------------
model running time:  26.16320037841797
-------------------------------
-------------------------------
model running time:  

 20%|â–ˆâ–ˆ        | 5/25 [00:23<01:37,  4.87s/it][A[A9.644031524658203
-------------------------------
-------------------------------
model running time:  26.0894718170166
-------------------------------
Vision time :  85.77433776855469
Action time :  102.44710540771484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.463359832763672
-------------------------------
-------------------------------
model running time:  7.869344234466553
-------------------------------
-------------------------------
model running time:  26.229759216308594
-------------------------------
-------------------------------
model running time:  9.674816131591797
-------------------------------
-------------------------------
model running time:  30.95142364501953
-------------------------------
Vision time :  85.76201629638672
Action time :  107.11654663085938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.701824188232422
-------------------------------
-------------------------------
model running time:  7.8815999031066895
-------------------------------
-------------------------------
model running time:  26.296384811401367
-------------------------------
-------------------------------
model running time:  9.687040328979492
-------------------------------
-------------------------------
model running time:  26.031103134155273
-------------------------------
Vision time :  85.74642944335938
Action time :  102.82077026367188
Trial 5 finished, success: tensor([True]), steps: 338
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.414207458496094
-------------------------------
-------------------------------
model running time:  7.878655910491943
-------------------------------
-------------------------------
model running time:  29.134912490844727
-------------------------------
-------------------------------
model running time:  9.658368110656738
-------------------------------
-------------------------------
model running time:  25.986047744750977
-------------------------------
Vision time :  85.78870391845703
Action time :  105.09107208251953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.481216430664062
-------------------------------
-------------------------------
model running time:  7.917568206787109
-------------------------------
-------------------------------
model running time:  31.123455047607422
-------------------------------
-------------------------------
model running time:  9.693280220031738
-------------------------------
-------------------------------
model running time:  26.046464920043945
-------------------------------
Vision time :  85.81651306152344
Action time :  108.29926300048828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.406015396118164
-------------------------------
-------------------------------
model running time:  7.861248016357422
-------------------------------
-------------------------------
model running time:  26.068992614746094
-------------------------------
-------------------------------
model running time:  9.646080017089844
-------------------------------
-------------------------------
model running time:  32.02764892578125
-------------------------------
Vision time :  85.79289245605469
Action time :  107.94905853271484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.33843231201172
-------------------------------
-------------------------------
model running time:  7.83462381362915
-------------------------------
-------------------------------
model running time:  26.193952560424805
-------------------------------
-------------------------------
model running time:  9.677824020385742
-------------------------------
-------------------------------
model running time:  35.66396713256836
-------------------------------
Vision time :  85.79542541503906
Action time :  111.46326446533203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.933439254760742
-------------------------------
-------------------------------
model running time:  7.825407981872559
-------------------------------
-------------------------------
model running time:  26.204160690307617
-------------------------------
-------------------------------
model running time:  9.680895805358887
-------------------------------
-------------------------------
model running time:  26.050559997558594
-------------------------------
Vision time :  85.78534698486328
Action time :  109.7676773071289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.586240768432617
-------------------------------
-------------------------------
model running time:  7.833600044250488
-------------------------------
-------------------------------
model running time:  30.717952728271484
-------------------------------
-------------------------------
model running time:  9.657343864440918
-------------------------------
-------------------------------
model running time:  25.92767906188965
-------------------------------
Vision time :  85.77468872070312
Action time :  106.8921890258789
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.37830352783203
-------------------------------
-------------------------------
model running time:  7.856128215789795
-------------------------------
-------------------------------
model running time:  26.16217613220215
-------------------------------
-------------------------------
model running time:  9.686112403869629
-------------------------------
-------------------------------
model running time:  26.039295196533203
-------------------------------
Vision time :  85.78562927246094
Action time :  111.02003479003906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.653823852539062
-------------------------------
-------------------------------
model running time:  7.912447929382324
-------------------------------
-------------------------------
model running time:  26.46620750427246
-------------------------------
-------------------------------
model running time:  9.73516845703125
-------------------------------
-------------------------------
model running time:  30.017536163330078
-------------------------------
Vision time :  85.74540710449219
Action time :  106.80115509033203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.593408584594727
-------------------------------
-------------------------------
model running time:  7.856128215789795
-------------------------------
-------------------------------
model running time:  26.191871643066406
-------------------------------
-------------------------------
model running time:  9.676799774169922
-------------------------------
-------------------------------
model running time:  25.93791961669922
-------------------------------
Vision time :  85.8087387084961
Action time :  102.23616027832031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.79408073425293
-------------------------------
-------------------------------
model running time:  7.845888137817383
-------------------------------
-------------------------------
model running time:  26.38323211669922
-------------------------------
-------------------------------
model running time:  11.692031860351562
-------------------------------
-------------------------------
model running time:  26.191871643066406
-------------------------------
Vision time :  85.78243255615234
Action time :  104.98662567138672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.74015998840332
-------------------------------
-------------------------------
model running time:  7.85100793838501
-------------------------------
-------------------------------
model running time:  26.427391052246094
-------------------------------
-------------------------------
model running time:  9.749504089355469
-------------------------------
-------------------------------
model running time:  26.292320251464844
-------------------------------
Vision time :  85.80697631835938
Action time :  106.10377502441406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.604671478271484
-------------------------------
-------------------------------
model running time:  7.889920234680176
-------------------------------
-------------------------------
model running time:  26.24300765991211
-------------------------------
-------------------------------
model running time:  9.680895805358887
-------------------------------
-------------------------------
model running time:  26.015743255615234
-------------------------------
Vision time :  85.78892517089844
Action time :  107.325439453125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.99135971069336
-------------------------------
-------------------------------
model running time:  7.811071872711182
-------------------------------
-------------------------------
model running time:  26.373119354248047
-------------------------------
-------------------------------
model running time:  9.678848266601562
-------------------------------
-------------------------------
model running time:  26.09663963317871
-------------------------------
Vision time :  85.73225402832031
Action time :  108.8911361694336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.976383209228516
-------------------------------
-------------------------------
model running time:  7.897119998931885
-------------------------------
-------------------------------
model running time:  26.34137535095215
-------------------------------
-------------------------------
model running time:  9.640959739685059
-------------------------------
-------------------------------
model running time:  36.842529296875
-------------------------------
Vision time :  85.76521301269531
Action time :  113.80326080322266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.05958366394043
-------------------------------
-------------------------------
model running time:  7.847904205322266
-------------------------------
-------------------------------
model running time:  26.360767364501953
-------------------------------
-------------------------------
model running time:  9.668607711791992
-------------------------------
-------------------------------
model running time:  28.32486343383789
-------------------------------
Vision time :  85.75421142578125
Action time :  110.06566619873047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.645631790161133
-------------------------------
-------------------------------
model running time:  7.857151985168457
-------------------------------
-------------------------------
model running time:  26.28505516052246
-------------------------------
-------------------------------
model running time:  9.7259521484375
-------------------------------
-------------------------------
model running time:  29.61408042907715
-------------------------------
Vision time :  85.75273895263672
Action time :  106.08332824707031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.374271392822266
-------------------------------
-------------------------------
model running time:  7.846879959106445
-------------------------------
-------------------------------
model running time:  34.140289306640625
-------------------------------
-------------------------------
model running time:  9.679871559143066
-------------------------------
-------------------------------
model running time:  26.149887084960938
-------------------------------
Vision time :  85.73331451416016
Action time :  110.0574722290039
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.77452850341797
-------------------------------
-------------------------------
model running time:  7.889920234680176
-------------------------------
-------------------------------
model running time:  26.31372833251953
-------------------------------
-------------------------------
model running time:  9.710495948791504
-------------------------------
-------------------------------
model running time:  29.646751403808594
-------------------------------
Vision time :  87.55773162841797
Action time :  106.30451202392578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.30463981628418
-------------------------------
-------------------------------
model running time:  7.798655986785889
-------------------------------
-------------------------------
model running time:  26.18060874938965
-------------------------------
-------------------------------
model running time:  9.666560173034668
-------------------------------
-------------------------------
model running time:  26.036224365234375
-------------------------------
Vision time :  85.77228546142578
Action time :  101.93612670898438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.33024024963379
-------------------------------
-------------------------------
model running time:  7.803904056549072
-------------------------------
-------------------------------
model running time:  30.95542335510254
-------------------------------
-------------------------------
model running time:  9.63584041595459
-------------------------------
-------------------------------
model running time:  25.7740478515625
-------------------------------
Vision time :  85.75981140136719
Action time :  106.36492919921875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.389631271362305
-------------------------------
-------------------------------
model running time:  7.7803521156311035
-------------------------------
-------------------------------
model running time:  26.048479080200195
-------------------------------
-------------------------------
model running time:  9.671680450439453
-------------------------------
-------------------------------
model running time:  25.68499183654785
-------------------------------
Vision time :  85.7615966796875
Action time :  101.4302749633789
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.358911514282227
-------------------------------
-------------------------------
model running time:  7.8151679039001465
-------------------------------
-------------------------------
model running time:  25.96566390991211
-------------------------------
-------------------------------
model running time:  9.6430082321167
-------------------------------
-------------------------------
model running time:  26.011648178100586
-------------------------------
Vision time :  85.79363250732422
Action time :  104.22169494628906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 24%|â–ˆâ–ˆâ–       | 6/25 [00:32<01:58,  6.21s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.49612808227539
-------------------------------
-------------------------------
model running time:  16.497663497924805
-------------------------------
-------------------------------
model running time:  26.247167587280273
-------------------------------
-------------------------------
model running time:  9.6245756149292
-------------------------------
-------------------------------
model running time:  25.784320831298828
-------------------------------
Vision time :  85.77420806884766
Action time :  110.56947326660156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.557567596435547
-------------------------------
-------------------------------
model running time:  7.823232173919678
-------------------------------
-------------------------------
model running time:  26.083328247070312
-------------------------------
-------------------------------
model running time:  9.653247833251953
-------------------------------
-------------------------------
model running time:  25.82921600341797
-------------------------------
Vision time :  85.76022338867188
Action time :  101.85215759277344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.32307243347168
-------------------------------
-------------------------------
model running time:  7.845888137817383
-------------------------------
-------------------------------
model running time:  26.073087692260742
-------------------------------
-------------------------------
model running time:  9.768959999084473
-------------------------------
-------------------------------
model running time:  25.845792770385742
-------------------------------
Vision time :  85.78652954101562
Action time :  102.2116470336914
Trial 6 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.20742416381836
-------------------------------
-------------------------------
model running time:  7.789567947387695
-------------------------------
-------------------------------
model running time:  34.25894546508789
-------------------------------
-------------------------------
model running time:  9.62559986114502
-------------------------------
-------------------------------
model running time:  25.93382453918457
-------------------------------
Vision time :  85.75820922851562
Action time :  109.8055648803711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.30259132385254
-------------------------------
-------------------------------
model running time:  7.887872219085693
-------------------------------
-------------------------------
model running time:  26.08639907836914
-------------------------------
-------------------------------
model running time:  9.890815734863281
-------------------------------
-------------------------------
model running time:  25.847808837890625
-------------------------------
Vision time :  85.77359771728516
Action time :  102.00371551513672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.11827278137207
-------------------------------
-------------------------------
model running time:  12.781567573547363
-------------------------------
-------------------------------
model running time:  26.024959564208984
-------------------------------
-------------------------------
model running time:  9.686911582946777
-------------------------------
-------------------------------
model running time:  25.90096092224121
-------------------------------
Vision time :  85.79337310791016
Action time :  106.25542449951172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.480255126953125
-------------------------------
-------------------------------
model running time:  7.8837761878967285
-------------------------------
-------------------------------
model running time:  25.993215560913086
-------------------------------
-------------------------------
model running time:  9.686976432800293
-------------------------------
-------------------------------
model running time:  27.213823318481445
-------------------------------
Vision time :  85.76544189453125
Action time :  111.13062286376953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.75174331665039
-------------------------------
-------------------------------
model running time:  7.864319801330566
-------------------------------
-------------------------------
model running time:  26.041343688964844
-------------------------------
-------------------------------
model running time:  9.607135772705078
-------------------------------
-------------------------------
model running time:  25.86636734008789
-------------------------------
Vision time :  85.84486389160156
Action time :  108.03609466552734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.93721580505371
-------------------------------
-------------------------------
model running time:  7.8305277824401855
-------------------------------
-------------------------------
model running time:  25.828351974487305
-------------------------------
-------------------------------
model running time:  9.61638355255127
-------------------------------
-------------------------------
model running time:  25.75052833557129
-------------------------------
Vision time :  85.77945709228516
Action time :  105.83039855957031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.190975189208984
-------------------------------
-------------------------------
model running time:  7.867392063140869
-------------------------------
-------------------------------
model running time:  25.760831832885742
-------------------------------
-------------------------------
model running time:  10.281984329223633
-------------------------------
-------------------------------
model running time:  26.428255081176758
-------------------------------
Vision time :  85.77228546142578
Action time :  105.11673736572266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.2554874420166
-------------------------------
-------------------------------
model running time:  7.832543849945068
-------------------------------
-------------------------------
model running time:  27.15033531188965
-------------------------------
-------------------------------
model running time:  9.691136360168457
-------------------------------
-------------------------------
model running time:  25.89913558959961
-------------------------------
Vision time :  85.78931427001953
Action time :  102.78707122802734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.77574348449707
-------------------------------
-------------------------------
model running time:  7.864319801330566
-------------------------------
-------------------------------
model running time:  26.016767501831055
-------------------------------
-------------------------------
model running time:  9.679871559143066
-------------------------------
-------------------------------
model running time:  26.003583908081055
-------------------------------
Vision time :  85.82015991210938
Action time :  109.31302642822266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.168447494506836
-------------------------------
-------------------------------
model running time:  7.841792106628418
-------------------------------
-------------------------------
model running time:  25.866239547729492
-------------------------------
-------------------------------
model running time:  9.623583793640137
-------------------------------
-------------------------------
model running time:  25.88262367248535
-------------------------------
Vision time :  85.74412536621094
Action time :  100.95616149902344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.87455940246582
-------------------------------
-------------------------------
model running time:  7.766880035400391
-------------------------------
-------------------------------
model running time:  25.65007972717285
-------------------------------
-------------------------------
model running time:  9.593855857849121
-------------------------------
-------------------------------
model running time:  25.582592010498047
-------------------------------
Vision time :  85.74905395507812
Action time :  99.97824096679688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.69228744506836
-------------------------------
-------------------------------
model running time:  7.740511894226074
-------------------------------
-------------------------------
model running time:  25.583616256713867
-------------------------------
-------------------------------
model running time:  9.6245756149292
-------------------------------
-------------------------------
model running time:  25.614336013793945
-------------------------------
Vision time :  85.7396469116211
Action time :  99.58921813964844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.973888397216797
-------------------------------
-------------------------------
model running time:  7.819263935089111
-------------------------------
-------------------------------
model running time:  26.639360427856445
-------------------------------
-------------------------------
model running time:  9.648127555847168
-------------------------------
-------------------------------
model running time:  25.902080535888672
-------------------------------
Vision time :  85.7252197265625
Action time :  101.7712631225586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.965696334838867
-------------------------------
-------------------------------
model running time:  7.823359966278076
-------------------------------
-------------------------------
model running time:  25.827327728271484
-------------------------------
-------------------------------
model running time:  9.676799774169922
-------------------------------
-------------------------------
model running time:  26.041343688964844
-------------------------------
Vision time :  85.7666244506836
Action time :  102.48806762695312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.143936157226562
-------------------------------
-------------------------------
model running time:  7.829567909240723
-------------------------------
-------------------------------
model running time:  25.780351638793945
-------------------------------
-------------------------------
model running time:  9.651200294494629
-------------------------------
-------------------------------
model running time:  25.72697639465332
-------------------------------
Vision time :  85.74755096435547
Action time :  105.6153564453125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.8919677734375
-------------------------------
-------------------------------
model running time:  7.754752159118652
-------------------------------
-------------------------------
model running time:  25.73209571838379
-------------------------------
-------------------------------
model running time:  9.614368438720703
-------------------------------
-------------------------------
model running time:  25.70956802368164
-------------------------------
Vision time :  85.76217651367188
Action time :  100.3868179321289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.64313507080078
-------------------------------
-------------------------------
model running time:  7.789567947387695
-------------------------------
-------------------------------
model running time:  25.631744384765625
-------------------------------
-------------------------------
model running time:  9.62662410736084
-------------------------------
-------------------------------
model running time:  25.71161651611328
-------------------------------
Vision time :  85.77369689941406
Action time :  99.95667266845703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.622079849243164
-------------------------------
-------------------------------
model running time:  7.815072059631348
-------------------------------
-------------------------------
model running time:  25.89174461364746
-------------------------------
-------------------------------
model running time:  9.687040328979492
-------------------------------
-------------------------------
model running time:  25.84886360168457
-------------------------------
Vision time :  85.79901123046875
Action time :  101.5541763305664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.971839904785156
-------------------------------
-------------------------------
model running time:  7.7557759284973145
-------------------------------
-------------------------------
model running time:  25.746431350708008
-------------------------------
-------------------------------
model running time:  9.629695892333984
-------------------------------
-------------------------------
model running time:  25.67475128173828
-------------------------------
Vision time :  85.7542724609375
Action time :  100.47078704833984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.808000564575195
-------------------------------
-------------------------------
model running time:  7.74451208114624
-------------------------------
-------------------------------
model running time:  25.65123176574707
-------------------------------
-------------------------------
model running time:  9.613408088684082
-------------------------------
-------------------------------
model running time:  25.728063583374023
-------------------------------
Vision time :  85.7573471069336
Action time :  100.01817321777344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.048288345336914
-------------------------------
-------------------------------
model running time:  7.758848190307617
-------------------------------
-------------------------------
model running time:  25.754623413085938
-------------------------------
-------------------------------
model running time:  9.597951889038086
-------------------------------
-------------------------------
model running time:  25.657344818115234
-------------------------------
Vision time :  85.73811340332031
Action time :  106.28915405273438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416


 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:41<02:06,  7.04s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.013792037963867
-------------------------------
-------------------------------
model running time:  7.8243842124938965
-------------------------------
-------------------------------
model running time:  25.792512893676758
-------------------------------
-------------------------------
model running time:  10.083392143249512
-------------------------------
-------------------------------
model running time:  25.717727661132812
-------------------------------
Vision time :  85.7674560546875
Action time :  101.03282928466797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.66160011291504
-------------------------------
-------------------------------
model running time:  7.8100481033325195
-------------------------------
-------------------------------
model running time:  25.610240936279297
-------------------------------
-------------------------------
model running time:  9.6112642288208
-------------------------------
-------------------------------
model running time:  25.57753562927246
-------------------------------
Vision time :  85.7369613647461
Action time :  99.71916961669922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.6595516204834
-------------------------------
-------------------------------
model running time:  7.763967990875244
-------------------------------
-------------------------------
model running time:  30.37593650817871
-------------------------------
-------------------------------
model running time:  9.621567726135254
-------------------------------
-------------------------------
model running time:  25.627647399902344
-------------------------------
Vision time :  85.75135803222656
Action time :  104.56473541259766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.766016006469727
-------------------------------
-------------------------------
model running time:  7.766016006469727
-------------------------------
-------------------------------
model running time:  25.648128509521484
-------------------------------
-------------------------------
model running time:  9.614336013793945
-------------------------------
-------------------------------
model running time:  25.607168197631836
-------------------------------
Vision time :  85.740478515625
Action time :  99.99769592285156
Trial 7 finished, success: tensor([True]), steps: 394
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.803903579711914
-------------------------------
-------------------------------
model running time:  7.794816017150879
-------------------------------
-------------------------------
model running time:  25.797632217407227
-------------------------------
-------------------------------
model running time:  9.577471733093262
-------------------------------
-------------------------------
model running time:  25.600000381469727
-------------------------------
Vision time :  85.76006317138672
Action time :  100.2484130859375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.714815139770508
-------------------------------
-------------------------------
model running time:  8.770560264587402
-------------------------------
-------------------------------
model running time:  25.845760345458984
-------------------------------
-------------------------------
model running time:  9.699328422546387
-------------------------------
-------------------------------
model running time:  25.72083282470703
-------------------------------
Vision time :  85.7667236328125
Action time :  101.37177276611328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.968767166137695
-------------------------------
-------------------------------
model running time:  7.773280143737793
-------------------------------
-------------------------------
model running time:  25.805824279785156
-------------------------------
-------------------------------
model running time:  9.60598373413086
-------------------------------
-------------------------------
model running time:  25.794559478759766
-------------------------------
Vision time :  85.7459487915039
Action time :  100.61312103271484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.888896942138672
-------------------------------
-------------------------------
model running time:  7.809023857116699
-------------------------------
-------------------------------
model running time:  25.676639556884766
-------------------------------
-------------------------------
model running time:  9.549887657165527
-------------------------------
-------------------------------
model running time:  25.598976135253906
-------------------------------
Vision time :  85.77503967285156
Action time :  100.04377746582031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.956575393676758
-------------------------------
-------------------------------
model running time:  7.7506561279296875
-------------------------------
-------------------------------
model running time:  25.892864227294922
-------------------------------
-------------------------------
model running time:  9.638912200927734
-------------------------------
-------------------------------
model running time:  25.763839721679688
-------------------------------
Vision time :  85.7639389038086
Action time :  100.62860870361328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.86944007873535
-------------------------------
-------------------------------
model running time:  7.759871959686279
-------------------------------
-------------------------------
model running time:  25.78838348388672
-------------------------------
-------------------------------
model running time:  9.61843204498291
-------------------------------
-------------------------------
model running time:  25.870336532592773
-------------------------------
Vision time :  85.7498550415039
Action time :  100.39500427246094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.118303298950195
-------------------------------
-------------------------------
model running time:  7.774240016937256
-------------------------------
-------------------------------
model running time:  25.92367935180664
-------------------------------
-------------------------------
model running time:  9.668607711791992
-------------------------------
-------------------------------
model running time:  25.888927459716797
-------------------------------
Vision time :  85.73212432861328
Action time :  101.08211517333984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.844831466674805
-------------------------------
-------------------------------
model running time:  7.782400131225586
-------------------------------
-------------------------------
model running time:  25.747455596923828
-------------------------------
-------------------------------
model running time:  9.607168197631836
-------------------------------
-------------------------------
model running time:  25.695232391357422
-------------------------------
Vision time :  85.74095916748047
Action time :  100.22310638427734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.88787269592285
-------------------------------
-------------------------------
model running time:  7.745535850524902
-------------------------------
-------------------------------
model running time:  25.89798355102539
-------------------------------
-------------------------------
model running time:  9.660415649414062
-------------------------------
-------------------------------
model running time:  25.72185516357422
-------------------------------
Vision time :  85.74307250976562
Action time :  100.44226837158203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.426496505737305
-------------------------------
-------------------------------
model running time:  7.8592000007629395
-------------------------------
-------------------------------
model running time:  25.944927215576172
-------------------------------
-------------------------------
model running time:  9.636704444885254
-------------------------------
-------------------------------
model running time:  25.898975372314453
-------------------------------
Vision time :  85.80406188964844
Action time :  101.66067504882812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.73632049560547
-------------------------------
-------------------------------
model running time:  7.746687889099121
-------------------------------
-------------------------------
model running time:  25.92870330810547
-------------------------------
-------------------------------
model running time:  9.649151802062988
-------------------------------
-------------------------------
model running time:  25.77008056640625
-------------------------------
Vision time :  85.75196838378906
Action time :  100.38272094726562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.04761505126953
-------------------------------
-------------------------------
model running time:  7.826335906982422
-------------------------------
-------------------------------
model running time:  25.841856002807617
-------------------------------
-------------------------------
model running time:  9.639039993286133
-------------------------------
-------------------------------
model running time:  25.74028778076172
-------------------------------
Vision time :  85.73302459716797
Action time :  100.62643432617188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.790592193603516
-------------------------------
-------------------------------
model running time:  7.715775966644287
-------------------------------
-------------------------------
model running time:  25.88262367248535
-------------------------------
-------------------------------
model running time:  9.655200004577637
-------------------------------
-------------------------------
model running time:  25.77903938293457
-------------------------------
Vision time :  85.69107055664062
Action time :  100.35507202148438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.00147247314453
-------------------------------
-------------------------------
model running time:  7.833600044250488
-------------------------------
-------------------------------
model running time:  25.827423095703125
-------------------------------
-------------------------------
model running time:  9.634943962097168
-------------------------------
-------------------------------
model running time:  25.789440155029297
-------------------------------
Vision time :  85.75161743164062
Action time :  100.54144287109375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.014720916748047
-------------------------------
-------------------------------
model running time:  7.718815803527832
-------------------------------
-------------------------------
model running time:  25.93382453918457
-------------------------------
-------------------------------
model running time:  9.648096084594727
-------------------------------
-------------------------------
model running time:  25.772064208984375
-------------------------------
Vision time :  85.75218963623047
Action time :  100.5844497680664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.21504020690918
-------------------------------
-------------------------------
model running time:  7.836671829223633
-------------------------------
-------------------------------
model running time:  25.886720657348633
-------------------------------
-------------------------------
model running time:  9.595904350280762
-------------------------------
-------------------------------
model running time:  27.667455673217773
-------------------------------
Vision time :  85.75686645507812
Action time :  103.89401245117188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.93600082397461
-------------------------------
-------------------------------
model running time:  7.787519931793213
-------------------------------
-------------------------------
model running time:  25.87343978881836
-------------------------------
-------------------------------
model running time:  9.700480461120605
-------------------------------
-------------------------------
model running time:  25.704608917236328
-------------------------------
Vision time :  85.76569366455078
Action time :  100.5670394897461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.88684844970703
-------------------------------
-------------------------------
model running time:  7.747583866119385
-------------------------------
-------------------------------
model running time:  25.790464401245117
-------------------------------
-------------------------------
model running time:  9.639776229858398
-------------------------------
-------------------------------
model running time:  25.76896095275879
-------------------------------
Vision time :  85.74336242675781
Action time :  100.28031921386719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.27084732055664
-------------------------------
-------------------------------
model running time:  7.797760009765625
-------------------------------
-------------------------------
model running time:  25.998336791992188
-------------------------------
-------------------------------
model running time:  9.60921573638916
-------------------------------
-------------------------------
model running time:  25.696256637573242
-------------------------------
Vision time :  85.73085021972656
Action time :  101.15280151367188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.350719451904297
-------------------------------
-------------------------------
model running time:  7.841792106628418
-------------------------------
-------------------------------
model running time:  26.029056549072266
-------------------------------
-------------------------------
model running time:  9.664511680603027
-------------------------------
-------------------------------
model running time:  31.644672393798828
-------------------------------
Vision time :  85.77033233642578
Action time :  107.29779052734375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  34.757633209228516
-------------------------------
-------------------------------
model running time:  7.773183822631836
-------------------------------
-------------------------------
model running time:  26.11507225036621
-------------------------------


 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:50<02:09,  7.61s/it][A[A-------------------------------
model running time:  9.621503829956055
-------------------------------
-------------------------------
model running time:  25.584640502929688
-------------------------------
Vision time :  85.77484893798828
Action time :  112.25702667236328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.07823944091797
-------------------------------
-------------------------------
model running time:  14.746623992919922
-------------------------------
-------------------------------
model running time:  25.847808837890625
-------------------------------
-------------------------------
model running time:  9.636863708496094
-------------------------------
-------------------------------
model running time:  25.659391403198242
-------------------------------
Vision time :  85.76854705810547
Action time :  107.66028594970703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.08345603942871
-------------------------------
-------------------------------
model running time:  7.766016006469727
-------------------------------
-------------------------------
model running time:  25.769983291625977
-------------------------------
-------------------------------
model running time:  9.571328163146973
-------------------------------
-------------------------------
model running time:  25.51603126525879
-------------------------------
Vision time :  85.76172637939453
Action time :  100.50867462158203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.848960876464844
-------------------------------
-------------------------------
model running time:  7.769087791442871
-------------------------------
-------------------------------
model running time:  25.667583465576172
-------------------------------
-------------------------------
model running time:  9.578368186950684
-------------------------------
-------------------------------
model running time:  25.5784969329834
-------------------------------
Vision time :  85.75529479980469
Action time :  100.0970230102539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.619583129882812
-------------------------------
-------------------------------
model running time:  7.709695816040039
-------------------------------
-------------------------------
model running time:  25.637792587280273
-------------------------------
-------------------------------
model running time:  9.564160346984863
-------------------------------
-------------------------------
model running time:  25.530208587646484
-------------------------------
Vision time :  85.7647705078125
Action time :  99.61881256103516
Trial 8 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.046207427978516
-------------------------------
-------------------------------
model running time:  7.818272113800049
-------------------------------
-------------------------------
model running time:  25.89081573486328
-------------------------------
-------------------------------
model running time:  9.649151802062988
-------------------------------
-------------------------------
model running time:  25.637887954711914
-------------------------------
Vision time :  85.7833251953125
Action time :  106.9148178100586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.970848083496094
-------------------------------
-------------------------------
model running time:  7.817215919494629
-------------------------------
-------------------------------
model running time:  25.902080535888672
-------------------------------
-------------------------------
model running time:  9.612159729003906
-------------------------------
-------------------------------
model running time:  25.663488388061523
-------------------------------
Vision time :  85.79203033447266
Action time :  100.7831039428711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.285184860229492
-------------------------------
-------------------------------
model running time:  7.738463878631592
-------------------------------
-------------------------------
model running time:  26.998655319213867
-------------------------------
-------------------------------
model running time:  9.569279670715332
-------------------------------
-------------------------------
model running time:  25.641984939575195
-------------------------------
Vision time :  85.76127624511719
Action time :  101.99858856201172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.112768173217773
-------------------------------
-------------------------------
model running time:  7.845823764801025
-------------------------------
-------------------------------
model running time:  25.829376220703125
-------------------------------
-------------------------------
model running time:  9.571231842041016
-------------------------------
-------------------------------
model running time:  28.632064819335938
-------------------------------
Vision time :  85.74575805664062
Action time :  109.85171508789062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.0762882232666
-------------------------------
-------------------------------
model running time:  7.79366397857666
-------------------------------
-------------------------------
model running time:  25.72697639465332
-------------------------------
-------------------------------
model running time:  9.586688041687012
-------------------------------
-------------------------------
model running time:  25.571327209472656
-------------------------------
Vision time :  85.76799774169922
Action time :  100.5486068725586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.979007720947266
-------------------------------
-------------------------------
model running time:  13.01193618774414
-------------------------------
-------------------------------
model running time:  25.7392635345459
-------------------------------
-------------------------------
model running time:  9.613311767578125
-------------------------------
-------------------------------
model running time:  25.7259521484375
-------------------------------
Vision time :  85.97622680664062
Action time :  105.7720947265625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.15430450439453
-------------------------------
-------------------------------
model running time:  7.818240165710449
-------------------------------
-------------------------------
model running time:  25.73619270324707
-------------------------------
-------------------------------
model running time:  9.612288475036621
-------------------------------
-------------------------------
model running time:  25.597951889038086
-------------------------------
Vision time :  85.77887725830078
Action time :  105.78435516357422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.375295639038086
-------------------------------
-------------------------------
model running time:  7.79260778427124
-------------------------------
-------------------------------
model running time:  25.83465576171875
-------------------------------
-------------------------------
model running time:  9.590784072875977
-------------------------------
-------------------------------
model running time:  26.093568801879883
-------------------------------
Vision time :  85.76585388183594
Action time :  101.46611022949219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.04761505126953
-------------------------------
-------------------------------
model running time:  7.841792106628418
-------------------------------
-------------------------------
model running time:  25.896032333374023
-------------------------------
-------------------------------
model running time:  9.596927642822266
-------------------------------
-------------------------------
model running time:  25.75974464416504
-------------------------------
Vision time :  85.76470184326172
Action time :  100.87731170654297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.09779167175293
-------------------------------
-------------------------------
model running time:  7.801695823669434
-------------------------------
-------------------------------
model running time:  31.20947265625
-------------------------------
-------------------------------
model running time:  9.622559547424316
-------------------------------
-------------------------------
model running time:  25.866304397583008
-------------------------------
Vision time :  85.7845458984375
Action time :  106.26048278808594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.156160354614258
-------------------------------
-------------------------------
model running time:  7.789567947387695
-------------------------------
-------------------------------
model running time:  25.760704040527344
-------------------------------
-------------------------------
model running time:  13.979711532592773
-------------------------------
-------------------------------
model running time:  25.71878433227539
-------------------------------
Vision time :  85.77244567871094
Action time :  105.31852722167969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.178720474243164
-------------------------------
-------------------------------
model running time:  7.774208068847656
-------------------------------
-------------------------------
model running time:  25.794559478759766
-------------------------------
-------------------------------
model running time:  9.628576278686523
-------------------------------
-------------------------------
model running time:  25.66851234436035
-------------------------------
Vision time :  85.74915313720703
Action time :  100.84556579589844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.066944122314453
-------------------------------
-------------------------------
model running time:  7.781375885009766
-------------------------------
-------------------------------
model running time:  25.775999069213867
-------------------------------
-------------------------------
model running time:  9.675775527954102
-------------------------------
-------------------------------
model running time:  25.684959411621094
-------------------------------
Vision time :  85.7674560546875
Action time :  100.65718078613281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.267776489257812
-------------------------------
-------------------------------
model running time:  7.819263935089111
-------------------------------
-------------------------------
model running time:  25.74336051940918
-------------------------------
-------------------------------
model running time:  9.621503829956055
-------------------------------
-------------------------------
model running time:  31.963136672973633
-------------------------------
Vision time :  85.77286529541016
Action time :  107.28755187988281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.29849624633789
-------------------------------
-------------------------------
model running time:  8.093695640563965
-------------------------------
-------------------------------
model running time:  26.047487258911133
-------------------------------
-------------------------------
model running time:  9.681920051574707
-------------------------------
-------------------------------
model running time:  32.55295944213867
-------------------------------
Vision time :  85.78185272216797
Action time :  108.47843170166016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.28006362915039
-------------------------------
-------------------------------
model running time:  7.774208068847656
-------------------------------
-------------------------------
model running time:  31.761503219604492
-------------------------------
-------------------------------
model running time:  9.637727737426758
-------------------------------
-------------------------------
model running time:  25.70137596130371
-------------------------------
Vision time :  85.78118133544922
Action time :  106.90662384033203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.025087356567383
-------------------------------
-------------------------------
model running time:  7.8089599609375
-------------------------------
-------------------------------
model running time:  36.0417594909668
-------------------------------
-------------------------------
model running time:  9.573375701904297
-------------------------------
-------------------------------
model running time:  25.738143920898438
-------------------------------
Vision time :  85.78076934814453
Action time :  110.98726654052734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.7128963470459
-------------------------------
-------------------------------
model running time:  7.8438401222229
-------------------------------
-------------------------------
model running time:  25.95020866394043
-------------------------------
-------------------------------
model running time:  9.630720138549805
-------------------------------
-------------------------------
model running time:  25.697280883789062
-------------------------------
Vision time :  85.77808380126953
Action time :  107.6336669921875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.857152938842773
-------------------------------
-------------------------------
model running time:  7.775231838226318
-------------------------------
-------------------------------
model running time:  26.652671813964844
-------------------------------
-------------------------------
model running time:  9.604096412658691
-------------------------------
-------------------------------
model running time:  30.99955177307129
-------------------------------
Vision time :  85.76742553710938
Action time :  106.42428588867188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.052736282348633
-------------------------------
-------------------------------
model running time:  7.778304100036621
-------------------------------
-------------------------------
model running time:  25.70137596130371
-------------------------------
-------------------------------
model running time:  9.566207885742188
-------------------------------
-------------------------------
model running time:  25.60416030883789
-------------------------------
Vision time :  85.74883270263672
Action time :  100.28953552246094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:58<02:07,  7.96s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.177696228027344
-------------------------------
-------------------------------
model running time:  7.838719844818115
-------------------------------
-------------------------------
model running time:  25.874431610107422
-------------------------------
-------------------------------
model running time:  9.608256340026855
-------------------------------
-------------------------------
model running time:  25.772031784057617
-------------------------------
Vision time :  85.7630386352539
Action time :  101.22752380371094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.430591583251953
-------------------------------
-------------------------------
model running time:  7.840928077697754
-------------------------------
-------------------------------
model running time:  25.92153549194336
-------------------------------
-------------------------------
model running time:  9.672608375549316
-------------------------------
-------------------------------
model running time:  25.92665672302246
-------------------------------
Vision time :  85.79350280761719
Action time :  101.83270263671875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.03340721130371
-------------------------------
-------------------------------
model running time:  7.806975841522217
-------------------------------
-------------------------------
model running time:  25.74131202697754
-------------------------------
-------------------------------
model running time:  9.609087944030762
-------------------------------
-------------------------------
model running time:  25.607135772705078
-------------------------------
Vision time :  85.7633285522461
Action time :  100.65110778808594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.11564826965332
-------------------------------
-------------------------------
model running time:  7.860223770141602
-------------------------------
-------------------------------
model running time:  30.652416229248047
-------------------------------
-------------------------------
model running time:  9.647104263305664
-------------------------------
-------------------------------
model running time:  25.88876724243164
-------------------------------
Vision time :  85.76457977294922
Action time :  107.07968139648438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.385440826416016
-------------------------------
-------------------------------
model running time:  7.849984169006348
-------------------------------
-------------------------------
model running time:  26.007551193237305
-------------------------------
-------------------------------
model running time:  9.646047592163086
-------------------------------
-------------------------------
model running time:  25.91756820678711
-------------------------------
Vision time :  85.83747100830078
Action time :  101.57670593261719
Trial 9 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.57766342163086
-------------------------------
-------------------------------
model running time:  7.946239948272705
-------------------------------
-------------------------------
model running time:  26.083263397216797
-------------------------------
-------------------------------
model running time:  9.614336013793945
-------------------------------
-------------------------------
model running time:  25.991104125976562
-------------------------------
Vision time :  85.77011108398438
Action time :  108.12723541259766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.436735153198242
-------------------------------
-------------------------------
model running time:  7.794591903686523
-------------------------------
-------------------------------
model running time:  26.210304260253906
-------------------------------
-------------------------------
model running time:  9.630816459655762
-------------------------------
-------------------------------
model running time:  25.791488647460938
-------------------------------
Vision time :  85.74658966064453
Action time :  101.77536010742188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.40083122253418
-------------------------------
-------------------------------
model running time:  7.80079984664917
-------------------------------
-------------------------------
model running time:  26.099552154541016
-------------------------------
-------------------------------
model running time:  9.63584041595459
-------------------------------
-------------------------------
model running time:  25.90617561340332
-------------------------------
Vision time :  85.7936019897461
Action time :  101.75590515136719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [01:00<01:31,  6.13s/it][A[A
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.675487518310547
-------------------------------
-------------------------------
model running time:  7.897024154663086
-------------------------------
-------------------------------
model running time:  26.179584503173828
-------------------------------
-------------------------------
model running time:  9.648127555847168
-------------------------------
-------------------------------
model running time:  25.90924835205078
-------------------------------
Vision time :  85.86966705322266
Action time :  102.53209686279297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.167423248291016
-------------------------------
-------------------------------
model running time:  7.778304100036621
-------------------------------
-------------------------------
model running time:  25.975807189941406
-------------------------------
-------------------------------
model running time:  9.647135734558105
-------------------------------
-------------------------------
model running time:  25.819135665893555
-------------------------------
Vision time :  85.7715835571289
Action time :  101.24492645263672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.423423767089844
-------------------------------
-------------------------------
model running time:  7.785344123840332
-------------------------------
-------------------------------
model running time:  25.921600341796875
-------------------------------
-------------------------------
model running time:  9.605119705200195
-------------------------------
-------------------------------
model running time:  25.620479583740234
-------------------------------
Vision time :  85.76432037353516
Action time :  107.14521789550781
Trial 10 finished, success: tensor([True]), steps: 89
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.98873519897461
-------------------------------
-------------------------------
model running time:  7.829599857330322
-------------------------------
-------------------------------
model running time:  25.933664321899414
-------------------------------
-------------------------------
model running time:  9.713567733764648
-------------------------------
-------------------------------
model running time:  25.631807327270508
-------------------------------
Vision time :  85.76422119140625
Action time :  108.90230560302734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.249183654785156
-------------------------------
-------------------------------
model running time:  7.8397440910339355
-------------------------------
-------------------------------
model running time:  27.56608009338379
-------------------------------
-------------------------------
model running time:  9.621503829956055
-------------------------------
-------------------------------
model running time:  25.802751541137695
-------------------------------
Vision time :  85.79151916503906
Action time :  102.91410827636719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.377344131469727
-------------------------------
-------------------------------
model running time:  7.8305277824401855
-------------------------------
-------------------------------
model running time:  26.001407623291016
-------------------------------
-------------------------------
model running time:  9.679871559143066
-------------------------------
-------------------------------
model running time:  25.888608932495117
-------------------------------
Vision time :  85.86985778808594
Action time :  101.8603515625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.849472045898438
-------------------------------
-------------------------------
model running time:  7.836671829223633
-------------------------------
-------------------------------
model running time:  25.871360778808594
-------------------------------
-------------------------------
model running time:  9.658495903015137
-------------------------------
-------------------------------
model running time:  25.757631301879883
-------------------------------
Vision time :  85.76640319824219
Action time :  108.76620483398438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.968671798706055
-------------------------------
-------------------------------
model running time:  7.82144021987915
-------------------------------
-------------------------------
model running time:  25.923583984375
-------------------------------
-------------------------------
model running time:  9.62764835357666
-------------------------------
-------------------------------
model running time:  26.616832733154297
-------------------------------
Vision time :  85.75971221923828
Action time :  101.60639953613281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048


 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [01:04<01:14,  5.30s/it][A[Aafter pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.53708839416504
-------------------------------
-------------------------------
model running time:  7.866367816925049
-------------------------------
-------------------------------
model running time:  26.13657569885254
-------------------------------
-------------------------------
model running time:  9.676863670349121
-------------------------------
-------------------------------
model running time:  26.466304779052734
-------------------------------
Vision time :  85.77555084228516
Action time :  102.56902313232422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.392704010009766
-------------------------------
-------------------------------
model running time:  7.8305277824401855
-------------------------------
-------------------------------
model running time:  26.24095916748047
-------------------------------
-------------------------------
model running time:  11.507712364196777
-------------------------------
-------------------------------
model running time:  27.124576568603516
-------------------------------
Vision time :  85.77942657470703
Action time :  108.51737976074219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.616960525512695
-------------------------------
-------------------------------
model running time:  7.872384071350098
-------------------------------
-------------------------------
model running time:  26.165376663208008
-------------------------------
-------------------------------
model running time:  9.774080276489258
-------------------------------
-------------------------------
model running time:  26.0710391998291
-------------------------------
Vision time :  85.77862548828125
Action time :  102.44812774658203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.073408126831055
-------------------------------
-------------------------------
model running time:  7.817215919494629
-------------------------------
-------------------------------
model running time:  26.108928680419922
-------------------------------
-------------------------------
model running time:  9.649151802062988
-------------------------------
-------------------------------
model running time:  25.797632217407227
-------------------------------
Vision time :  85.7919692993164
Action time :  106.21952056884766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.74015998840332
-------------------------------
-------------------------------
model running time:  7.830431938171387
-------------------------------
-------------------------------
model running time:  26.053632736206055
-------------------------------
-------------------------------
model running time:  9.676799774169922
-------------------------------
-------------------------------
model running time:  25.91961669921875
-------------------------------
Vision time :  85.74642944335938
Action time :  104.880126953125
Trial 11 finished, success: tensor([True]), steps: 155
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.900928497314453
-------------------------------
-------------------------------
model running time:  7.887872219085693
-------------------------------
-------------------------------
model running time:  26.31475257873535
-------------------------------
-------------------------------
model running time:  9.758720397949219
-------------------------------
-------------------------------
model running time:  25.947200775146484
-------------------------------
Vision time :  85.76201629638672
Action time :  105.58172607421875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.301599502563477
-------------------------------
-------------------------------
model running time:  7.889920234680176
-------------------------------
-------------------------------
model running time:  26.205184936523438
-------------------------------
-------------------------------
model running time:  9.662464141845703
-------------------------------
-------------------------------
model running time:  35.346431732177734
-------------------------------
Vision time :  85.78562927246094
Action time :  111.22179412841797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.186880111694336
-------------------------------
-------------------------------
model running time:  7.75167989730835
-------------------------------
-------------------------------
model running time:  25.92051124572754
-------------------------------
-------------------------------
model running time:  9.593855857849121
-------------------------------
-------------------------------
model running time:  25.658367156982422
-------------------------------
Vision time :  85.76873779296875
Action time :  100.89266967773438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 


 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [01:06<00:55,  4.29s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.48793601989746
-------------------------------
-------------------------------
model running time:  13.0764799118042
-------------------------------
-------------------------------
model running time:  26.12019157409668
-------------------------------
-------------------------------
model running time:  9.676799774169922
-------------------------------
-------------------------------
model running time:  25.927776336669922
-------------------------------
Vision time :  85.77705383300781
Action time :  108.69145965576172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.29132843017578
-------------------------------
-------------------------------
model running time:  8.863743782043457
-------------------------------
-------------------------------
model running time:  25.94099235534668
-------------------------------
-------------------------------
model running time:  9.63584041595459
-------------------------------
-------------------------------
model running time:  25.68499183654785
-------------------------------
Vision time :  85.78659057617188
Action time :  108.2635498046875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.32089614868164
-------------------------------
-------------------------------
model running time:  7.8243842124938965
-------------------------------
-------------------------------
model running time:  25.899072647094727
-------------------------------
-------------------------------
model running time:  9.630720138549805
-------------------------------
-------------------------------
model running time:  25.72390365600586
-------------------------------
Vision time :  85.78457641601562
Action time :  101.30521392822266
Trial 12 finished, success: tensor([True]), steps: 82
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.475391387939453
-------------------------------
-------------------------------
model running time:  7.799808025360107
-------------------------------
-------------------------------
model running time:  25.72185516357422
-------------------------------
-------------------------------
model running time:  9.578495979309082
-------------------------------
-------------------------------
model running time:  25.651199340820312
-------------------------------
Vision time :  85.76422119140625
Action time :  105.00812530517578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.826496124267578
-------------------------------
-------------------------------
model running time:  7.822336196899414
-------------------------------
-------------------------------
model running time:  25.883647918701172
-------------------------------
-------------------------------
model running time:  9.61843204498291
-------------------------------
-------------------------------
model running time:  25.68191909790039
-------------------------------
Vision time :  85.75625610351562
Action time :  107.46367645263672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  23.952415466308594
-------------------------------
-------------------------------
model running time:  7.753727912902832
-------------------------------
-------------------------------
model running time:  25.793535232543945
-------------------------------
-------------------------------
model running time:  9.649151802062988
-------------------------------
-------------------------------
model running time:  25.609216690063477
-------------------------------
Vision time :  85.79682922363281
Action time :  100.55680084228516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.472576141357422
-------------------------------
-------------------------------
model running time:  7.827455997467041
-------------------------------
-------------------------------
model running time:  31.6549129486084
-------------------------------
-------------------------------
model running time:  9.61023998260498
-------------------------------
-------------------------------
model running time:  25.89798355102539
-------------------------------
Vision time :  85.77017974853516
Action time :  107.33773040771484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.21049690246582
-------------------------------
-------------------------------
model running time:  8.33129596710205
-------------------------------
-------------------------------
model running time:  32.613407135009766
-------------------------------
-------------------------------
model running time:  9.676735877990723
-------------------------------
-------------------------------
model running time:  25.644031524658203
-------------------------------
Vision time :  85.77356719970703
Action time :  108.61772918701172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.710752487182617
-------------------------------
-------------------------------
model running time:  7.897088050842285
-------------------------------
-------------------------------
model running time:  26.635263442993164
-------------------------------
-------------------------------
model running time:  9.72374439239502
-------------------------------
-------------------------------
model running time:  26.34022331237793
-------------------------------
Vision time :  85.77171325683594
Action time :  109.21062469482422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.155263900756836
-------------------------------
-------------------------------
model running time:  8.013824462890625
-------------------------------
-------------------------------
model running time:  26.714111328125
-------------------------------
-------------------------------
model running time:  9.736191749572754
-------------------------------
-------------------------------
model running time:  26.29631996154785
-------------------------------
Vision time :  85.78160095214844
Action time :  108.02073669433594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.577024459838867
-------------------------------
-------------------------------
model running time:  7.856128215789795
-------------------------------
-------------------------------
model running time:  26.384384155273438
-------------------------------
-------------------------------
model running time:  9.699328422546387
-------------------------------
-------------------------------
model running time:  31.896575927734375
-------------------------------
Vision time :  85.76815795898438
Action time :  108.40985870361328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.572799682617188
-------------------------------
-------------------------------
model running time:  7.8592000007629395
-------------------------------
-------------------------------
model running time:  26.454015731811523
-------------------------------
-------------------------------
model running time:  9.773152351379395
-------------------------------
-------------------------------
model running time:  26.192895889282227
-------------------------------
Vision time :  85.76051330566406
Action time :  104.84941101074219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.69487953186035
-------------------------------
-------------------------------
model running time:  7.907296180725098
-------------------------------
-------------------------------
model running time:  26.400768280029297
-------------------------------
-------------------------------
model running time:  9.720831871032715
-------------------------------
-------------------------------
model running time:  28.76416015625
-------------------------------
Vision time :  85.78768157958984
Action time :  107.68297576904297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.438783645629883
-------------------------------
-------------------------------
model running time:  7.817215919494629
-------------------------------
-------------------------------
model running time:  26.28505516052246
-------------------------------
-------------------------------
model running time:  9.739263534545898
-------------------------------
-------------------------------
model running time:  26.108928680419922
-------------------------------
Vision time :  86.47183990478516
Action time :  102.36518096923828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.625152587890625
-------------------------------
-------------------------------
model running time:  7.89299201965332
-------------------------------
-------------------------------
model running time:  26.281984329223633
-------------------------------
-------------------------------
model running time:  9.660351753234863
-------------------------------
-------------------------------
model running time:  26.064895629882812
-------------------------------
Vision time :  85.77033233642578
Action time :  102.46553802490234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.252416610717773
-------------------------------
-------------------------------
model running time:  7.823296070098877
-------------------------------
-------------------------------
model running time:  30.99443244934082
-------------------------------
-------------------------------
model running time:  9.669631958007812
-------------------------------
-------------------------------
model running time:  26.219520568847656
-------------------------------
Vision time :  85.7688980102539
Action time :  106.78169250488281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.61084747314453
-------------------------------
-------------------------------
model running time:  7.899136066436768
-------------------------------
-------------------------------
model running time:  26.369983673095703
-------------------------------
-------------------------------
model running time:  14.493727684020996
-------------------------------
-------------------------------
model running time:  26.187679290771484
-------------------------------
Vision time :  85.76908874511719
Action time :  107.55693054199219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.58937644958496
-------------------------------
-------------------------------
model running time:  7.825407981872559
-------------------------------
-------------------------------
model running time:  30.76710319519043
-------------------------------
-------------------------------
model running time:  9.748479843139648
-------------------------------
-------------------------------
model running time:  26.244096755981445
-------------------------------
Vision time :  85.75651550292969
Action time :  107.02336120605469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.49295997619629
-------------------------------
-------------------------------
model running time:  7.85203218460083
-------------------------------
-------------------------------
model running time:  26.207231521606445
-------------------------------
-------------------------------
model running time:  9.693056106567383
-------------------------------
-------------------------------
model running time:  26.14067268371582
-------------------------------
Vision time :  85.76493072509766
Action time :  102.331298828125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.70400047302246
-------------------------------
-------------------------------
model running time:  7.905280113220215
-------------------------------
-------------------------------
model running time:  26.438655853271484
-------------------------------
-------------------------------
model running time:  9.703424453735352
-------------------------------
-------------------------------
model running time:  26.219520568847656
-------------------------------
Vision time :  85.78518676757812
Action time :  107.1124496459961
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.86591911315918
-------------------------------
-------------------------------
model running time:  7.903232097625732
-------------------------------
-------------------------------
model running time:  26.396671295166016
-------------------------------
-------------------------------
model running time:  9.681920051574707
-------------------------------
-------------------------------
model running time:  26.225664138793945
-------------------------------
Vision time :  85.7779541015625
Action time :  103.0830078125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.671232223510742
-------------------------------
-------------------------------
model running time:  7.986176013946533
-------------------------------
-------------------------------
model running time:  32.0819206237793
-------------------------------
-------------------------------
model running time:  9.722880363464355
-------------------------------
-------------------------------
model running time:  26.34752082824707
-------------------------------
Vision time :  85.79590606689453
Action time :  108.99251556396484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.99692726135254
-------------------------------
-------------------------------
model running time:  7.885824203491211
-------------------------------
-------------------------------
model running time:  26.51955223083496
-------------------------------
-------------------------------
model running time:  9.701375961303711
-------------------------------
-------------------------------
model running time:  26.220447540283203
-------------------------------
Vision time :  85.76057434082031
Action time :  110.24486541748047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.47974395751953
-------------------------------
-------------------------------
model running time:  7.847936153411865
-------------------------------
-------------------------------
model running time:  30.58073616027832
-------------------------------
-------------------------------
model running time:  9.681920051574707
-------------------------------
-------------------------------
model running time:  26.100608825683594
-------------------------------
Vision time :  85.7768325805664
Action time :  106.57987213134766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.799232482910156
-------------------------------
-------------------------------
model running time:  

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [01:14<01:07,  5.60s/it][A[A7.9042558670043945
-------------------------------
-------------------------------
model running time:  26.517343521118164
-------------------------------
-------------------------------
model running time:  9.712512016296387
-------------------------------
-------------------------------
model running time:  26.71001625061035
-------------------------------
Vision time :  85.78304290771484
Action time :  103.75475311279297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.27280044555664
-------------------------------
-------------------------------
model running time:  7.825407981872559
-------------------------------
-------------------------------
model running time:  26.059776306152344
-------------------------------
-------------------------------
model running time:  9.649279594421387
-------------------------------
-------------------------------
model running time:  25.703487396240234
-------------------------------
Vision time :  85.8326416015625
Action time :  101.26028442382812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.20534324645996
-------------------------------
-------------------------------
model running time:  7.778304100036621
-------------------------------
-------------------------------
model running time:  25.784320831298828
-------------------------------
-------------------------------
model running time:  9.631744384765625
-------------------------------
-------------------------------
model running time:  25.587711334228516
-------------------------------
Vision time :  85.76112365722656
Action time :  100.88448333740234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.028160095214844
-------------------------------
-------------------------------
model running time:  7.744480133056641
-------------------------------
-------------------------------
model running time:  25.777151107788086
-------------------------------
-------------------------------
model running time:  9.621536254882812
-------------------------------
-------------------------------
model running time:  26.204160690307617
-------------------------------
Vision time :  85.78749084472656
Action time :  101.14559936523438
Trial 13 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.08857536315918
-------------------------------
-------------------------------
model running time:  7.833600044250488
-------------------------------
-------------------------------
model running time:  25.90825653076172
-------------------------------
-------------------------------
model running time:  9.61740779876709
-------------------------------
-------------------------------
model running time:  25.71366310119629
-------------------------------
Vision time :  85.77782440185547
Action time :  100.95718383789062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.049728393554688
-------------------------------
-------------------------------
model running time:  7.791615962982178
-------------------------------
-------------------------------
model running time:  25.994239807128906
-------------------------------
-------------------------------
model running time:  9.63481616973877
-------------------------------
-------------------------------
model running time:  25.75052833557129
-------------------------------
Vision time :  85.78800201416016
Action time :  100.94694519042969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.188928604125977
-------------------------------
-------------------------------
model running time:  7.833600044250488
-------------------------------
-------------------------------
model running time:  25.830400466918945
-------------------------------
-------------------------------
model running time:  9.646080017089844
-------------------------------
-------------------------------
model running time:  25.700191497802734
-------------------------------
Vision time :  85.78163146972656
Action time :  101.10975646972656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.202239990234375
-------------------------------
-------------------------------
model running time:  7.870463848114014
-------------------------------
-------------------------------
model running time:  25.94291114807129
-------------------------------
-------------------------------
model running time:  9.682944297790527
-------------------------------
-------------------------------
model running time:  25.73209571838379
-------------------------------
Vision time :  85.78419494628906
Action time :  101.07698822021484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.07526397705078
-------------------------------
-------------------------------
model running time:  7.781375885009766
-------------------------------


 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [01:19<00:56,  5.17s/it][A[A-------------------------------
model running time:  25.95020866394043
-------------------------------
-------------------------------
model running time:  9.648127555847168
-------------------------------
-------------------------------
model running time:  26.09766387939453
-------------------------------
Vision time :  85.7844467163086
Action time :  101.3790054321289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.217439651489258
-------------------------------
-------------------------------
model running time:  7.826432228088379
-------------------------------
-------------------------------
model running time:  25.817087173461914
-------------------------------
-------------------------------
model running time:  9.638815879821777
-------------------------------
-------------------------------
model running time:  25.659391403198242
-------------------------------
Vision time :  85.81330871582031
Action time :  100.90803527832031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.208383560180664
-------------------------------
-------------------------------
model running time:  7.803904056549072
-------------------------------
-------------------------------
model running time:  25.845760345458984
-------------------------------
-------------------------------
model running time:  9.623552322387695
-------------------------------
-------------------------------
model running time:  25.70854377746582
-------------------------------
Vision time :  85.80009460449219
Action time :  101.29920196533203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.201215744018555
-------------------------------
-------------------------------
model running time:  7.778336048126221
-------------------------------
-------------------------------
model running time:  25.769983291625977
-------------------------------
-------------------------------
model running time:  9.621536254882812
-------------------------------
-------------------------------
model running time:  25.617408752441406
-------------------------------
Vision time :  85.79750061035156
Action time :  100.8721923828125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.5534725189209
-------------------------------
-------------------------------
model running time:  7.862271785736084
-------------------------------
-------------------------------
model running time:  26.083328247070312
-------------------------------
-------------------------------
model running time:  9.655296325683594
-------------------------------
-------------------------------
model running time:  25.805824279785156
-------------------------------
Vision time :  85.81123352050781
Action time :  101.95868682861328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.387584686279297
-------------------------------
-------------------------------
model running time:  7.90015983581543
-------------------------------
-------------------------------
model running time:  26.03001594543457
-------------------------------
-------------------------------
model running time:  9.66543960571289
-------------------------------
-------------------------------
model running time:  25.821088790893555
-------------------------------
Vision time :  85.77696228027344
Action time :  101.5920639038086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.31078338623047
-------------------------------
-------------------------------
model running time:  7.852960109710693
-------------------------------
-------------------------------
model running time:  26.109952926635742
-------------------------------
-------------------------------
model running time:  9.598976135253906
-------------------------------
-------------------------------
model running time:  25.820159912109375
-------------------------------
Vision time :  85.67724609375
Action time :  101.53164672851562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.30352020263672
-------------------------------
-------------------------------
model running time:  7.792640209197998
-------------------------------
-------------------------------
model running time:  25.93391990661621
-------------------------------
-------------------------------
model running time:  9.620479583740234
-------------------------------
-------------------------------
model running time:  32.38809585571289
-------------------------------
Vision time :  85.65856170654297
Action time :  107.85894775390625
Trial 14 finished, success: tensor([True]), steps: 192
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 1092, 2048]), num_elements=2236416
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  24.35686492919922
-------------------------------
-------------------------------
model running time:  7.8632001876831055
-------------------------------
-------------------------------
model running time:  26.034175872802734