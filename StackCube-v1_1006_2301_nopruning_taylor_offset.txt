nohup: ignoring input
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
using taylor
RDT_taylor_img_p(
  (t_embedder): TimestepEmbedder(
    (mlp): Sequential(
      (0): Linear(in_features=256, out_features=2048, bias=True)
      (1): SiLU()
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
  )
  (freq_embedder): TimestepEmbedder(
    (mlp): Sequential(
      (0): Linear(in_features=256, out_features=2048, bias=True)
      (1): SiLU()
      (2): Linear(in_features=2048, out_features=2048, bias=True)
    )
  )
  (blocks): ModuleList(
    (0-27): 28 x RDTBlock_taylor_img_p(
      (norm1): RmsNorm()
      (attn): TaylorAttention(
        (qkv): Linear(in_features=2048, out_features=6144, bias=True)
        (q_norm): RmsNorm()
        (k_norm): RmsNorm()
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=2048, out_features=2048, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (cross_attn): TaylorCrossAttention(
        (q): Linear(in_features=2048, out_features=2048, bias=True)
        (kv): Linear(in_features=2048, out_features=4096, bias=True)
        (q_norm): RmsNorm()
        (k_norm): RmsNorm()
        (attn_drop): Dropout(p=0, inplace=False)
        (proj): Linear(in_features=2048, out_features=2048, bias=True)
        (proj_drop): Dropout(p=0, inplace=False)
      )
      (norm2): RmsNorm()
      (ffn): WrappedTaylorMlp(
        (fc1): Linear(in_features=2048, out_features=2048, bias=True)
        (act): GELU(approximate='tanh')
        (fc2): Linear(in_features=2048, out_features=2048, bias=True)
      )
      (norm3): RmsNorm()
    )
  )
  (final_layer): FinalLayer(
    (norm_final): RmsNorm()
    (ffn_final): Mlp(
      (fc1): Linear(in_features=2048, out_features=2048, bias=True)
      (act): GELU(approximate='tanh')
      (drop1): Dropout(p=0, inplace=False)
      (norm): Identity()
      (fc2): Linear(in_features=2048, out_features=128, bias=True)
      (drop2): Dropout(p=0, inplace=False)
    )
  )
)
Diffusion params: 1.228320e+09
Loading weights from /root/autodl-tmp/ckpt/rdt/maniskill-model/rdt/mp_rank_00_model_states.pt
test inter text encode time
0
policy.encode_instruction GPU time: 172.496 ms
1
policy.encode_instruction GPU time: 22.276 ms
2
policy.encode_instruction GPU time: 18.322 ms
3
policy.encode_instruction GPU time: 18.319 ms
4
policy.encode_instruction GPU time: 18.270 ms
5
policy.encode_instruction GPU time: 18.534 ms
6
policy.encode_instruction GPU time: 18.178 ms
7
policy.encode_instruction GPU time: 24.537 ms
8
policy.encode_instruction GPU time: 18.287 ms
9
policy.encode_instruction GPU time: 18.192 ms
10
policy.encode_instruction GPU time: 18.297 ms
11
policy.encode_instruction GPU time: 18.158 ms
12
policy.encode_instruction GPU time: 18.236 ms
13
policy.encode_instruction GPU time: 18.827 ms
14
policy.encode_instruction GPU time: 18.640 ms
15
policy.encode_instruction GPU time: 18.217 ms
16
policy.encode_instruction GPU time: 18.536 ms
17
policy.encode_instruction GPU time: 18.220 ms
18
policy.encode_instruction GPU time: 18.138 ms
19
policy.encode_instruction GPU time: 18.235 ms
20
policy.encode_instruction GPU time: 18.138 ms
21
policy.encode_instruction GPU time: 18.471 ms
22
policy.encode_instruction GPU time: 23.255 ms
23
policy.encode_instruction GPU time: 18.445 ms
24
policy.encode_instruction GPU time: 18.670 ms
25
policy.encode_instruction GPU time: 26.504 ms
26
policy.encode_instruction GPU time: 20.418 ms
27
policy.encode_instruction GPU time: 18.241 ms
28
policy.encode_instruction GPU time: 18.191 ms
29
policy.encode_instruction GPU time: 18.171 ms
[ 0.01        0.31622777 10.        ]
grid search:   0%|          | 0/9 [00:00<?, ?it/s]
  0%|          | 0/10 [00:00<?, ?it/s][ARunning trial with alpha=1.0, temp=0.01. Re-seeding with 20241201.


  0%|          | 0/25 [00:00<?, ?it/s][A[A

  4%|â–         | 1/25 [00:02<01:10,  2.93s/it][A[Abefore pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  34.8671989440918
-------------------------------
-------------------------------
model running time:  8.578047752380371
-------------------------------
-------------------------------
model running time:  29.904895782470703
-------------------------------
-------------------------------
model running time:  10.522624015808105
-------------------------------
-------------------------------
model running time:  37.226497650146484
-------------------------------
Vision time :  144.18258666992188
Action time :  128.86630249023438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.054527282714844
-------------------------------
-------------------------------
model running time:  8.51968002319336
-------------------------------
-------------------------------
model running time:  27.98080062866211
-------------------------------
-------------------------------
model running time:  14.420096397399902
-------------------------------
-------------------------------
model running time:  27.78112030029297
-------------------------------
Vision time :  85.3598403930664
Action time :  111.40608215332031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.807872772216797
-------------------------------
-------------------------------
model running time:  8.456192016601562
-------------------------------
-------------------------------
model running time:  27.423744201660156
-------------------------------
-------------------------------
model running time:  10.558464050292969
-------------------------------
-------------------------------
model running time:  27.41254425048828
-------------------------------
Vision time :  85.37939453125
Action time :  104.25135803222656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  34.332672119140625
-------------------------------
-------------------------------
model running time:  8.487936019897461
-------------------------------
-------------------------------
model running time:  27.741119384765625
-------------------------------
-------------------------------
model running time:  10.514431953430176
-------------------------------
-------------------------------
model running time:  27.5916805267334
-------------------------------
Vision time :  85.34451293945312
Action time :  113.32300567626953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.938560485839844
-------------------------------
-------------------------------
model running time:  8.438783645629883
-------------------------------
-------------------------------
model running time:  27.871231079101562
-------------------------------
-------------------------------
model running time:  10.492959976196289
-------------------------------
-------------------------------
model running time:  27.644927978515625
-------------------------------
Vision time :  85.35497283935547
Action time :  110.91558074951172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.74380874633789
-------------------------------
-------------------------------
model running time:  8.494048118591309
-------------------------------
-------------------------------
model running time:  27.79955291748047
-------------------------------
-------------------------------
model running time:  10.566656112670898
-------------------------------
-------------------------------
model running time:  27.54470443725586
-------------------------------
Vision time :  85.43446350097656
Action time :  105.98092651367188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.200511932373047
-------------------------------
-------------------------------
model running time:  8.545344352722168
-------------------------------
-------------------------------
model running time:  27.811840057373047
-------------------------------
-------------------------------
model running time:  16.01024055480957
-------------------------------
-------------------------------
model running time:  27.672576904296875
-------------------------------
Vision time :  85.38960266113281
Action time :  111.92524719238281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.11814308166504
-------------------------------
-------------------------------
model running time:  8.519776344299316
-------------------------------
-------------------------------
model running time:  27.73196792602539
-------------------------------
-------------------------------
model running time:  10.475520133972168
-------------------------------
-------------------------------
model running time:  27.689119338989258
-------------------------------
Vision time :  85.42495727539062
Action time :  105.14636993408203
Trial 1 finished, success: tensor([True]), steps: 126
policy.alpha = 1.0policy.temp = 0.01
before pruning: 


  8%|â–Š         | 2/25 [00:05<01:00,  2.61s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.925695419311523
-------------------------------
-------------------------------
model running time:  8.51046371459961
-------------------------------
-------------------------------
model running time:  27.78316879272461
-------------------------------
-------------------------------
model running time:  10.574848175048828
-------------------------------
-------------------------------
model running time:  27.702272415161133
-------------------------------
Vision time :  85.41824340820312
Action time :  105.28761291503906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.846784591674805
-------------------------------
-------------------------------
model running time:  8.486047744750977
-------------------------------
-------------------------------
model running time:  27.985919952392578
-------------------------------
-------------------------------
model running time:  10.579968452453613
-------------------------------
-------------------------------
model running time:  27.57632064819336
-------------------------------
Vision time :  85.40838623046875
Action time :  105.11148834228516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.157087326049805
-------------------------------
-------------------------------
model running time:  8.463359832763672
-------------------------------
-------------------------------
model running time:  36.541439056396484
-------------------------------
-------------------------------
model running time:  10.511360168457031
-------------------------------
-------------------------------
model running time:  27.738208770751953
-------------------------------
Vision time :  85.43222045898438
Action time :  114.17292785644531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.995264053344727
-------------------------------
-------------------------------
model running time:  8.474623680114746
-------------------------------
-------------------------------
model running time:  27.888511657714844
-------------------------------
-------------------------------
model running time:  10.487808227539062
-------------------------------
-------------------------------
model running time:  34.27328109741211
-------------------------------
Vision time :  85.45974731445312
Action time :  111.92626953125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.6844482421875
-------------------------------
-------------------------------
model running time:  8.427552223205566
-------------------------------
-------------------------------
model running time:  27.646976470947266
-------------------------------
-------------------------------
model running time:  10.503168106079102
-------------------------------
-------------------------------
model running time:  27.595775604248047
-------------------------------
Vision time :  85.40713500976562
Action time :  105.56416320800781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.94495964050293
-------------------------------
-------------------------------
model running time:  8.454143524169922
-------------------------------
-------------------------------
model running time:  27.715648651123047
-------------------------------
-------------------------------
model running time:  10.60364818572998
-------------------------------
-------------------------------
model running time:  27.49852752685547
-------------------------------
Vision time :  85.4386215209961
Action time :  105.04704284667969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.963520050048828
-------------------------------
-------------------------------
model running time:  8.51251220703125
-------------------------------
-------------------------------
model running time:  27.75449562072754
-------------------------------
-------------------------------
model running time:  10.596287727355957
-------------------------------
-------------------------------
model running time:  27.53023910522461
-------------------------------
Vision time :  85.43936157226562
Action time :  105.56403350830078
Trial 2 finished, success: tensor([True]), steps: 104
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.91948890686035
-------------------------------
-------------------------------
model running time:  8.51046371459961
-------------------------------
-------------------------------
model running time:  31.59040069580078
-------------------------------
-------------------------------
model running time:  10.602496147155762
-------------------------------
-------------------------------
model running time:  27.476991653442383
-------------------------------
Vision time :  85.40624237060547
Action time :  108.97599792480469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 12%|â–ˆâ–        | 3/25 [00:07<00:52,  2.38s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.95020866394043
-------------------------------
-------------------------------
model running time:  8.443903923034668
-------------------------------
-------------------------------
model running time:  27.58348846435547
-------------------------------
-------------------------------
model running time:  10.514431953430176
-------------------------------
-------------------------------
model running time:  27.444223403930664
-------------------------------
Vision time :  85.4217300415039
Action time :  105.00495910644531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.617408752441406
-------------------------------
-------------------------------
model running time:  8.428544044494629
-------------------------------
-------------------------------
model running time:  27.610111236572266
-------------------------------
-------------------------------
model running time:  10.53388786315918
-------------------------------
-------------------------------
model running time:  30.081024169921875
-------------------------------
Vision time :  85.43299102783203
Action time :  110.01958465576172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.870975494384766
-------------------------------
-------------------------------
model running time:  8.475775718688965
-------------------------------
-------------------------------
model running time:  27.465856552124023
-------------------------------
-------------------------------
model running time:  10.513407707214355
-------------------------------
-------------------------------
model running time:  27.339744567871094
-------------------------------
Vision time :  85.45597076416016
Action time :  110.67801666259766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.595903396606445
-------------------------------
-------------------------------
model running time:  8.411231994628906
-------------------------------
-------------------------------
model running time:  27.433984756469727
-------------------------------
-------------------------------
model running time:  10.595328330993652
-------------------------------
-------------------------------
model running time:  27.487232208251953
-------------------------------
Vision time :  85.43062591552734
Action time :  104.30054473876953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.93017578125
-------------------------------
-------------------------------
model running time:  8.472576141357422
-------------------------------
-------------------------------
model running time:  27.474943161010742
-------------------------------
-------------------------------
model running time:  10.51852798461914
-------------------------------
-------------------------------
model running time:  27.35820770263672
-------------------------------
Vision time :  85.42854309082031
Action time :  107.78214263916016
Trial 3 finished, success: tensor([True]), steps: 94
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.849279403686523
-------------------------------
-------------------------------
model running time:  11.051103591918945
-------------------------------
-------------------------------
model running time:  27.624448776245117
-------------------------------
-------------------------------
model running time:  10.52774429321289
-------------------------------
-------------------------------
model running time:  27.449312210083008
-------------------------------
Vision time :  85.46489715576172
Action time :  110.53260803222656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.914688110351562
-------------------------------
-------------------------------
model running time:  8.48691177368164
-------------------------------
-------------------------------
model running time:  27.827232360839844
-------------------------------
-------------------------------
model running time:  10.486751556396484
-------------------------------
-------------------------------
model running time:  30.527488708496094
-------------------------------
Vision time :  85.46131134033203
Action time :  111.23404693603516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.11097526550293
-------------------------------
-------------------------------
model running time:  8.409024238586426
-------------------------------
-------------------------------
model running time:  27.60089683532715
-------------------------------
-------------------------------
model running time:  10.491904258728027
-------------------------------
-------------------------------
model running time:  27.464704513549805
-------------------------------
Vision time :  85.40975952148438
Action time :  106.65164947509766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 16%|â–ˆâ–Œ        | 4/25 [00:09<00:50,  2.43s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.958688735961914
-------------------------------
-------------------------------
model running time:  8.43769645690918
-------------------------------
-------------------------------
model running time:  27.465728759765625
-------------------------------
-------------------------------
model running time:  10.44275188446045
-------------------------------
-------------------------------
model running time:  27.331552505493164
-------------------------------
Vision time :  85.46991729736328
Action time :  109.60896301269531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.280960083007812
-------------------------------
-------------------------------
model running time:  8.6046724319458
-------------------------------
-------------------------------
model running time:  27.654016494750977
-------------------------------
-------------------------------
model running time:  10.539008140563965
-------------------------------
-------------------------------
model running time:  34.530303955078125
-------------------------------
Vision time :  85.46672058105469
Action time :  113.0384292602539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.31679916381836
-------------------------------
-------------------------------
model running time:  8.506367683410645
-------------------------------
-------------------------------
model running time:  27.621376037597656
-------------------------------
-------------------------------
model running time:  10.529791831970215
-------------------------------
-------------------------------
model running time:  27.462656021118164
-------------------------------
Vision time :  85.47856140136719
Action time :  105.45868682861328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.1529598236084
-------------------------------
-------------------------------
model running time:  8.39782428741455
-------------------------------
-------------------------------
model running time:  27.563007354736328
-------------------------------
-------------------------------
model running time:  10.515551567077637
-------------------------------
-------------------------------
model running time:  27.469823837280273
-------------------------------
Vision time :  85.4651870727539
Action time :  105.09209442138672
Trial 4 finished, success: tensor([True]), steps: 112
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.09676742553711
-------------------------------
-------------------------------
model running time:  8.39577579498291
-------------------------------
-------------------------------
model running time:  27.690975189208984
-------------------------------
-------------------------------
model running time:  10.507264137268066
-------------------------------
-------------------------------
model running time:  28.001279830932617
-------------------------------
Vision time :  85.44239807128906
Action time :  105.47814178466797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.54867172241211
-------------------------------
-------------------------------
model running time:  8.51353645324707
-------------------------------
-------------------------------
model running time:  27.842559814453125
-------------------------------
-------------------------------
model running time:  10.62399959564209
-------------------------------
-------------------------------
model running time:  27.54252815246582
-------------------------------
Vision time :  85.47901153564453
Action time :  106.9343032836914
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.55628776550293
-------------------------------
-------------------------------
model running time:  8.467455863952637
-------------------------------
-------------------------------
model running time:  27.579391479492188
-------------------------------
-------------------------------
model running time:  10.485759735107422
-------------------------------
-------------------------------
model running time:  30.457855224609375
-------------------------------
Vision time :  85.47443389892578
Action time :  110.41382598876953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.166271209716797
-------------------------------
-------------------------------
model running time:  8.417280197143555
-------------------------------
-------------------------------
model running time:  27.55788803100586
-------------------------------
-------------------------------
model running time:  10.492927551269531
-------------------------------
-------------------------------
model running time:  27.7391357421875
-------------------------------
Vision time :  85.5130844116211
Action time :  105.14329528808594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952

 20%|â–ˆâ–ˆ        | 5/25 [00:11<00:45,  2.29s/it][A[A

 24%|â–ˆâ–ˆâ–       | 6/25 [00:14<00:42,  2.24s/it][A[A
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.235904693603516
-------------------------------
-------------------------------
model running time:  8.42137622833252
-------------------------------
-------------------------------
model running time:  27.510784149169922
-------------------------------
-------------------------------
model running time:  10.53286361694336
-------------------------------
-------------------------------
model running time:  32.21196746826172
-------------------------------
Vision time :  85.45891571044922
Action time :  109.8424301147461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.765888214111328
-------------------------------
-------------------------------
model running time:  8.39577579498291
-------------------------------
-------------------------------
model running time:  27.708351135253906
-------------------------------
-------------------------------
model running time:  10.533920288085938
-------------------------------
-------------------------------
model running time:  31.718399047851562
-------------------------------
Vision time :  85.42857360839844
Action time :  108.86144256591797
Trial 5 finished, success: tensor([True]), steps: 85
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.93071937561035
-------------------------------
-------------------------------
model running time:  8.434687614440918
-------------------------------
-------------------------------
model running time:  27.59894371032715
-------------------------------
-------------------------------
model running time:  10.5513277053833
-------------------------------
-------------------------------
model running time:  27.45142364501953
-------------------------------
Vision time :  85.4513931274414
Action time :  104.59648132324219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92460823059082
-------------------------------
-------------------------------
model running time:  8.470527648925781
-------------------------------
-------------------------------
model running time:  27.668319702148438
-------------------------------
-------------------------------
model running time:  10.536959648132324
-------------------------------
-------------------------------
model running time:  27.492351531982422
-------------------------------
Vision time :  85.4738540649414
Action time :  104.79510498046875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.783296585083008
-------------------------------
-------------------------------
model running time:  8.415360450744629
-------------------------------
-------------------------------
model running time:  29.97043228149414
-------------------------------
-------------------------------
model running time:  10.534815788269043
-------------------------------
-------------------------------
model running time:  27.380704879760742
-------------------------------
Vision time :  85.44989013671875
Action time :  109.85164642333984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.079423904418945
-------------------------------
-------------------------------
model running time:  8.537088394165039
-------------------------------
-------------------------------
model running time:  28.147647857666016
-------------------------------
-------------------------------
model running time:  10.62604808807373
-------------------------------
-------------------------------
model running time:  28.114944458007812
-------------------------------
Vision time :  85.4501724243164
Action time :  111.51062774658203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.886432647705078
-------------------------------
-------------------------------
model running time:  8.498175621032715
-------------------------------
-------------------------------
model running time:  28.669952392578125
-------------------------------
-------------------------------
model running time:  10.539008140563965
-------------------------------
-------------------------------
model running time:  27.786239624023438
-------------------------------
Vision time :  85.4933090209961
Action time :  108.22962951660156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.477567672729492
-------------------------------
-------------------------------
model running time:  8.466400146484375
-------------------------------
-------------------------------
model running time:  27.936800003051758
-------------------------------
-------------------------------
model running time:  20.206592559814453
-------------------------------
-------------------------------
model running time:  27.833343505859375
-------------------------------
Vision time :  85.48995208740234
Action time :  115.91065979003906
Trial 6 finished, success: tensor([True]), steps: 95
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:16<00:41,  2.32s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.288415908813477
-------------------------------
-------------------------------
model running time:  8.49510383605957
-------------------------------
-------------------------------
model running time:  28.03718376159668
-------------------------------
-------------------------------
model running time:  10.636223793029785
-------------------------------
-------------------------------
model running time:  27.72377586364746
-------------------------------
Vision time :  85.4441909790039
Action time :  107.0459213256836
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.895423889160156
-------------------------------
-------------------------------
model running time:  8.435711860656738
-------------------------------
-------------------------------
model running time:  27.985919952392578
-------------------------------
-------------------------------
model running time:  10.521599769592285
-------------------------------
-------------------------------
model running time:  27.704320907592773
-------------------------------
Vision time :  85.47779083251953
Action time :  113.3465576171875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.33670425415039
-------------------------------
-------------------------------
model running time:  8.491007804870605
-------------------------------
-------------------------------
model running time:  28.045408248901367
-------------------------------
-------------------------------
model running time:  10.52672004699707
-------------------------------
-------------------------------
model running time:  27.84569549560547
-------------------------------
Vision time :  85.60476684570312
Action time :  107.54550170898438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.067487716674805
-------------------------------
-------------------------------
model running time:  8.487936019897461
-------------------------------
-------------------------------
model running time:  28.003328323364258
-------------------------------
-------------------------------
model running time:  10.557439804077148
-------------------------------
-------------------------------
model running time:  33.068031311035156
-------------------------------
Vision time :  85.48489379882812
Action time :  112.09420776367188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.619903564453125
-------------------------------
-------------------------------
model running time:  8.441856384277344
-------------------------------
-------------------------------
model running time:  28.11084747314453
-------------------------------
-------------------------------
model running time:  10.495039939880371
-------------------------------
-------------------------------
model running time:  27.913087844848633
-------------------------------
Vision time :  85.55033874511719
Action time :  106.57587432861328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.53081512451172
-------------------------------
-------------------------------
model running time:  8.465408325195312
-------------------------------
-------------------------------
model running time:  27.970592498779297
-------------------------------
-------------------------------
model running time:  10.586112022399902
-------------------------------
-------------------------------
model running time:  28.644351959228516
-------------------------------
Vision time :  85.49385833740234
Action time :  107.01618957519531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.74278450012207
-------------------------------
-------------------------------
model running time:  8.477696418762207
-------------------------------
-------------------------------
model running time:  28.32793617248535
-------------------------------
-------------------------------
model running time:  10.554368019104004
-------------------------------
-------------------------------
model running time:  33.39468765258789
-------------------------------
Vision time :  85.47942352294922
Action time :  112.73113250732422
Trial 7 finished, success: tensor([True]), steps: 108
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.665983200073242
-------------------------------
-------------------------------
model running time:  8.50534439086914
-------------------------------
-------------------------------
model running time:  34.08588790893555
-------------------------------
-------------------------------
model running time:  10.65881633758545
-------------------------------
-------------------------------
model running time:  28.137407302856445
-------------------------------
Vision time :  85.49791717529297
Action time :  112.94412994384766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:19<00:44,  2.64s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.634239196777344
-------------------------------
-------------------------------
model running time:  8.530943870544434
-------------------------------
-------------------------------
model running time:  28.156831741333008
-------------------------------
-------------------------------
model running time:  10.560511589050293
-------------------------------
-------------------------------
model running time:  28.006271362304688
-------------------------------
Vision time :  85.47039794921875
Action time :  106.90361785888672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.808223724365234
-------------------------------
-------------------------------
model running time:  8.523743629455566
-------------------------------
-------------------------------
model running time:  28.16307258605957
-------------------------------
-------------------------------
model running time:  10.661888122558594
-------------------------------
-------------------------------
model running time:  27.933696746826172
-------------------------------
Vision time :  85.5567398071289
Action time :  107.12678527832031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.5031681060791
-------------------------------
-------------------------------
model running time:  8.455167770385742
-------------------------------
-------------------------------
model running time:  39.135231018066406
-------------------------------
-------------------------------
model running time:  10.618847846984863
-------------------------------
-------------------------------
model running time:  28.060672760009766
-------------------------------
Vision time :  85.49542236328125
Action time :  117.65555572509766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.32646369934082
-------------------------------
-------------------------------
model running time:  15.856639862060547
-------------------------------
-------------------------------
model running time:  27.850624084472656
-------------------------------
-------------------------------
model running time:  10.570752143859863
-------------------------------
-------------------------------
model running time:  27.888639450073242
-------------------------------
Vision time :  85.52416229248047
Action time :  114.50975799560547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.286239624023438
-------------------------------
-------------------------------
model running time:  8.456192016601562
-------------------------------
-------------------------------
model running time:  27.921279907226562
-------------------------------
-------------------------------
model running time:  10.534751892089844
-------------------------------
-------------------------------
model running time:  27.665407180786133
-------------------------------
Vision time :  85.50841522216797
Action time :  108.89411163330078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.635263442993164
-------------------------------
-------------------------------
model running time:  8.484864234924316
-------------------------------
-------------------------------
model running time:  34.90611267089844
-------------------------------
-------------------------------
model running time:  10.571776390075684
-------------------------------
-------------------------------
model running time:  27.76464080810547
-------------------------------
Vision time :  85.50070190429688
Action time :  113.89328002929688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.636287689208984
-------------------------------
-------------------------------
model running time:  8.468480110168457
-------------------------------
-------------------------------
model running time:  27.96441650390625
-------------------------------
-------------------------------
model running time:  10.545151710510254
-------------------------------
-------------------------------
model running time:  35.4969596862793
-------------------------------
Vision time :  85.48387145996094
Action time :  114.36646270751953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.547040939331055
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  33.80223846435547
-------------------------------
-------------------------------
model running time:  10.51039981842041
-------------------------------
-------------------------------
model running time:  27.915264129638672
-------------------------------
Vision time :  85.49209594726562
Action time :  112.8458251953125
Trial 8 finished, success: tensor([True]), steps: 137
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.565759658813477
-------------------------------
-------------------------------
model running time:  8.484864234924316
-------------------------------
-------------------------------
model running time:  28.025856018066406
-------------------------------
-------------------------------
model running time:  10.552319526672363
-------------------------------
-------------------------------
model running time:  27.840511322021484
-------------------------------
Vision time :  85.49552154541016
Action time :  107.27629089355469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.024959564208984
-------------------------------
-------------------------------
model running time:  8.525823593139648
-------------------------------
-------------------------------
model running time:  28.182527542114258
-------------------------------
-------------------------------
model running time:  10.521599769592285
-------------------------------
-------------------------------
model running time:  28.10982322692871
-------------------------------
Vision time :  85.50418853759766
Action time :  106.5195541381836
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.074111938476562
-------------------------------
-------------------------------
model running time:  8.42956829071045
-------------------------------
-------------------------------
model running time:  27.72275161743164
-------------------------------
-------------------------------
model running time:  10.516480445861816
-------------------------------
-------------------------------
model running time:  27.56096076965332
-------------------------------
Vision time :  85.51494598388672
Action time :  106.4632339477539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.084352493286133
-------------------------------
-------------------------------
model running time:  8.472576141357422
-------------------------------
-------------------------------
model running time:  27.69715118408203
-------------------------------
-------------------------------
model running time:  10.593279838562012
-------------------------------
-------------------------------
model running time:  27.664384841918945
-------------------------------
Vision time :  85.46281433105469
Action time :  105.61238098144531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.858047485351562
-------------------------------
-------------------------------
model running time:  8.468480110168457
-------------------------------
-------------------------------
model running time:  27.73811149597168
-------------------------------
-------------------------------
model running time:  10.52774429321289
-------------------------------
-------------------------------
model running time:  31.455232620239258
-------------------------------
Vision time :  85.47206115722656
Action time :  109.29971313476562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.003456115722656
-------------------------------
-------------------------------
model running time:  8.465408325195312
-------------------------------
-------------------------------
model running time:  27.768831253051758
-------------------------------
-------------------------------
model running time:  10.546143531799316
-------------------------------
-------------------------------
model running time:  27.567232131958008
-------------------------------
Vision time :  85.46572875976562
Action time :  105.57440185546875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.164384841918945
-------------------------------
-------------------------------
model running time:  8.435711860656738
-------------------------------
-------------------------------
model running time:  28.037120819091797
-------------------------------
-------------------------------
model running time:  10.522624015808105
-------------------------------
-------------------------------
model running time:  32.273406982421875
-------------------------------
Vision time :  85.46729278564453
Action time :  110.38105773925781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.768192291259766
-------------------------------
-------------------------------
model running time:  13.442048072814941
-------------------------------
-------------------------------
model running time:  28.296192169189453
-------------------------------
-------------------------------
model running time:  10.534912109375
-------------------------------
-------------------------------
model running time:  28.069887161254883
-------------------------------
Vision time :  85.48297882080078
Action time :  113.67727661132812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 


 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:23<00:45,  2.86s/it][A[A

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:25<00:39,  2.66s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.235776901245117
-------------------------------
-------------------------------
model running time:  8.49510383605957
-------------------------------
-------------------------------
model running time:  28.35456085205078
-------------------------------
-------------------------------
model running time:  10.537983894348145
-------------------------------
-------------------------------
model running time:  28.004352569580078
-------------------------------
Vision time :  85.49024200439453
Action time :  107.30496215820312
Trial 9 finished, success: tensor([True]), steps: 139
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.10483169555664
-------------------------------
-------------------------------
model running time:  8.473600387573242
-------------------------------
-------------------------------
model running time:  28.431360244750977
-------------------------------
-------------------------------
model running time:  16.277568817138672
-------------------------------
-------------------------------
model running time:  28.19481658935547
-------------------------------
Vision time :  85.45311737060547
Action time :  112.15769958496094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.994272232055664
-------------------------------
-------------------------------
model running time:  8.464384078979492
-------------------------------
-------------------------------
model running time:  27.84988784790039
-------------------------------
-------------------------------
model running time:  10.556415557861328
-------------------------------
-------------------------------
model running time:  35.64656066894531
-------------------------------
Vision time :  85.4853744506836
Action time :  113.28717041015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  38.21577453613281
-------------------------------
-------------------------------
model running time:  12.286111831665039
-------------------------------
-------------------------------
model running time:  40.597503662109375
-------------------------------
-------------------------------
model running time:  15.484031677246094
-------------------------------
-------------------------------
model running time:  55.16185760498047
-------------------------------
Vision time :  85.45641326904297
Action time :  167.9615936279297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.006528854370117
-------------------------------
-------------------------------
model running time:  12.575743675231934
-------------------------------
-------------------------------
model running time:  27.72480010986328
-------------------------------
-------------------------------
model running time:  10.492927551269531
-------------------------------
-------------------------------
model running time:  27.410432815551758
-------------------------------
Vision time :  85.465087890625
Action time :  108.91366577148438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.48691177368164
-------------------------------
-------------------------------
model running time:  8.507391929626465
-------------------------------
-------------------------------
model running time:  27.797504425048828
-------------------------------
-------------------------------
model running time:  10.554368019104004
-------------------------------
-------------------------------
model running time:  30.867456436157227
-------------------------------
Vision time :  85.45884704589844
Action time :  108.90035247802734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.5732479095459
-------------------------------
-------------------------------
model running time:  8.521727561950684
-------------------------------
-------------------------------
model running time:  27.95110321044922
-------------------------------
-------------------------------
model running time:  10.577919960021973
-------------------------------
-------------------------------
model running time:  27.778047561645508
-------------------------------
Vision time :  85.55500793457031
Action time :  108.55731201171875
Trial 10 finished, success: tensor([True]), steps: 85
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.946016311645508
-------------------------------
-------------------------------
model running time:  8.50534439086914
-------------------------------
-------------------------------
model running time:  27.784160614013672
-------------------------------
-------------------------------
model running time:  10.560511589050293
-------------------------------
-------------------------------
model running time:  27.839487075805664
-------------------------------
Vision time :  85.51251220703125
Action time :  105.16182708740234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.15657615661621
-------------------------------
-------------------------------
model running time:  8.523776054382324
-------------------------------
-------------------------------
model running time:  33.75001525878906
-------------------------------
-------------------------------
model running time:  10.513407707214355
-------------------------------
-------------------------------
model running time:  27.602975845336914
-------------------------------
Vision time :  85.49628448486328
Action time :  112.26214599609375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.962495803833008
-------------------------------
-------------------------------
model running time:  8.459263801574707
-------------------------------
-------------------------------
model running time:  27.71660804748535
-------------------------------
-------------------------------
model running time:  10.487808227539062
-------------------------------
-------------------------------
model running time:  27.48201560974121
-------------------------------
Vision time :  85.51849365234375
Action time :  104.93440246582031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.14476776123047
-------------------------------
-------------------------------
model running time:  8.484864234924316
-------------------------------
-------------------------------
model running time:  27.682815551757812
-------------------------------
-------------------------------
model running time:  10.499103546142578
-------------------------------
-------------------------------
model running time:  27.494400024414062
-------------------------------
Vision time :  85.51526641845703
Action time :  105.02230072021484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.694015502929688
-------------------------------
-------------------------------
model running time:  8.454015731811523
-------------------------------
-------------------------------
model running time:  27.778047561645508
-------------------------------
-------------------------------
model running time:  10.447872161865234
-------------------------------
-------------------------------
model running time:  27.55583953857422
-------------------------------
Vision time :  85.50768280029297
Action time :  108.6924819946289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.038272857666016
-------------------------------
-------------------------------
model running time:  8.46735954284668
-------------------------------
-------------------------------
model running time:  36.51679992675781
-------------------------------
-------------------------------
model running time:  10.481568336486816
-------------------------------
-------------------------------
model running time:  27.589632034301758
-------------------------------
Vision time :  85.48941040039062
Action time :  113.89740753173828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.801536560058594
-------------------------------
-------------------------------
model running time:  8.50432014465332
-------------------------------
-------------------------------
model running time:  27.761695861816406
-------------------------------
-------------------------------
model running time:  10.529760360717773
-------------------------------
-------------------------------
model running time:  27.451391220092773
-------------------------------
Vision time :  85.52073669433594
Action time :  112.14131164550781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.93484878540039
-------------------------------
-------------------------------
model running time:  8.424448013305664
-------------------------------
-------------------------------
model running time:  27.704320907592773
-------------------------------
-------------------------------
model running time:  10.490880012512207
-------------------------------
-------------------------------
model running time:  27.547744750976562
-------------------------------
Vision time :  85.48258972167969
Action time :  104.85247802734375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.580543518066406
-------------------------------
-------------------------------
model running time:  8.39680004119873
-------------------------------
-------------------------------
model running time:  27.596799850463867
-------------------------------
-------------------------------
model running time:  10.488672256469727
-------------------------------
-------------------------------
model running time:  27.541471481323242
-------------------------------
Vision time :  85.47555541992188
Action time :  104.09369659423828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.498624801635742
-------------------------------
-------------------------------
model running time:  8.414079666137695
-------------------------------
-------------------------------
model running time:  27.5230712890625
-------------------------------
-------------------------------
model running time:  10.519552230834961
-------------------------------
-------------------------------
model running time:  27.529216766357422
-------------------------------
Vision time :  85.46435546875
Action time :  104.74700927734375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.383935928344727
-------------------------------
-------------------------------
model running time:  8.36905574798584
-------------------------------
-------------------------------
model running time:  27.56710433959961
-------------------------------
-------------------------------
model running time:  10.620767593383789
-------------------------------
-------------------------------
model running time:  27.521024703979492
-------------------------------
Vision time :  85.45494079589844
Action time :  104.34867095947266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.778175354003906
-------------------------------
-------------------------------
model running time:  8.447104454040527
-------------------------------
-------------------------------
model running time:  27.856992721557617
-------------------------------
-------------------------------
model running time:  10.539008140563965
-------------------------------
-------------------------------
model running time:  27.522048950195312
-------------------------------
Vision time :  85.48531341552734
Action time :  104.99788665771484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.081727981567383
-------------------------------
-------------------------------
model running time:  8.4868803024292
-------------------------------
-------------------------------
model running time:  27.74118423461914
-------------------------------
-------------------------------
model running time:  10.477567672729492
-------------------------------
-------------------------------
model running time:  27.502559661865234
-------------------------------
Vision time :  85.49846649169922
Action time :  106.34848022460938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.623552322387695
-------------------------------
-------------------------------
model running time:  8.473600387573242
-------------------------------
-------------------------------
model running time:  27.489280700683594
-------------------------------
-------------------------------
model running time:  10.514592170715332
-------------------------------
-------------------------------
model running time:  27.398143768310547
-------------------------------
Vision time :  85.46345520019531
Action time :  104.29644775390625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.37164878845215
-------------------------------
-------------------------------
model running time:  8.355839729309082
-------------------------------
-------------------------------
model running time:  27.453439712524414
-------------------------------
-------------------------------
model running time:  10.508288383483887
-------------------------------
-------------------------------
model running time:  27.445247650146484
-------------------------------
Vision time :  85.46233367919922
Action time :  103.57955169677734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.563167572021484
-------------------------------
-------------------------------
model running time:  8.373248100280762
-------------------------------
-------------------------------
model running time:  27.31929588317871
-------------------------------
-------------------------------
model running time:  10.51852798461914
-------------------------------
-------------------------------
model running time:  27.259904861450195
-------------------------------
Vision time :  85.45878601074219
Action time :  103.86943817138672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.403392791748047
-------------------------------
-------------------------------
model running time:  8.433695793151855
-------------------------------
-------------------------------
model running time:  27.492351531982422
-------------------------------
-------------------------------
model running time:  10.44275188446045
-------------------------------
-------------------------------
model running time:  27.34079933166504
-------------------------------
Vision time :  85.5021743774414
Action time :  104.19097900390625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048


 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:34<01:03,  4.57s/it][A[A-------------------------------
model running time:  25.291776657104492
-------------------------------
-------------------------------
model running time:  8.434687614440918
-------------------------------
-------------------------------
model running time:  27.34796714782715
-------------------------------
-------------------------------
model running time:  10.480511665344238
-------------------------------
-------------------------------
model running time:  27.244543075561523
-------------------------------
Vision time :  85.54096221923828
Action time :  104.06604766845703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.979904174804688
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  27.686912536621094
-------------------------------
-------------------------------
model running time:  10.52569580078125
-------------------------------
-------------------------------
model running time:  27.454463958740234
-------------------------------
Vision time :  85.4955825805664
Action time :  105.83654022216797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.661439895629883
-------------------------------
-------------------------------
model running time:  8.409088134765625
-------------------------------
-------------------------------
model running time:  27.62335968017578
-------------------------------
-------------------------------
model running time:  10.53388786315918
-------------------------------
-------------------------------
model running time:  27.487232208251953
-------------------------------
Vision time :  85.48751831054688
Action time :  104.39785766601562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.643007278442383
-------------------------------
-------------------------------
model running time:  8.452095985412598
-------------------------------
-------------------------------
model running time:  27.57734489440918
-------------------------------
-------------------------------
model running time:  10.506239891052246
-------------------------------
-------------------------------
model running time:  27.56003189086914
-------------------------------
Vision time :  85.47315216064453
Action time :  104.96205139160156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.68294334411621
-------------------------------
-------------------------------
model running time:  8.417280197143555
-------------------------------
-------------------------------
model running time:  27.512672424316406
-------------------------------
-------------------------------
model running time:  10.541055679321289
-------------------------------
-------------------------------
model running time:  27.399168014526367
-------------------------------
Vision time :  85.54265594482422
Action time :  104.65996551513672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.5467529296875
-------------------------------
-------------------------------
model running time:  8.427519798278809
-------------------------------
-------------------------------
model running time:  27.54150390625
-------------------------------
-------------------------------
model running time:  10.53388786315918
-------------------------------
-------------------------------
model running time:  27.399168014526367
-------------------------------
Vision time :  85.5564193725586
Action time :  104.59136199951172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.380863189697266
-------------------------------
-------------------------------
model running time:  8.378368377685547
-------------------------------
-------------------------------
model running time:  27.481088638305664
-------------------------------
-------------------------------
model running time:  10.524736404418945
-------------------------------
-------------------------------
model running time:  27.457536697387695
-------------------------------
Vision time :  85.52476501464844
Action time :  104.23296356201172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.248767852783203
-------------------------------
-------------------------------
model running time:  10.2041597366333
-------------------------------
-------------------------------
model running time:  27.498559951782227
-------------------------------
-------------------------------
model running time:  10.512384414672852
-------------------------------
-------------------------------
model running time:  27.374431610107422
-------------------------------
Vision time :  85.53206634521484
Action time :  105.88569641113281
Trial 11 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:36<00:49,  3.84s/it][A[A25.464736938476562
-------------------------------
-------------------------------
model running time:  8.579071998596191
-------------------------------
-------------------------------
model running time:  27.464576721191406
-------------------------------
-------------------------------
model running time:  10.520575523376465
-------------------------------
-------------------------------
model running time:  27.376544952392578
-------------------------------
Vision time :  85.5054702758789
Action time :  104.48998260498047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.264127731323242
-------------------------------
-------------------------------
model running time:  8.369152069091797
-------------------------------
-------------------------------
model running time:  27.392000198364258
-------------------------------
-------------------------------
model running time:  10.450943946838379
-------------------------------
-------------------------------
model running time:  27.392000198364258
-------------------------------
Vision time :  85.54236602783203
Action time :  104.04351806640625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.29680061340332
-------------------------------
-------------------------------
model running time:  8.370176315307617
-------------------------------
-------------------------------
model running time:  27.407487869262695
-------------------------------
-------------------------------
model running time:  10.520575523376465
-------------------------------
-------------------------------
model running time:  27.549535751342773
-------------------------------
Vision time :  85.50691223144531
Action time :  104.24832153320312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.37164878845215
-------------------------------
-------------------------------
model running time:  8.381440162658691
-------------------------------
-------------------------------
model running time:  27.31007957458496
-------------------------------
-------------------------------
model running time:  10.432512283325195
-------------------------------
-------------------------------
model running time:  27.310976028442383
-------------------------------
Vision time :  85.4728012084961
Action time :  103.66675567626953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.32863998413086
-------------------------------
-------------------------------
model running time:  8.353792190551758
-------------------------------
-------------------------------
model running time:  27.453439712524414
-------------------------------
-------------------------------
model running time:  10.531968116760254
-------------------------------
-------------------------------
model running time:  27.32441520690918
-------------------------------
Vision time :  85.47382354736328
Action time :  104.15936279296875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.454591751098633
-------------------------------
-------------------------------
model running time:  8.339455604553223
-------------------------------
-------------------------------
model running time:  27.405311584472656
-------------------------------
-------------------------------
model running time:  10.471424102783203
-------------------------------
-------------------------------
model running time:  27.396095275878906
-------------------------------
Vision time :  85.61039733886719
Action time :  103.98822021484375
Trial 12 finished, success: tensor([True]), steps: 95
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.614336013793945
-------------------------------
-------------------------------
model running time:  8.449024200439453
-------------------------------
-------------------------------
model running time:  27.70732879638672
-------------------------------
-------------------------------
model running time:  10.533791542053223
-------------------------------
-------------------------------
model running time:  27.44118309020996
-------------------------------
Vision time :  85.48560333251953
Action time :  104.30156707763672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.554943084716797
-------------------------------
-------------------------------
model running time:  8.41420841217041
-------------------------------
-------------------------------
model running time:  27.51590347290039
-------------------------------
-------------------------------
model running time:  10.511360168457031
-------------------------------
-------------------------------
model running time:  27.38585662841797
-------------------------------
Vision time :  85.61238098144531
Action time :  103.89491271972656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.31328010559082
-------------------------------
-------------------------------
model running time:  8.37939167022705
-------------------------------
-------------------------------
model running time:  27.412479400634766
-------------------------------
-------------------------------
model running time:  10.503007888793945
-------------------------------
-------------------------------
model running time:  27.34592056274414
-------------------------------
Vision time :  85.50118255615234
Action time :  103.44857788085938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.555967330932617
-------------------------------
-------------------------------
model running time:  8.319999694824219
-------------------------------
-------------------------------
model running time:  27.5230712890625
-------------------------------
-------------------------------
model running time:  10.452960014343262
-------------------------------
-------------------------------
model running time:  27.289567947387695
-------------------------------
Vision time :  85.48118591308594
Action time :  103.53977966308594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.670656204223633
-------------------------------
-------------------------------
model running time:  8.53001594543457
-------------------------------
-------------------------------
model running time:  27.505664825439453
-------------------------------
-------------------------------
model running time:  10.729439735412598
-------------------------------
-------------------------------
model running time:  27.494400024414062
-------------------------------
Vision time :  85.49203491210938
Action time :  104.31795501708984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.641984939575195
-------------------------------
-------------------------------
model running time:  8.410016059875488
-------------------------------
-------------------------------
model running time:  27.414527893066406
-------------------------------
-------------------------------
model running time:  10.446847915649414
-------------------------------
-------------------------------
model running time:  27.33465576171875
-------------------------------
Vision time :  85.60262298583984
Action time :  104.2092514038086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.08406448364258
-------------------------------
-------------------------------
model running time:  8.409088134765625
-------------------------------
-------------------------------
model running time:  27.458560943603516
-------------------------------
-------------------------------
model running time:  10.602496147155762
-------------------------------
-------------------------------
model running time:  27.34796714782715
-------------------------------
Vision time :  85.56195068359375
Action time :  111.21663665771484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.50886344909668
-------------------------------
-------------------------------
model running time:  8.366175651550293
-------------------------------
-------------------------------
model running time:  27.31622314453125
-------------------------------
-------------------------------
model running time:  10.491904258728027
-------------------------------
-------------------------------
model running time:  27.30601692199707
-------------------------------
Vision time :  85.49600219726562
Action time :  103.50694274902344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.425920486450195
-------------------------------
-------------------------------
model running time:  8.377440452575684
-------------------------------
-------------------------------
model running time:  27.56505584716797
-------------------------------
-------------------------------
model running time:  10.49392032623291
-------------------------------
-------------------------------
model running time:  27.479040145874023
-------------------------------
Vision time :  85.4994888305664
Action time :  104.38137817382812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.53340721130371
-------------------------------
-------------------------------
model running time:  8.467455863952637
-------------------------------
-------------------------------
model running time:  27.653120040893555
-------------------------------
-------------------------------
model running time:  10.553343772888184
-------------------------------
-------------------------------
model running time:  27.5230712890625
-------------------------------
Vision time :  85.48489379882812
Action time :  104.31283569335938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.020864486694336
-------------------------------
-------------------------------
model running time:  8.478719711303711
-------------------------------
-------------------------------


 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:42<00:52,  4.41s/it][A[Amodel running time:  27.44211196899414
-------------------------------
-------------------------------
model running time:  10.516480445861816
-------------------------------
-------------------------------
model running time:  27.50054359436035
-------------------------------
Vision time :  85.56956481933594
Action time :  104.65586853027344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.83340835571289
-------------------------------
-------------------------------
model running time:  8.446975708007812
-------------------------------
-------------------------------
model running time:  31.099903106689453
-------------------------------
-------------------------------
model running time:  10.476544380187988
-------------------------------
-------------------------------
model running time:  27.469728469848633
-------------------------------
Vision time :  85.48371124267578
Action time :  107.79344177246094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.787391662597656
-------------------------------
-------------------------------
model running time:  8.438783645629883
-------------------------------
-------------------------------
model running time:  27.50774383544922
-------------------------------
-------------------------------
model running time:  10.518655776977539
-------------------------------
-------------------------------
model running time:  27.415552139282227
-------------------------------
Vision time :  85.56937408447266
Action time :  104.42854309082031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.95020866394043
-------------------------------
-------------------------------
model running time:  9.537535667419434
-------------------------------
-------------------------------
model running time:  27.657215118408203
-------------------------------
-------------------------------
model running time:  10.549247741699219
-------------------------------
-------------------------------
model running time:  27.602943420410156
-------------------------------
Vision time :  85.5357437133789
Action time :  106.24822235107422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.810943603515625
-------------------------------
-------------------------------
model running time:  8.440832138061523
-------------------------------
-------------------------------
model running time:  32.559104919433594
-------------------------------
-------------------------------
model running time:  10.517663955688477
-------------------------------
-------------------------------
model running time:  27.443359375
-------------------------------
Vision time :  85.585693359375
Action time :  109.39801788330078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.738239288330078
-------------------------------
-------------------------------
model running time:  8.41427230834961
-------------------------------
-------------------------------
model running time:  27.53536033630371
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  27.381664276123047
-------------------------------
Vision time :  85.52448272705078
Action time :  104.78297424316406
Trial 13 finished, success: tensor([True]), steps: 254
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.56211280822754
-------------------------------
-------------------------------
model running time:  8.435711860656738
-------------------------------
-------------------------------
model running time:  27.5230712890625
-------------------------------
-------------------------------
model running time:  10.519552230834961
-------------------------------
-------------------------------
model running time:  27.636735916137695
-------------------------------
Vision time :  85.50006103515625
Action time :  104.08038330078125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.652223587036133
-------------------------------
-------------------------------
model running time:  8.491135597229004
-------------------------------
-------------------------------
model running time:  27.7554874420166
-------------------------------
-------------------------------
model running time:  10.626175880432129
-------------------------------
-------------------------------
model running time:  27.72368049621582
-------------------------------
Vision time :  85.58525085449219
Action time :  104.65280151367188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.73311996459961
-------------------------------
-------------------------------
model running time:  8.417247772216797
-------------------------------
-------------------------------
model running time:  34.928768157958984


 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:44<00:42,  3.84s/it][A[A-------------------------------
-------------------------------
model running time:  10.61683177947998
-------------------------------
-------------------------------
model running time:  27.570079803466797
-------------------------------
Vision time :  85.52140808105469
Action time :  111.95597076416016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.01958465576172
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  28.596223831176758
-------------------------------
-------------------------------
model running time:  10.431488037109375
-------------------------------
-------------------------------
model running time:  27.33875274658203
-------------------------------
Vision time :  85.5219497680664
Action time :  109.45433807373047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.749343872070312
-------------------------------
-------------------------------
model running time:  8.504256248474121
-------------------------------
-------------------------------
model running time:  27.57734489440918
-------------------------------
-------------------------------
model running time:  10.539104461669922
-------------------------------
-------------------------------
model running time:  27.488256454467773
-------------------------------
Vision time :  85.55619049072266
Action time :  104.58624267578125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.762815475463867
-------------------------------
-------------------------------
model running time:  8.398816108703613
-------------------------------
-------------------------------
model running time:  27.549663543701172
-------------------------------
-------------------------------
model running time:  10.516480445861816
-------------------------------
-------------------------------
model running time:  27.471872329711914
-------------------------------
Vision time :  85.52880096435547
Action time :  104.24217224121094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.556991577148438
-------------------------------
-------------------------------
model running time:  8.40601634979248
-------------------------------
-------------------------------
model running time:  33.29024124145508
-------------------------------
-------------------------------
model running time:  10.594304084777832
-------------------------------
-------------------------------
model running time:  27.617279052734375
-------------------------------
Vision time :  85.49513244628906
Action time :  110.01651000976562
Trial 14 finished, success: tensor([True]), steps: 112
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.885536193847656
-------------------------------
-------------------------------
model running time:  8.48691177368164
-------------------------------
-------------------------------
model running time:  27.839487075805664
-------------------------------
-------------------------------
model running time:  10.561535835266113
-------------------------------
-------------------------------
model running time:  27.48214340209961
-------------------------------
Vision time :  85.49443054199219
Action time :  104.94054412841797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.028064727783203
-------------------------------
-------------------------------
model running time:  8.60262393951416
-------------------------------
-------------------------------
model running time:  27.659168243408203
-------------------------------
-------------------------------
model running time:  10.499072074890137
-------------------------------
-------------------------------
model running time:  27.6408634185791
-------------------------------
Vision time :  85.55244445800781
Action time :  105.09414672851562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.954303741455078
-------------------------------
-------------------------------
model running time:  8.41215991973877
-------------------------------
-------------------------------
model running time:  27.64784049987793
-------------------------------
-------------------------------
model running time:  10.496000289916992
-------------------------------
-------------------------------
model running time:  27.56403160095215
-------------------------------
Vision time :  85.58838653564453
Action time :  106.66291046142578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.087615966796875
-------------------------------
-------------------------------
model running time:  8.451071739196777
-------------------------------
-------------------------------
model running time:  27.662336349487305
-------------------------------


 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:46<00:33,  3.31s/it][A[A-------------------------------
model running time:  11.544608116149902
-------------------------------
-------------------------------
model running time:  27.519039154052734
-------------------------------
Vision time :  85.55526733398438
Action time :  111.07737731933594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.868288040161133
-------------------------------
-------------------------------
model running time:  8.438655853271484
-------------------------------
-------------------------------
model running time:  27.673599243164062
-------------------------------
-------------------------------
model running time:  14.943231582641602
-------------------------------
-------------------------------
model running time:  27.736064910888672
-------------------------------
Vision time :  85.61984252929688
Action time :  109.28953552246094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.039199829101562
-------------------------------
-------------------------------
model running time:  8.491007804870605
-------------------------------
-------------------------------
model running time:  27.78313636779785
-------------------------------
-------------------------------
model running time:  10.50716781616211
-------------------------------
-------------------------------
model running time:  27.493375778198242
-------------------------------
Vision time :  85.67523193359375
Action time :  105.16889953613281
Trial 15 finished, success: tensor([True]), steps: 91
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.583040237426758
-------------------------------
-------------------------------
model running time:  8.464384078979492
-------------------------------
-------------------------------
model running time:  27.94803237915039
-------------------------------
-------------------------------
model running time:  10.52467155456543
-------------------------------
-------------------------------
model running time:  32.27648162841797
-------------------------------
Vision time :  85.55235290527344
Action time :  110.43106842041016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.842687606811523
-------------------------------
-------------------------------
model running time:  8.435808181762695
-------------------------------
-------------------------------
model running time:  27.470848083496094
-------------------------------
-------------------------------
model running time:  10.52672004699707
-------------------------------
-------------------------------
model running time:  27.407360076904297
-------------------------------
Vision time :  85.53036499023438
Action time :  104.29644775390625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92870330810547
-------------------------------
-------------------------------
model running time:  8.375295639038086
-------------------------------
-------------------------------
model running time:  30.82147216796875
-------------------------------
-------------------------------
model running time:  10.63219165802002
-------------------------------
-------------------------------
model running time:  27.43903923034668
-------------------------------
Vision time :  85.66063690185547
Action time :  107.88658905029297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.681760787963867
-------------------------------
-------------------------------
model running time:  8.39577579498291
-------------------------------
-------------------------------
model running time:  27.529216766357422
-------------------------------
-------------------------------
model running time:  11.857919692993164
-------------------------------
-------------------------------
model running time:  29.299711227416992
-------------------------------
Vision time :  85.79523468017578
Action time :  107.54032135009766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.76896095275879
-------------------------------
-------------------------------
model running time:  8.432640075683594
-------------------------------
-------------------------------
model running time:  27.414527893066406
-------------------------------
-------------------------------
model running time:  10.441727638244629
-------------------------------
-------------------------------
model running time:  33.719295501708984
-------------------------------
Vision time :  85.59110260009766
Action time :  111.3333740234375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.076128005981445
-------------------------------
-------------------------------
model running time:  8.432640075683594
-------------------------------
-------------------------------
model running time:  27.405311584472656
-------------------------------
-------------------------------
model running time:  10.47766399383545
-------------------------------
-------------------------------
model running time:  27.299840927124023
-------------------------------
Vision time :  85.63263702392578
Action time :  105.15046691894531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.047487258911133
-------------------------------
-------------------------------
model running time:  8.435711860656738
-------------------------------
-------------------------------
model running time:  27.380735397338867
-------------------------------
-------------------------------
model running time:  10.477567672729492
-------------------------------
-------------------------------
model running time:  27.510784149169922
-------------------------------
Vision time :  85.60425567626953
Action time :  105.34092712402344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.100736618041992
-------------------------------
-------------------------------
model running time:  8.388671875
-------------------------------
-------------------------------
model running time:  32.29283142089844
-------------------------------
-------------------------------
model running time:  10.499072074890137
-------------------------------
-------------------------------
model running time:  27.410432815551758
-------------------------------
Vision time :  85.64399719238281
Action time :  109.50137329101562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.13657569885254
-------------------------------
-------------------------------
model running time:  8.423423767089844
-------------------------------
-------------------------------
model running time:  27.399072647094727
-------------------------------
-------------------------------
model running time:  10.4202241897583
-------------------------------
-------------------------------
model running time:  27.29267120361328
-------------------------------
Vision time :  85.61923217773438
Action time :  105.11052703857422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.74822425842285
-------------------------------
-------------------------------
model running time:  8.442879676818848
-------------------------------
-------------------------------
model running time:  27.806720733642578
-------------------------------
-------------------------------
model running time:  10.53388786315918
-------------------------------
-------------------------------
model running time:  27.755680084228516
-------------------------------
Vision time :  85.72611236572266
Action time :  109.14918518066406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.228736877441406
-------------------------------
-------------------------------
model running time:  8.481951713562012
-------------------------------
-------------------------------
model running time:  30.436384201049805
-------------------------------
-------------------------------
model running time:  10.585087776184082
-------------------------------
-------------------------------
model running time:  27.661312103271484
-------------------------------
Vision time :  85.72089385986328
Action time :  108.74883270263672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.82592010498047
-------------------------------
-------------------------------
model running time:  8.464384078979492
-------------------------------
-------------------------------
model running time:  27.794431686401367
-------------------------------
-------------------------------
model running time:  10.487808227539062
-------------------------------
-------------------------------
model running time:  30.118911743164062
-------------------------------
Vision time :  85.7119369506836
Action time :  113.82681274414062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.0894718170166
-------------------------------
-------------------------------
model running time:  13.842432022094727
-------------------------------
-------------------------------
model running time:  27.867136001586914
-------------------------------
-------------------------------
model running time:  10.488832473754883
-------------------------------
-------------------------------
model running time:  27.76371192932129
-------------------------------
Vision time :  85.71062469482422
Action time :  112.77721405029297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.268672943115234
-------------------------------
-------------------------------
model running time:  8.476672172546387
-------------------------------
-------------------------------
model running time:  27.72377586364746
-------------------------------
-------------------------------
model running time:  10.481663703918457
-------------------------------
-------------------------------
model running time:  27.452415466308594
-------------------------------
Vision time :  85.6390380859375
Action time :  105.86009979248047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.583040237426758
-------------------------------
-------------------------------
model running time:  8.570943832397461
-------------------------------
-------------------------------
model running time:  28.402687072753906
-------------------------------
-------------------------------
model running time:  10.536959648132324
-------------------------------
-------------------------------
model running time:  27.797504425048828
-------------------------------
Vision time :  85.6522216796875
Action time :  107.18617248535156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.395647048950195
-------------------------------
-------------------------------
model running time:  8.556544303894043
-------------------------------
-------------------------------
model running time:  27.80771255493164
-------------------------------
-------------------------------
model running time:  10.519552230834961
-------------------------------
-------------------------------
model running time:  27.60099220275879
-------------------------------
Vision time :  85.68582153320312
Action time :  106.07011413574219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.279935836791992
-------------------------------
-------------------------------
model running time:  8.516608238220215
-------------------------------
-------------------------------
model running time:  27.719680786132812
-------------------------------
-------------------------------
model running time:  10.606592178344727
-------------------------------
-------------------------------
model running time:  27.91321563720703
-------------------------------
Vision time :  85.68758392333984
Action time :  106.25321960449219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.33523178100586
-------------------------------
-------------------------------
model running time:  8.423423767089844
-------------------------------
-------------------------------
model running time:  27.621376037597656
-------------------------------
-------------------------------
model running time:  10.576895713806152
-------------------------------
-------------------------------
model running time:  27.421823501586914
-------------------------------
Vision time :  85.7081298828125
Action time :  105.18220520019531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.31167984008789
-------------------------------
-------------------------------
model running time:  8.483839988708496
-------------------------------
-------------------------------
model running time:  27.690975189208984
-------------------------------
-------------------------------
model running time:  10.529791831970215
-------------------------------
-------------------------------
model running time:  28.01571273803711
-------------------------------
Vision time :  85.5860824584961
Action time :  106.57894134521484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.609216690063477
-------------------------------
-------------------------------
model running time:  8.398816108703613
-------------------------------
-------------------------------
model running time:  27.55174446105957
-------------------------------
-------------------------------
model running time:  16.935935974121094
-------------------------------
-------------------------------
model running time:  27.5548152923584
-------------------------------
Vision time :  85.62518310546875
Action time :  111.52793884277344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.772031784057617
-------------------------------
-------------------------------
model running time:  8.388640403747559
-------------------------------
-------------------------------
model running time:  27.445280075073242
-------------------------------
-------------------------------
model running time:  10.499072074890137
-------------------------------
-------------------------------
model running time:  27.602943420410156
-------------------------------
Vision time :  85.59458923339844
Action time :  104.62092590332031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.00556755065918
-------------------------------
-------------------------------
model running time:  8.504159927368164
-------------------------------
-------------------------------
model running time:  27.77292823791504
-------------------------------
-------------------------------
model running time:  10.51750373840332
-------------------------------
-------------------------------
model running time:  27.55174446105957
-------------------------------
Vision time :  85.69750213623047
Action time :  105.43411254882812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:55<00:45,  5.00s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.064895629882812
-------------------------------
-------------------------------
model running time:  8.453120231628418
-------------------------------
-------------------------------
model running time:  27.76576042175293
-------------------------------
-------------------------------
model running time:  10.588159561157227
-------------------------------
-------------------------------
model running time:  27.68275260925293
-------------------------------
Vision time :  85.58979034423828
Action time :  106.0864028930664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  35.32697677612305
-------------------------------
-------------------------------
model running time:  8.48681640625
-------------------------------
-------------------------------
model running time:  27.835391998291016
-------------------------------
-------------------------------
model running time:  10.529791831970215
-------------------------------
-------------------------------
model running time:  27.663360595703125
-------------------------------
Vision time :  85.64640045166016
Action time :  114.86617279052734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.981952667236328
-------------------------------
-------------------------------
model running time:  8.450048446655273
-------------------------------
-------------------------------
model running time:  27.727872848510742
-------------------------------
-------------------------------
model running time:  10.502143859863281
-------------------------------
-------------------------------
model running time:  32.78643035888672
-------------------------------
Vision time :  85.59910583496094
Action time :  110.85004425048828
Trial 16 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.14067268371582
-------------------------------
-------------------------------
model running time:  8.55958366394043
-------------------------------
-------------------------------
model running time:  27.94291114807129
-------------------------------
-------------------------------
model running time:  10.567680358886719
-------------------------------
-------------------------------
model running time:  27.65622329711914
-------------------------------
Vision time :  85.59945678710938
Action time :  105.70457458496094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.845760345458984
-------------------------------
-------------------------------
model running time:  8.483839988708496
-------------------------------
-------------------------------
model running time:  27.915231704711914
-------------------------------
-------------------------------
model running time:  10.60863971710205
-------------------------------
-------------------------------
model running time:  27.899808883666992
-------------------------------
Vision time :  85.60851287841797
Action time :  105.85804748535156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.71673583984375
-------------------------------
-------------------------------
model running time:  8.401920318603516
-------------------------------
-------------------------------
model running time:  27.51081657409668
-------------------------------
-------------------------------
model running time:  10.567647933959961
-------------------------------
-------------------------------
model running time:  28.37401580810547
-------------------------------
Vision time :  85.60249328613281
Action time :  105.46995544433594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.54924774169922
-------------------------------
-------------------------------
model running time:  8.468480110168457
-------------------------------
-------------------------------
model running time:  27.487295150756836
-------------------------------
-------------------------------
model running time:  10.44377613067627
-------------------------------
-------------------------------
model running time:  27.373600006103516
-------------------------------
Vision time :  85.75593566894531
Action time :  105.27037048339844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.091712951660156
-------------------------------
-------------------------------
model running time:  8.469504356384277
-------------------------------
-------------------------------
model running time:  27.5150089263916
-------------------------------
-------------------------------
model running time:  10.458111763000488
-------------------------------
-------------------------------
model running time:  37.47942352294922
-------------------------------
Vision time :  85.66201782226562
Action time :  120.14694213867188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:58<00:34,  4.27s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  35.84716796875
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  27.479040145874023
-------------------------------
-------------------------------
model running time:  10.476544380187988
-------------------------------
-------------------------------
model running time:  27.32249641418457
-------------------------------
Vision time :  85.65570831298828
Action time :  114.27635192871094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.914304733276367
-------------------------------
-------------------------------
model running time:  8.492032051086426
-------------------------------
-------------------------------
model running time:  27.726911544799805
-------------------------------
-------------------------------
model running time:  10.539008140563965
-------------------------------
-------------------------------
model running time:  31.261728286743164
-------------------------------
Vision time :  85.76083374023438
Action time :  108.63616180419922
Trial 17 finished, success: tensor([True]), steps: 112
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.91641616821289
-------------------------------
-------------------------------
model running time:  8.652799606323242
-------------------------------
-------------------------------
model running time:  34.875423431396484
-------------------------------
-------------------------------
model running time:  10.583040237426758
-------------------------------
-------------------------------
model running time:  27.484159469604492
-------------------------------
Vision time :  85.65100860595703
Action time :  112.1864013671875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.846080780029297
-------------------------------
-------------------------------
model running time:  8.467488288879395
-------------------------------
-------------------------------
model running time:  27.49951934814453
-------------------------------
-------------------------------
model running time:  10.531840324401855
-------------------------------
-------------------------------
model running time:  27.613183975219727
-------------------------------
Vision time :  85.61027526855469
Action time :  107.70015716552734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.60825729370117
-------------------------------
-------------------------------
model running time:  8.499199867248535
-------------------------------
-------------------------------
model running time:  27.7391357421875
-------------------------------
-------------------------------
model running time:  10.568703651428223
-------------------------------
-------------------------------
model running time:  27.599872589111328
-------------------------------
Vision time :  85.5999984741211
Action time :  111.892578125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89695930480957
-------------------------------
-------------------------------
model running time:  8.481792449951172
-------------------------------
-------------------------------
model running time:  27.659168243408203
-------------------------------
-------------------------------
model running time:  10.505215644836426
-------------------------------
-------------------------------
model running time:  33.69075012207031
-------------------------------
Vision time :  85.61052703857422
Action time :  110.8460464477539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.995264053344727
-------------------------------
-------------------------------
model running time:  8.470527648925781
-------------------------------
-------------------------------
model running time:  28.609535217285156
-------------------------------
-------------------------------
model running time:  10.54412841796875
-------------------------------
-------------------------------
model running time:  34.543617248535156
-------------------------------
Vision time :  85.61036682128906
Action time :  112.94822692871094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.885696411132812
-------------------------------
-------------------------------
model running time:  8.376352310180664
-------------------------------
-------------------------------
model running time:  27.607040405273438
-------------------------------
-------------------------------
model running time:  10.507295608520508
-------------------------------
-------------------------------
model running time:  27.549728393554688
-------------------------------
Vision time :  85.60944366455078
Action time :  104.59760284423828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [01:03<00:30,  4.38s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.12019157409668
-------------------------------
-------------------------------
model running time:  8.472448348999023
-------------------------------
-------------------------------
model running time:  31.99692726135254
-------------------------------
-------------------------------
model running time:  10.52672004699707
-------------------------------
-------------------------------
model running time:  27.421695709228516
-------------------------------
Vision time :  85.74291229248047
Action time :  109.32736206054688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.856000900268555
-------------------------------
-------------------------------
model running time:  8.492959976196289
-------------------------------
-------------------------------
model running time:  35.74467086791992
-------------------------------
-------------------------------
model running time:  10.537983894348145
-------------------------------
-------------------------------
model running time:  27.645952224731445
-------------------------------
Vision time :  85.68204498291016
Action time :  112.8990707397461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.413055419921875
-------------------------------
-------------------------------
model running time:  8.363007545471191
-------------------------------
-------------------------------
model running time:  31.76959991455078
-------------------------------
-------------------------------
model running time:  10.58521556854248
-------------------------------
-------------------------------
model running time:  27.618303298950195
-------------------------------
Vision time :  85.70470428466797
Action time :  109.36115264892578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.651168823242188
-------------------------------
-------------------------------
model running time:  8.416192054748535
-------------------------------
-------------------------------
model running time:  27.35513687133789
-------------------------------
-------------------------------
model running time:  10.458111763000488
-------------------------------
-------------------------------
model running time:  27.324352264404297
-------------------------------
Vision time :  85.6908187866211
Action time :  103.86115264892578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.952255249023438
-------------------------------
-------------------------------
model running time:  8.424448013305664
-------------------------------
-------------------------------
model running time:  27.703296661376953
-------------------------------
-------------------------------
model running time:  16.22211265563965
-------------------------------
-------------------------------
model running time:  27.36742401123047
-------------------------------
Vision time :  85.70854187011719
Action time :  110.487548828125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.442623138427734
-------------------------------
-------------------------------
model running time:  9.745408058166504
-------------------------------
-------------------------------
model running time:  31.478784561157227
-------------------------------
-------------------------------
model running time:  10.550271987915039
-------------------------------
-------------------------------
model running time:  27.683839797973633
-------------------------------
Vision time :  85.71084594726562
Action time :  112.87760162353516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89081573486328
-------------------------------
-------------------------------
model running time:  8.434687614440918
-------------------------------
-------------------------------
model running time:  31.069183349609375
-------------------------------
-------------------------------
model running time:  10.463232040405273
-------------------------------
-------------------------------
model running time:  27.292800903320312
-------------------------------
Vision time :  85.72943878173828
Action time :  107.86815643310547
Trial 18 finished, success: tensor([True]), steps: 205
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.006431579589844
-------------------------------
-------------------------------
model running time:  8.428544044494629
-------------------------------
-------------------------------
model running time:  36.42265701293945
-------------------------------
-------------------------------
model running time:  10.552384376525879
-------------------------------
-------------------------------
model running time:  27.711423873901367
-------------------------------
Vision time :  85.70336151123047
Action time :  114.03587341308594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [01:05<00:22,  3.72s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.660415649414062
-------------------------------
-------------------------------
model running time:  8.416255950927734
-------------------------------
-------------------------------
model running time:  27.592639923095703
-------------------------------
-------------------------------
model running time:  10.658687591552734
-------------------------------
-------------------------------
model running time:  28.678144454956055
-------------------------------
Vision time :  85.71526336669922
Action time :  105.73632049560547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.763839721679688
-------------------------------
-------------------------------
model running time:  8.42137622833252
-------------------------------
-------------------------------
model running time:  27.417600631713867
-------------------------------
-------------------------------
model running time:  10.44480037689209
-------------------------------
-------------------------------
model running time:  27.48726463317871
-------------------------------
Vision time :  85.74041748046875
Action time :  104.43775939941406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.809919357299805
-------------------------------
-------------------------------
model running time:  8.399871826171875
-------------------------------
-------------------------------
model running time:  27.450271606445312
-------------------------------
-------------------------------
model running time:  10.52467155456543
-------------------------------
-------------------------------
model running time:  27.274240493774414
-------------------------------
Vision time :  85.62579345703125
Action time :  104.1602554321289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.07084846496582
-------------------------------
-------------------------------
model running time:  8.547327995300293
-------------------------------
-------------------------------
model running time:  28.17228889465332
-------------------------------
-------------------------------
model running time:  10.579968452453613
-------------------------------
-------------------------------
model running time:  28.026752471923828
-------------------------------
Vision time :  85.7332763671875
Action time :  108.4395523071289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.792959213256836
-------------------------------
-------------------------------
model running time:  8.501248359680176
-------------------------------
-------------------------------
model running time:  28.17638397216797
-------------------------------
-------------------------------
model running time:  12.405759811401367
-------------------------------
-------------------------------
model running time:  28.035167694091797
-------------------------------
Vision time :  85.78125
Action time :  109.4676513671875
Trial 19 finished, success: tensor([True]), steps: 89
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.457088470458984
-------------------------------
-------------------------------
model running time:  8.643584251403809
-------------------------------
-------------------------------
model running time:  28.13542366027832
-------------------------------
-------------------------------
model running time:  10.585087776184082
-------------------------------
-------------------------------
model running time:  27.96556854248047
-------------------------------
Vision time :  85.74569702148438
Action time :  107.05510711669922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.534912109375
-------------------------------
-------------------------------
model running time:  8.499199867248535
-------------------------------
-------------------------------
model running time:  28.188671112060547
-------------------------------
-------------------------------
model running time:  10.521599769592285
-------------------------------
-------------------------------
model running time:  27.839616775512695
-------------------------------
Vision time :  85.74739074707031
Action time :  106.46835327148438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.5031681060791
-------------------------------
-------------------------------
model running time:  8.473600387573242
-------------------------------
-------------------------------
model running time:  28.028032302856445
-------------------------------
-------------------------------
model running time:  10.54310417175293
-------------------------------
-------------------------------
model running time:  27.845632553100586
-------------------------------
Vision time :  85.76019287109375
Action time :  106.2103042602539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.724191665649414
-------------------------------
-------------------------------
model running time:  8.546303749084473
-------------------------------
-------------------------------
model running time:  28.104703903198242
-------------------------------
-------------------------------
model running time:  10.526592254638672
-------------------------------
-------------------------------
model running time:  27.94598388671875
-------------------------------
Vision time :  85.74066925048828
Action time :  107.13292694091797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.478496551513672
-------------------------------
-------------------------------
model running time:  8.458239555358887
-------------------------------
-------------------------------
model running time:  27.899904251098633
-------------------------------
-------------------------------
model running time:  10.54310417175293
-------------------------------
-------------------------------
model running time:  27.810815811157227
-------------------------------
Vision time :  85.73072052001953
Action time :  106.76032257080078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.57689666748047
-------------------------------
-------------------------------
model running time:  8.481792449951172
-------------------------------
-------------------------------
model running time:  27.92755126953125
-------------------------------
-------------------------------
model running time:  10.546175956726074
-------------------------------
-------------------------------
model running time:  34.5478401184082
-------------------------------
Vision time :  85.78179168701172
Action time :  113.33321380615234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.441856384277344
-------------------------------
-------------------------------
model running time:  8.423423767089844
-------------------------------
-------------------------------
model running time:  27.89580726623535
-------------------------------
-------------------------------
model running time:  10.46121597290039
-------------------------------
-------------------------------
model running time:  27.728736877441406
-------------------------------
Vision time :  85.75759887695312
Action time :  106.47135925292969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.565631866455078
-------------------------------
-------------------------------
model running time:  8.467519760131836
-------------------------------
-------------------------------
model running time:  28.244895935058594
-------------------------------
-------------------------------
model running time:  10.496000289916992
-------------------------------
-------------------------------
model running time:  27.75654411315918
-------------------------------
Vision time :  85.78633880615234
Action time :  106.69363403320312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.52057647705078
-------------------------------
-------------------------------
model running time:  8.522751808166504
-------------------------------
-------------------------------
model running time:  28.088224411010742
-------------------------------
-------------------------------
model running time:  10.573920249938965
-------------------------------
-------------------------------
model running time:  28.087295532226562
-------------------------------
Vision time :  85.77005004882812
Action time :  107.39600372314453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.622976303100586
-------------------------------
-------------------------------
model running time:  8.477696418762207
-------------------------------
-------------------------------
model running time:  33.80326461791992
-------------------------------
-------------------------------
model running time:  10.556480407714844
-------------------------------
-------------------------------
model running time:  27.840511322021484
-------------------------------
Vision time :  85.73094177246094
Action time :  112.38706970214844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.35366439819336
-------------------------------
-------------------------------
model running time:  8.438783645629883
-------------------------------
-------------------------------
model running time:  27.836416244506836
-------------------------------
-------------------------------
model running time:  10.475456237792969
-------------------------------
-------------------------------
model running time:  27.760671615600586
-------------------------------
Vision time :  85.74179077148438
Action time :  105.93075561523438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.68227195739746
-------------------------------
-------------------------------
model running time:  8.480640411376953
-------------------------------
-------------------------------
model running time:  27.93779182434082
-------------------------------
-------------------------------
model running time:  10.698911666870117
-------------------------------
-------------------------------
model running time:  27.867136001586914
-------------------------------
Vision time :  85.7781753540039
Action time :  106.8216323852539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.55129623413086
-------------------------------
-------------------------------
model running time:  8.458368301391602
-------------------------------
-------------------------------
model running time:  27.966463088989258
-------------------------------
-------------------------------
model running time:  10.497023582458496
-------------------------------
-------------------------------
model running time:  27.878400802612305
-------------------------------
Vision time :  85.7647705078125
Action time :  106.86463928222656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.646528244018555
-------------------------------
-------------------------------
model running time:  8.463295936584473
-------------------------------
-------------------------------
model running time:  27.93164825439453
-------------------------------
-------------------------------
model running time:  10.584063529968262
-------------------------------
-------------------------------
model running time:  27.82624053955078
-------------------------------
Vision time :  85.7688980102539
Action time :  106.84825897216797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.409984588623047
-------------------------------
-------------------------------
model running time:  8.433664321899414
-------------------------------
-------------------------------
model running time:  27.982847213745117
-------------------------------
-------------------------------
model running time:  10.563584327697754
-------------------------------
-------------------------------
model running time:  27.803647994995117
-------------------------------
Vision time :  85.7635498046875
Action time :  106.42415618896484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.166271209716797
-------------------------------
-------------------------------
model running time:  8.481792449951172
-------------------------------
-------------------------------
model running time:  27.9685115814209
-------------------------------
-------------------------------
model running time:  10.537983894348145
-------------------------------
-------------------------------
model running time:  27.487232208251953
-------------------------------
Vision time :  85.73741149902344
Action time :  106.33824157714844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.72185516357422
-------------------------------
-------------------------------
model running time:  8.49407958984375
-------------------------------
-------------------------------
model running time:  27.610271453857422
-------------------------------
-------------------------------
model running time:  10.492927551269531
-------------------------------
-------------------------------
model running time:  27.398143768310547
-------------------------------
Vision time :  85.74310302734375
Action time :  105.11257934570312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.265792846679688
-------------------------------
-------------------------------
model running time:  8.468480110168457
-------------------------------
-------------------------------
model running time:  27.650047302246094
-------------------------------
-------------------------------
model running time:  10.4519681930542
-------------------------------
-------------------------------
model running time:  32.82944107055664
-------------------------------
Vision time :  85.75555419921875
Action time :  116.0284194946289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  34.69721603393555
-------------------------------
-------------------------------
model running time:  8.480704307556152
-------------------------------
-------------------------------
model running time:  27.69817543029785
-------------------------------
-------------------------------
model running time:  10.529696464538574
-------------------------------
-------------------------------
model running time:  27.425792694091797
-------------------------------
Vision time :  85.73564910888672
Action time :  114.21475219726562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048


 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [01:14<00:26,  5.31s/it][A[A-------------------------------
model running time:  34.270206451416016
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  27.521024703979492
-------------------------------
-------------------------------
model running time:  10.465279579162598
-------------------------------
-------------------------------
model running time:  27.468799591064453
-------------------------------
Vision time :  85.70931243896484
Action time :  112.95744323730469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.005504608154297
-------------------------------
-------------------------------
model running time:  8.453120231628418
-------------------------------
-------------------------------
model running time:  27.933696746826172
-------------------------------
-------------------------------
model running time:  10.507264137268066
-------------------------------
-------------------------------
model running time:  27.787328720092773
-------------------------------
Vision time :  85.72172546386719
Action time :  105.97599792480469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.984159469604492
-------------------------------
-------------------------------
model running time:  8.511455535888672
-------------------------------
-------------------------------
model running time:  27.838464736938477
-------------------------------
-------------------------------
model running time:  10.498047828674316
-------------------------------
-------------------------------
model running time:  31.968416213989258
-------------------------------
Vision time :  85.71186828613281
Action time :  110.00115203857422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.790559768676758
-------------------------------
-------------------------------
model running time:  8.424351692199707
-------------------------------
-------------------------------
model running time:  27.74630355834961
-------------------------------
-------------------------------
model running time:  10.463232040405273
-------------------------------
-------------------------------
model running time:  33.03628921508789
-------------------------------
Vision time :  85.73062133789062
Action time :  111.1694107055664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.928640365600586
-------------------------------
-------------------------------
model running time:  8.417344093322754
-------------------------------
-------------------------------
model running time:  27.575231552124023
-------------------------------
-------------------------------
model running time:  10.472448348999023
-------------------------------
-------------------------------
model running time:  27.55059242248535
-------------------------------
Vision time :  85.70982360839844
Action time :  105.01119995117188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.068992614746094
-------------------------------
-------------------------------
model running time:  8.445023536682129
-------------------------------
-------------------------------
model running time:  27.851776123046875
-------------------------------
-------------------------------
model running time:  10.506239891052246
-------------------------------
-------------------------------
model running time:  27.736064910888672
-------------------------------
Vision time :  85.73526763916016
Action time :  105.64822387695312
Trial 20 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.83180809020996
-------------------------------
-------------------------------
model running time:  8.688672065734863
-------------------------------
-------------------------------
model running time:  28.409727096557617
-------------------------------
-------------------------------
model running time:  10.537952423095703
-------------------------------
-------------------------------
model running time:  30.95756721496582
-------------------------------
Vision time :  85.74934387207031
Action time :  110.37398529052734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.1529598236084
-------------------------------
-------------------------------
model running time:  8.558591842651367
-------------------------------
-------------------------------
model running time:  28.077152252197266
-------------------------------
-------------------------------
model running time:  10.539999961853027
-------------------------------
-------------------------------
model running time:  27.77302360534668
-------------------------------
Vision time :  85.8067855834961
Action time :  106.09980773925781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.961471557617188
-------------------------------
-------------------------------
model running time:  8.51353645324707
-------------------------------
-------------------------------
model running time:  27.826175689697266
-------------------------------
-------------------------------
model running time:  10.63542366027832
-------------------------------
-------------------------------
model running time:  27.70636749267578
-------------------------------
Vision time :  85.74998474121094
Action time :  105.48633575439453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.316736221313477
-------------------------------
-------------------------------
model running time:  8.543231964111328
-------------------------------
-------------------------------
model running time:  28.649471282958984
-------------------------------
-------------------------------
model running time:  10.494976043701172
-------------------------------
-------------------------------
model running time:  27.933727264404297
-------------------------------
Vision time :  85.74281311035156
Action time :  106.81139373779297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.7192325592041
-------------------------------
-------------------------------
model running time:  8.488960266113281
-------------------------------
-------------------------------
model running time:  27.98080062866211
-------------------------------
-------------------------------
model running time:  10.506239891052246
-------------------------------
-------------------------------
model running time:  28.39142417907715
-------------------------------
Vision time :  85.789794921875
Action time :  106.82367706298828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.712223052978516
-------------------------------
-------------------------------
model running time:  8.483839988708496
-------------------------------
-------------------------------
model running time:  28.453887939453125
-------------------------------
-------------------------------
model running time:  10.536959648132324
-------------------------------
-------------------------------
model running time:  32.44441604614258
-------------------------------
Vision time :  85.71603393554688
Action time :  111.4234848022461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.130495071411133
-------------------------------
-------------------------------
model running time:  8.52070426940918
-------------------------------
-------------------------------
model running time:  28.56243133544922
-------------------------------
-------------------------------
model running time:  10.614784240722656
-------------------------------
-------------------------------
model running time:  28.013568878173828
-------------------------------
Vision time :  85.74518585205078
Action time :  106.58723449707031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.25587272644043
-------------------------------
-------------------------------
model running time:  8.525823593139648
-------------------------------
-------------------------------
model running time:  36.86502456665039
-------------------------------
-------------------------------
model running time:  10.508288383483887
-------------------------------
-------------------------------
model running time:  27.847679138183594
-------------------------------
Vision time :  85.77017974853516
Action time :  115.90553283691406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.09663963317871
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  27.9552001953125
-------------------------------
-------------------------------
model running time:  10.501119613647461
-------------------------------
-------------------------------
model running time:  33.18374252319336
-------------------------------
Vision time :  85.69795227050781
Action time :  111.17362976074219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.053632736206055
-------------------------------
-------------------------------
model running time:  8.470527648925781
-------------------------------
-------------------------------
model running time:  35.60038375854492
-------------------------------
-------------------------------
model running time:  10.465279579162598
-------------------------------
-------------------------------
model running time:  27.71571159362793
-------------------------------
Vision time :  85.73033905029297
Action time :  112.93798065185547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.971744537353516
-------------------------------
-------------------------------
model running time:  8.417280197143555
-------------------------------
-------------------------------
model running time:  27.840511322021484
-------------------------------
-------------------------------
model running time:  10.501119613647461
-------------------------------
-------------------------------
model running time:  27.742080688476562
-------------------------------
Vision time :  85.72249603271484
Action time :  105.31523132324219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.88819122314453
-------------------------------
-------------------------------
model running time:  8.573951721191406
-------------------------------
-------------------------------
model running time:  31.62931251525879
-------------------------------
-------------------------------
model running time:  10.484831809997559
-------------------------------
-------------------------------
model running time:  27.822080612182617
-------------------------------
Vision time :  85.7903060913086
Action time :  110.23776245117188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.427135467529297
-------------------------------
-------------------------------
model running time:  8.436736106872559
-------------------------------
-------------------------------
model running time:  27.834367752075195
-------------------------------
-------------------------------
model running time:  10.53388786315918
-------------------------------
-------------------------------
model running time:  27.704320907592773
-------------------------------
Vision time :  85.76866912841797
Action time :  109.73490905761719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.23574447631836
-------------------------------
-------------------------------
model running time:  8.489983558654785
-------------------------------
-------------------------------
model running time:  27.95212745666504
-------------------------------
-------------------------------
model running time:  10.493951797485352
-------------------------------
-------------------------------
model running time:  27.840511322021484
-------------------------------
Vision time :  85.73868560791016
Action time :  105.73619079589844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.844928741455078
-------------------------------
-------------------------------
model running time:  8.439680099487305
-------------------------------
-------------------------------
model running time:  27.94393539428711
-------------------------------
-------------------------------
model running time:  10.564607620239258
-------------------------------
-------------------------------
model running time:  27.882495880126953
-------------------------------
Vision time :  85.7462387084961
Action time :  110.3359375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.200063705444336
-------------------------------
-------------------------------
model running time:  8.428544044494629
-------------------------------
-------------------------------
model running time:  27.97056007385254
-------------------------------
-------------------------------
model running time:  10.498175621032715
-------------------------------
-------------------------------
model running time:  27.76678466796875
-------------------------------
Vision time :  85.74729919433594
Action time :  105.58566284179688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.89311981201172
-------------------------------
-------------------------------
model running time:  8.485024452209473
-------------------------------
-------------------------------
model running time:  27.9418888092041
-------------------------------
-------------------------------
model running time:  10.519552230834961
-------------------------------
-------------------------------
model running time:  27.810848236083984
-------------------------------
Vision time :  85.7864990234375
Action time :  106.50019073486328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.0710391998291
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  33.84422302246094
-------------------------------
-------------------------------
model running time:  10.446847915649414
-------------------------------
-------------------------------
model running time:  27.560800552368164
-------------------------------
Vision time :  85.7023696899414
Action time :  111.36204528808594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.18284797668457
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  27.827199935913086
-------------------------------
-------------------------------
model running time:  

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [01:23<00:26,  6.56s/it][A[A10.462207794189453
-------------------------------
-------------------------------
model running time:  27.599872589111328
-------------------------------
Vision time :  85.74502563476562
Action time :  110.35852813720703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.33113670349121
-------------------------------
-------------------------------
model running time:  8.40601634979248
-------------------------------
-------------------------------
model running time:  35.23891067504883
-------------------------------
-------------------------------
model running time:  10.521599769592285
-------------------------------
-------------------------------
model running time:  27.74220848083496
-------------------------------
Vision time :  85.73506927490234
Action time :  112.98925018310547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.12428855895996
-------------------------------
-------------------------------
model running time:  8.477696418762207
-------------------------------
-------------------------------
model running time:  27.864032745361328
-------------------------------
-------------------------------
model running time:  10.457088470458984
-------------------------------
-------------------------------
model running time:  27.77791976928711
-------------------------------
Vision time :  85.75440216064453
Action time :  106.13555145263672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.043487548828125
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  27.841535568237305
-------------------------------
-------------------------------
model running time:  10.569727897644043
-------------------------------
-------------------------------
model running time:  27.78927993774414
-------------------------------
Vision time :  85.77804565429688
Action time :  105.6153564453125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92572784423828
-------------------------------
-------------------------------
model running time:  8.453280448913574
-------------------------------
-------------------------------
model running time:  27.933696746826172
-------------------------------
-------------------------------
model running time:  10.484736442565918
-------------------------------
-------------------------------
model running time:  27.72991943359375
-------------------------------
Vision time :  85.72611236572266
Action time :  105.47798156738281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.9246711730957
-------------------------------
-------------------------------
model running time:  8.441856384277344
-------------------------------
-------------------------------
model running time:  27.8590087890625
-------------------------------
-------------------------------
model running time:  10.496000289916992
-------------------------------
-------------------------------
model running time:  27.683839797973633
-------------------------------
Vision time :  85.73487854003906
Action time :  112.24883270263672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.98147201538086
-------------------------------
-------------------------------
model running time:  8.452095985412598
-------------------------------
-------------------------------
model running time:  27.86419105529785
-------------------------------
-------------------------------
model running time:  10.450943946838379
-------------------------------
-------------------------------
model running time:  27.645952224731445
-------------------------------
Vision time :  85.7580795288086
Action time :  106.39462280273438
Trial 21 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.132320404052734
-------------------------------
-------------------------------
model running time:  8.468480110168457
-------------------------------
-------------------------------
model running time:  27.744352340698242
-------------------------------
-------------------------------
model running time:  10.579968452453613
-------------------------------
-------------------------------
model running time:  33.238014221191406
-------------------------------
Vision time :  85.76182556152344
Action time :  111.73580932617188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.93382453918457
-------------------------------
-------------------------------
model running time:  8.39468765258789
-------------------------------
-------------------------------
model running time:  27.898880004882812
-------------------------------
-------------------------------
model running time:  10.511360168457031
-------------------------------
-------------------------------
model running time:  27.56608009338379
-------------------------------
Vision time :  85.72787475585938
Action time :  105.69522857666016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.971712112426758
-------------------------------
-------------------------------
model running time:  8.431615829467773
-------------------------------
-------------------------------
model running time:  27.787263870239258
-------------------------------
-------------------------------
model running time:  13.902848243713379
-------------------------------
-------------------------------
model running time:  27.702272415161133
-------------------------------
Vision time :  85.74626922607422
Action time :  108.66073608398438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.859840393066406
-------------------------------
-------------------------------
model running time:  8.41318416595459
-------------------------------
-------------------------------
model running time:  27.797504425048828
-------------------------------
-------------------------------
model running time:  10.45798397064209
-------------------------------
-------------------------------
model running time:  27.69715118408203
-------------------------------
Vision time :  85.77110290527344
Action time :  109.40211486816406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.95123291015625
-------------------------------
-------------------------------
model running time:  8.491007804870605
-------------------------------
-------------------------------
model running time:  27.792383193969727
-------------------------------
-------------------------------
model running time:  10.455039978027344
-------------------------------
-------------------------------
model running time:  27.79737663269043
-------------------------------
Vision time :  85.74694061279297
Action time :  105.6737289428711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.003456115722656
-------------------------------
-------------------------------
model running time:  8.452095985412598
-------------------------------
-------------------------------
model running time:  32.845760345458984
-------------------------------
-------------------------------
model running time:  10.532735824584961
-------------------------------
-------------------------------
model running time:  27.49951934814453
-------------------------------
Vision time :  85.7511978149414
Action time :  110.6688003540039
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.73619270324707
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  36.43084716796875
-------------------------------
-------------------------------
model running time:  10.548224449157715
-------------------------------
-------------------------------
model running time:  27.443199157714844
-------------------------------
Vision time :  87.24240112304688
Action time :  113.83200073242188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.991167068481445
-------------------------------
-------------------------------
model running time:  8.444928169250488
-------------------------------
-------------------------------
model running time:  27.513856887817383
-------------------------------
-------------------------------
model running time:  10.529791831970215
-------------------------------
-------------------------------
model running time:  27.449344635009766
-------------------------------
Vision time :  85.73900604248047
Action time :  105.72402954101562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.93484878540039
-------------------------------
-------------------------------
model running time:  8.49407958984375
-------------------------------
-------------------------------
model running time:  27.702144622802734
-------------------------------
-------------------------------
model running time:  10.550271987915039
-------------------------------
-------------------------------
model running time:  30.213119506835938
-------------------------------
Vision time :  85.7383041381836
Action time :  107.6316146850586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.959423065185547
-------------------------------
-------------------------------
model running time:  8.42137622833252
-------------------------------
-------------------------------
model running time:  27.614208221435547
-------------------------------
-------------------------------
model running time:  10.456064224243164
-------------------------------
-------------------------------
model running time:  27.37766456604004
-------------------------------
Vision time :  85.76016235351562
Action time :  

 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [01:27<00:16,  5.66s/it][A[A105.03577423095703
Trial 22 finished, success: tensor([True]), steps: 145
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.5928955078125
-------------------------------
-------------------------------
model running time:  8.484864234924316
-------------------------------
-------------------------------
model running time:  27.74425506591797
-------------------------------
-------------------------------
model running time:  10.54412841796875
-------------------------------
-------------------------------
model running time:  29.758464813232422
-------------------------------
Vision time :  85.79177856445312
Action time :  113.904541015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9102725982666
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  27.878400802612305
-------------------------------
-------------------------------
model running time:  10.54207992553711
-------------------------------
-------------------------------
model running time:  36.23628616333008
-------------------------------
Vision time :  85.78253173828125
Action time :  113.77970886230469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.875455856323242
-------------------------------
-------------------------------
model running time:  8.488960266113281
-------------------------------
-------------------------------
model running time:  32.1710090637207
-------------------------------
-------------------------------
model running time:  10.545151710510254
-------------------------------
-------------------------------
model running time:  27.59270477294922
-------------------------------
Vision time :  85.74742126464844
Action time :  109.43084716796875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.945087432861328
-------------------------------
-------------------------------
model running time:  8.43990421295166
-------------------------------
-------------------------------
model running time:  27.635711669921875
-------------------------------
-------------------------------
model running time:  10.572959899902344
-------------------------------
-------------------------------
model running time:  27.51692771911621
-------------------------------
Vision time :  85.74396514892578
Action time :  104.72444915771484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.73619270324707
-------------------------------
-------------------------------
model running time:  8.463359832763672
-------------------------------
-------------------------------
model running time:  27.54457664489746
-------------------------------
-------------------------------
model running time:  10.519552230834961
-------------------------------
-------------------------------
model running time:  27.480064392089844
-------------------------------
Vision time :  85.7735366821289
Action time :  104.31488037109375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.13657569885254
-------------------------------
-------------------------------
model running time:  8.509440422058105
-------------------------------
-------------------------------
model running time:  27.787391662597656
-------------------------------
-------------------------------
model running time:  10.471424102783203
-------------------------------
-------------------------------
model running time:  27.606016159057617
-------------------------------
Vision time :  85.75730895996094
Action time :  105.29296112060547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.788415908813477
-------------------------------
-------------------------------
model running time:  8.431615829467773
-------------------------------
-------------------------------
model running time:  27.696128845214844
-------------------------------
-------------------------------
model running time:  10.536959648132324
-------------------------------
-------------------------------
model running time:  27.531360626220703
-------------------------------
Vision time :  85.77184295654297
Action time :  104.595458984375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.93987274169922
-------------------------------
-------------------------------
model running time:  14.003199577331543
-------------------------------
-------------------------------
model running time:  35.210208892822266
-------------------------------
-------------------------------
model running time:  11.593728065490723
-------------------------------
-------------------------------
model running time:  27.467775344848633
-------------------------------
Vision time :  85.77417755126953
Action time :  119.0739517211914
before pruning: 


 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [01:30<00:10,  5.05s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.1079044342041
-------------------------------
-------------------------------
model running time:  8.462335586547852
-------------------------------
-------------------------------
model running time:  27.692031860351562
-------------------------------
-------------------------------
model running time:  10.504192352294922
-------------------------------
-------------------------------
model running time:  27.66851234436035
-------------------------------
Vision time :  85.75225830078125
Action time :  105.23340606689453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.976831436157227
-------------------------------
-------------------------------
model running time:  8.385536193847656
-------------------------------
-------------------------------
model running time:  27.65510368347168
-------------------------------
-------------------------------
model running time:  10.456159591674805
-------------------------------
-------------------------------
model running time:  27.55686378479004
-------------------------------
Vision time :  85.7458267211914
Action time :  104.67635345458984
Trial 23 finished, success: tensor([True]), steps: 145
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.869760513305664
-------------------------------
-------------------------------
model running time:  8.443936347961426
-------------------------------
-------------------------------
model running time:  27.92972755432129
-------------------------------
-------------------------------
model running time:  10.507264137268066
-------------------------------
-------------------------------
model running time:  27.846656799316406
-------------------------------
Vision time :  85.8707504272461
Action time :  106.5379867553711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.3874568939209
-------------------------------
-------------------------------
model running time:  8.465375900268555
-------------------------------
-------------------------------
model running time:  28.16204833984375
-------------------------------
-------------------------------
model running time:  10.5000638961792
-------------------------------
-------------------------------
model running time:  27.75961685180664
-------------------------------
Vision time :  85.83798217773438
Action time :  106.07324981689453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.843040466308594
-------------------------------
-------------------------------
model running time:  8.484895706176758
-------------------------------
-------------------------------
model running time:  27.772031784057617
-------------------------------
-------------------------------
model running time:  10.487903594970703
-------------------------------
-------------------------------
model running time:  27.601919174194336
-------------------------------
Vision time :  85.75177764892578
Action time :  112.88883209228516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.889535903930664
-------------------------------
-------------------------------
model running time:  8.440832138061523
-------------------------------
-------------------------------
model running time:  27.719615936279297
-------------------------------
-------------------------------
model running time:  10.530816078186035
-------------------------------
-------------------------------
model running time:  27.642879486083984
-------------------------------
Vision time :  85.76882934570312
Action time :  108.89727783203125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.87446403503418
-------------------------------
-------------------------------
model running time:  8.467552185058594
-------------------------------
-------------------------------
model running time:  34.2743034362793
-------------------------------
-------------------------------
model running time:  10.494976043701172
-------------------------------
-------------------------------
model running time:  27.373567581176758
-------------------------------
Vision time :  85.76502227783203
Action time :  111.12242889404297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.860864639282227
-------------------------------
-------------------------------
model running time:  9.729023933410645
-------------------------------
-------------------------------
model running time:  27.777023315429688
-------------------------------
-------------------------------
model running time:  10.506239891052246
-------------------------------
-------------------------------
model running time:  27.5599365234375
-------------------------------
Vision time :  85.76115417480469
Action time :  112.04198455810547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [01:33<00:04,  4.32s/it][A[A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [01:35<00:00,  3.65s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [01:35<00:00,  3.82s/it]

 10%|â–ˆ         | 1/10 [01:35<14:20, 95.58s/it][Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.895776748657227
-------------------------------
-------------------------------
model running time:  8.454143524169922
-------------------------------
-------------------------------
model running time:  27.67571258544922
-------------------------------
-------------------------------
model running time:  10.52774429321289
-------------------------------
-------------------------------
model running time:  27.5097599029541
-------------------------------
Vision time :  85.74899291992188
Action time :  104.76646423339844
Trial 24 finished, success: tensor([True]), steps: 112
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.001407623291016
-------------------------------
-------------------------------
model running time:  8.5032958984375
-------------------------------
-------------------------------
model running time:  32.84889602661133
-------------------------------
-------------------------------
model running time:  10.617792129516602
-------------------------------
-------------------------------
model running time:  27.78927993774414
-------------------------------
Vision time :  85.78662109375
Action time :  110.40767669677734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89900779724121
-------------------------------
-------------------------------
model running time:  8.44700813293457
-------------------------------
-------------------------------
model running time:  27.63052749633789
-------------------------------
-------------------------------
model running time:  10.518655776977539
-------------------------------
-------------------------------
model running time:  33.68761444091797
-------------------------------
Vision time :  85.80668640136719
Action time :  110.83177947998047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.903135299682617
-------------------------------
-------------------------------
model running time:  8.434687614440918
-------------------------------
-------------------------------
model running time:  27.611135482788086
-------------------------------
-------------------------------
model running time:  10.55129623413086
-------------------------------
-------------------------------
model running time:  27.497472763061523
-------------------------------
Vision time :  85.79132843017578
Action time :  104.54425811767578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.876480102539062
-------------------------------
-------------------------------
model running time:  8.440832138061523
-------------------------------
-------------------------------
model running time:  27.636735916137695
-------------------------------
-------------------------------
model running time:  10.54207992553711
-------------------------------
-------------------------------
model running time:  27.519968032836914
-------------------------------
Vision time :  85.77388763427734
Action time :  104.55757141113281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.193920135498047
-------------------------------
-------------------------------
model running time:  8.483839988708496
-------------------------------
-------------------------------
model running time:  27.427839279174805
-------------------------------
-------------------------------
model running time:  10.588159561157227
-------------------------------
-------------------------------
model running time:  33.593345642089844
-------------------------------
Vision time :  85.8497314453125
Action time :  113.9261474609375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.944063186645508
-------------------------------
-------------------------------
model running time:  8.426495552062988
-------------------------------
-------------------------------
model running time:  27.504640579223633
-------------------------------
-------------------------------
model running time:  10.54319953918457
-------------------------------
-------------------------------
model running time:  30.455808639526367
-------------------------------
Vision time :  85.81037139892578
Action time :  107.57734680175781
Trial 25 finished, success: tensor([True]), steps: 87
policy.alpha = 1.0policy.temp = 0.01
policy.alpha = 1.0policy.temp = 0.01
Success rate: 84.0%
Running trial with alpha=1.0, temp=0.01. Re-seeding with 20241201.


  0%|          | 0/25 [00:00<?, ?it/s][A[A

  4%|â–         | 1/25 [00:02<01:07,  2.81s/it][A[Abefore pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.614336013793945
-------------------------------
-------------------------------
model running time:  8.416255950927734
-------------------------------
-------------------------------
model running time:  27.51590347290039
-------------------------------
-------------------------------
model running time:  10.51750373840332
-------------------------------
-------------------------------
model running time:  30.467071533203125
-------------------------------
Vision time :  85.75475311279297
Action time :  107.12678527832031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.70342445373535
-------------------------------
-------------------------------
model running time:  8.373248100280762
-------------------------------
-------------------------------
model running time:  27.450368881225586
-------------------------------
-------------------------------
model running time:  10.44480037689209
-------------------------------
-------------------------------
model running time:  27.313152313232422
-------------------------------
Vision time :  85.76812744140625
Action time :  103.88467407226562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.963136672973633
-------------------------------
-------------------------------
model running time:  8.495231628417969
-------------------------------
-------------------------------
model running time:  27.68499183654785
-------------------------------
-------------------------------
model running time:  10.530816078186035
-------------------------------
-------------------------------
model running time:  27.51705551147461
-------------------------------
Vision time :  85.8067855834961
Action time :  110.9032974243164
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.79769515991211
-------------------------------
-------------------------------
model running time:  8.410112380981445
-------------------------------
-------------------------------
model running time:  27.5199031829834
-------------------------------
-------------------------------
model running time:  10.468352317810059
-------------------------------
-------------------------------
model running time:  34.667518615722656
-------------------------------
Vision time :  85.78486633300781
Action time :  111.37535858154297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.837440490722656
-------------------------------
-------------------------------
model running time:  8.460288047790527
-------------------------------
-------------------------------
model running time:  31.75014305114746
-------------------------------
-------------------------------
model running time:  10.514431953430176
-------------------------------
-------------------------------
model running time:  27.406335830688477
-------------------------------
Vision time :  85.78153228759766
Action time :  110.59302520751953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.991167068481445
-------------------------------
-------------------------------
model running time:  8.435711860656738
-------------------------------
-------------------------------
model running time:  28.112895965576172
-------------------------------
-------------------------------
model running time:  10.53388786315918
-------------------------------
-------------------------------
model running time:  27.54662322998047
-------------------------------
Vision time :  85.76710510253906
Action time :  105.2774429321289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.70035171508789
-------------------------------
-------------------------------
model running time:  8.441856384277344
-------------------------------
-------------------------------
model running time:  27.56915283203125
-------------------------------
-------------------------------
model running time:  10.488832473754883
-------------------------------
-------------------------------
model running time:  35.13657760620117
-------------------------------
Vision time :  85.76636505126953
Action time :  112.12185668945312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.74028778076172
-------------------------------
-------------------------------
model running time:  8.407039642333984
-------------------------------
-------------------------------
model running time:  33.98348617553711
-------------------------------
-------------------------------
model running time:  10.482687950134277
-------------------------------
-------------------------------
model running time:  27.450368881225586
-------------------------------
Vision time :  85.74870300292969
Action time :  111.26067352294922
Trial 1 finished, success: tensor([True]), steps: 126
policy.alpha = 1.0policy.temp = 0.01
before pruning: 


  8%|â–Š         | 2/25 [00:05<00:59,  2.58s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.79974365234375
-------------------------------
-------------------------------
model running time:  8.425472259521484
-------------------------------
-------------------------------
model running time:  27.5732479095459
-------------------------------
-------------------------------
model running time:  10.671008110046387
-------------------------------
-------------------------------
model running time:  34.98495864868164
-------------------------------
Vision time :  85.72828674316406
Action time :  112.09318542480469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.808895111083984
-------------------------------
-------------------------------
model running time:  8.468480110168457
-------------------------------
-------------------------------
model running time:  27.7258243560791
-------------------------------
-------------------------------
model running time:  10.499168395996094
-------------------------------
-------------------------------
model running time:  30.947328567504883
-------------------------------
Vision time :  85.78166198730469
Action time :  108.0258560180664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.814016342163086
-------------------------------
-------------------------------
model running time:  8.456192016601562
-------------------------------
-------------------------------
model running time:  29.930496215820312
-------------------------------
-------------------------------
model running time:  10.510335922241211
-------------------------------
-------------------------------
model running time:  27.653120040893555
-------------------------------
Vision time :  85.79984283447266
Action time :  106.94041442871094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.892864227294922
-------------------------------
-------------------------------
model running time:  8.40294361114502
-------------------------------
-------------------------------
model running time:  27.671552658081055
-------------------------------
-------------------------------
model running time:  10.523648262023926
-------------------------------
-------------------------------
model running time:  27.431936264038086
-------------------------------
Vision time :  85.75785827636719
Action time :  104.53401947021484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.51193618774414
-------------------------------
-------------------------------
model running time:  8.937472343444824
-------------------------------
-------------------------------
model running time:  27.529216766357422
-------------------------------
-------------------------------
model running time:  10.557439804077148
-------------------------------
-------------------------------
model running time:  27.496448516845703
-------------------------------
Vision time :  85.75049591064453
Action time :  104.67327880859375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.565183639526367
-------------------------------
-------------------------------
model running time:  8.426336288452148
-------------------------------
-------------------------------
model running time:  27.50783920288086
-------------------------------
-------------------------------
model running time:  10.523615837097168
-------------------------------
-------------------------------
model running time:  27.58665657043457
-------------------------------
Vision time :  85.75606536865234
Action time :  104.30156707763672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.299968719482422
-------------------------------
-------------------------------
model running time:  8.390656471252441
-------------------------------
-------------------------------
model running time:  27.430912017822266
-------------------------------
-------------------------------
model running time:  10.483712196350098
-------------------------------
-------------------------------
model running time:  27.371519088745117
-------------------------------
Vision time :  85.7649917602539
Action time :  103.34617614746094
Trial 2 finished, success: tensor([True]), steps: 104
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.52524757385254
-------------------------------
-------------------------------
model running time:  8.386560440063477
-------------------------------
-------------------------------
model running time:  27.52297592163086
-------------------------------
-------------------------------
model running time:  10.49510383605957
-------------------------------
-------------------------------
model running time:  27.513824462890625
-------------------------------
Vision time :  85.76831817626953
Action time :  103.87865447998047
before pruning: 


 12%|â–ˆâ–        | 3/25 [00:07<00:52,  2.38s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.664512634277344
-------------------------------
-------------------------------
model running time:  8.399968147277832
-------------------------------
-------------------------------
model running time:  27.649023056030273
-------------------------------
-------------------------------
model running time:  10.49897575378418
-------------------------------
-------------------------------
model running time:  27.57632064819336
-------------------------------
Vision time :  85.7713623046875
Action time :  104.28108978271484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.553760528564453
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  27.492351531982422
-------------------------------
-------------------------------
model running time:  10.54412841796875
-------------------------------
-------------------------------
model running time:  27.3940486907959
-------------------------------
Vision time :  85.76719665527344
Action time :  104.18172454833984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.892864227294922
-------------------------------
-------------------------------
model running time:  8.455167770385742
-------------------------------
-------------------------------
model running time:  27.585535049438477
-------------------------------
-------------------------------
model running time:  10.531840324401855
-------------------------------
-------------------------------
model running time:  28.207103729248047
-------------------------------
Vision time :  85.78524780273438
Action time :  105.87648010253906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.37164878845215
-------------------------------
-------------------------------
model running time:  8.357888221740723
-------------------------------
-------------------------------
model running time:  27.634687423706055
-------------------------------
-------------------------------
model running time:  10.521632194519043
-------------------------------
-------------------------------
model running time:  27.454463958740234
-------------------------------
Vision time :  85.79808044433594
Action time :  104.03955078125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.601024627685547
-------------------------------
-------------------------------
model running time:  8.38758373260498
-------------------------------
-------------------------------
model running time:  27.433984756469727
-------------------------------
-------------------------------
model running time:  10.465279579162598
-------------------------------
-------------------------------
model running time:  27.36742401123047
-------------------------------
Vision time :  85.80630493164062
Action time :  104.01382446289062
Trial 3 finished, success: tensor([True]), steps: 94
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.56211280822754
-------------------------------
-------------------------------
model running time:  8.391551971435547
-------------------------------
-------------------------------
model running time:  27.448320388793945
-------------------------------
-------------------------------
model running time:  10.499072074890137
-------------------------------
-------------------------------
model running time:  27.35820770263672
-------------------------------
Vision time :  85.76166534423828
Action time :  103.7834243774414
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.70035171508789
-------------------------------
-------------------------------
model running time:  8.470527648925781
-------------------------------
-------------------------------
model running time:  27.62656021118164
-------------------------------
-------------------------------
model running time:  10.547200202941895
-------------------------------
-------------------------------
model running time:  27.38083267211914
-------------------------------
Vision time :  85.78006744384766
Action time :  104.21654510498047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.447423934936523
-------------------------------
-------------------------------
model running time:  8.392704010009766
-------------------------------
-------------------------------
model running time:  27.37766456604004
-------------------------------
-------------------------------
model running time:  10.584063529968262
-------------------------------
-------------------------------
model running time:  27.373567581176758
-------------------------------
Vision time :  85.7891845703125
Action time :  103.56326293945312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 16%|â–ˆâ–Œ        | 4/25 [00:10<00:53,  2.53s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.503488540649414
-------------------------------
-------------------------------
model running time:  8.39782428741455
-------------------------------
-------------------------------
model running time:  27.424768447875977
-------------------------------
-------------------------------
model running time:  10.507264137268066
-------------------------------
-------------------------------
model running time:  27.268096923828125
-------------------------------
Vision time :  85.75936126708984
Action time :  108.34329223632812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.491455078125
-------------------------------
-------------------------------
model running time:  8.41318416595459
-------------------------------
-------------------------------
model running time:  27.448320388793945
-------------------------------
-------------------------------
model running time:  10.475520133972168
-------------------------------
-------------------------------
model running time:  27.397119522094727
-------------------------------
Vision time :  85.78607940673828
Action time :  103.89299011230469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.367551803588867
-------------------------------
-------------------------------
model running time:  8.392704010009766
-------------------------------
-------------------------------
model running time:  27.38688087463379
-------------------------------
-------------------------------
model running time:  10.475520133972168
-------------------------------
-------------------------------
model running time:  27.476991653442383
-------------------------------
Vision time :  85.7609634399414
Action time :  103.77737426757812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.31737518310547
-------------------------------
-------------------------------
model running time:  8.376319885253906
-------------------------------
-------------------------------
model running time:  27.252735137939453
-------------------------------
-------------------------------
model running time:  10.50931167602539
-------------------------------
-------------------------------
model running time:  27.240447998046875
-------------------------------
Vision time :  85.77798461914062
Action time :  103.18966674804688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.428895950317383
-------------------------------
-------------------------------
model running time:  8.357888221740723
-------------------------------
-------------------------------
model running time:  27.387807846069336
-------------------------------
-------------------------------
model running time:  10.419136047363281
-------------------------------
-------------------------------
model running time:  27.303936004638672
-------------------------------
Vision time :  85.7423324584961
Action time :  103.80083465576172
Trial 4 finished, success: tensor([True]), steps: 116
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.636863708496094
-------------------------------
-------------------------------
model running time:  8.41215991973877
-------------------------------
-------------------------------
model running time:  27.7258243560791
-------------------------------
-------------------------------
model running time:  10.483743667602539
-------------------------------
-------------------------------
model running time:  27.441152572631836
-------------------------------
Vision time :  85.75910186767578
Action time :  104.18278503417969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.390079498291016
-------------------------------
-------------------------------
model running time:  8.431615829467773
-------------------------------
-------------------------------
model running time:  27.70524787902832
-------------------------------
-------------------------------
model running time:  10.537983894348145
-------------------------------
-------------------------------
model running time:  27.389951705932617
-------------------------------
Vision time :  85.75939178466797
Action time :  103.87763214111328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.817087173461914
-------------------------------
-------------------------------
model running time:  8.398847579956055
-------------------------------
-------------------------------
model running time:  27.54969596862793
-------------------------------
-------------------------------
model running time:  10.516480445861816
-------------------------------
-------------------------------
model running time:  27.976703643798828
-------------------------------
Vision time :  85.76399993896484
Action time :  104.8729248046875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 20%|â–ˆâ–ˆ        | 5/25 [00:12<00:47,  2.35s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.69308853149414
-------------------------------
-------------------------------
model running time:  8.39782428741455
-------------------------------
-------------------------------
model running time:  27.56915283203125
-------------------------------
-------------------------------
model running time:  10.53593635559082
-------------------------------
-------------------------------
model running time:  27.489280700683594
-------------------------------
Vision time :  85.75657653808594
Action time :  104.30464172363281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.406463623046875
-------------------------------
-------------------------------
model running time:  8.385631561279297
-------------------------------
-------------------------------
model running time:  27.54764747619629
-------------------------------
-------------------------------
model running time:  10.522624015808105
-------------------------------
-------------------------------
model running time:  27.423744201660156
-------------------------------
Vision time :  85.77180480957031
Action time :  103.74246215820312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.793535232543945
-------------------------------
-------------------------------
model running time:  8.377344131469727
-------------------------------
-------------------------------
model running time:  27.497600555419922
-------------------------------
-------------------------------
model running time:  10.446847915649414
-------------------------------
-------------------------------
model running time:  27.443199157714844
-------------------------------
Vision time :  85.77766418457031
Action time :  104.1244125366211
Trial 5 finished, success: tensor([True]), steps: 84
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89798355102539
-------------------------------
-------------------------------
model running time:  8.469504356384277
-------------------------------
-------------------------------
model running time:  27.54969596862793
-------------------------------
-------------------------------
model running time:  10.561535835266113
-------------------------------
-------------------------------
model running time:  27.49452781677246
-------------------------------
Vision time :  85.80694580078125
Action time :  104.62003326416016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.605119705200195
-------------------------------
-------------------------------
model running time:  8.439871788024902
-------------------------------
-------------------------------
model running time:  27.5948486328125
-------------------------------
-------------------------------
model running time:  10.612735748291016
-------------------------------
-------------------------------
model running time:  27.34489631652832
-------------------------------
Vision time :  85.78543853759766
Action time :  104.16019439697266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.35424041748047
-------------------------------
-------------------------------
model running time:  8.360960006713867
-------------------------------
-------------------------------
model running time:  27.513696670532227
-------------------------------
-------------------------------
model running time:  10.529855728149414
-------------------------------
-------------------------------
model running time:  27.331584930419922
-------------------------------
Vision time :  85.79357147216797
Action time :  103.56214141845703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.431936264038086
-------------------------------
-------------------------------
model running time:  8.410112380981445
-------------------------------
-------------------------------
model running time:  27.5599365234375
-------------------------------
-------------------------------
model running time:  10.487808227539062
-------------------------------
-------------------------------
model running time:  27.405311584472656
-------------------------------
Vision time :  85.76924896240234
Action time :  105.76793670654297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.453567504882812
-------------------------------
-------------------------------
model running time:  8.375391960144043
-------------------------------
-------------------------------
model running time:  27.594751358032227
-------------------------------
-------------------------------
model running time:  10.483712196350098
-------------------------------
-------------------------------
model running time:  27.361248016357422
-------------------------------
Vision time :  85.77228546142578
Action time :  103.72300720214844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 24%|â–ˆâ–ˆâ–       | 6/25 [00:14<00:43,  2.28s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.50579261779785
-------------------------------
-------------------------------
model running time:  8.3754243850708
-------------------------------
-------------------------------
model running time:  27.512832641601562
-------------------------------
-------------------------------
model running time:  10.493951797485352
-------------------------------
-------------------------------
model running time:  27.34604835510254
-------------------------------
Vision time :  85.76614379882812
Action time :  103.7107162475586
Trial 6 finished, success: tensor([True]), steps: 95
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.607168197631836
-------------------------------
-------------------------------
model running time:  8.40601634979248
-------------------------------
-------------------------------
model running time:  27.684864044189453
-------------------------------
-------------------------------
model running time:  10.492959976196289
-------------------------------
-------------------------------
model running time:  27.542688369750977
-------------------------------
Vision time :  85.77999877929688
Action time :  104.2607650756836
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.4781436920166
-------------------------------
-------------------------------
model running time:  8.4202880859375
-------------------------------
-------------------------------
model running time:  27.607040405273438
-------------------------------
-------------------------------
model running time:  10.521599769592285
-------------------------------
-------------------------------
model running time:  27.392000198364258
-------------------------------
Vision time :  85.77174377441406
Action time :  103.94226837158203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.383007049560547
-------------------------------
-------------------------------
model running time:  8.356863975524902
-------------------------------
-------------------------------
model running time:  27.448320388793945
-------------------------------
-------------------------------
model running time:  10.513407707214355
-------------------------------
-------------------------------
model running time:  27.51590347290039
-------------------------------
Vision time :  85.79209899902344
Action time :  103.69625854492188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92563247680664
-------------------------------
-------------------------------
model running time:  8.400896072387695
-------------------------------
-------------------------------
model running time:  27.512832641601562
-------------------------------
-------------------------------
model running time:  10.522624015808105
-------------------------------
-------------------------------
model running time:  27.4116153717041
-------------------------------
Vision time :  85.7837142944336
Action time :  104.36812591552734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.771007537841797
-------------------------------
-------------------------------
model running time:  8.460288047790527
-------------------------------
-------------------------------
model running time:  32.935935974121094
-------------------------------
-------------------------------
model running time:  10.490880012512207
-------------------------------
-------------------------------
model running time:  27.55583953857422
-------------------------------
Vision time :  85.81263732910156
Action time :  109.80147552490234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.004575729370117
-------------------------------
-------------------------------
model running time:  8.426495552062988
-------------------------------
-------------------------------
model running time:  27.631616592407227
-------------------------------
-------------------------------
model running time:  13.894720077514648
-------------------------------
-------------------------------
model running time:  27.489280700683594
-------------------------------
Vision time :  85.79843139648438
Action time :  108.1364517211914
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.797632217407227
-------------------------------
-------------------------------
model running time:  8.479743957519531
-------------------------------
-------------------------------
model running time:  27.50771141052246
-------------------------------
-------------------------------
model running time:  10.459136009216309
-------------------------------
-------------------------------
model running time:  28.487680435180664
-------------------------------
Vision time :  85.774658203125
Action time :  105.41455841064453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.662464141845703
-------------------------------
-------------------------------
model running time:  8.370112419128418
-------------------------------
-------------------------------
model running time:  27.51897621154785
-------------------------------
-------------------------------
model running time:  10.468352317810059
-------------------------------
-------------------------------
model running time:  27.36947250366211
-------------------------------
Vision time :  85.75507354736328
Action time :  103.92985534667969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.599903106689453
-------------------------------
-------------------------------
model running time:  8.401856422424316
-------------------------------
-------------------------------
model running time:  27.567264556884766
-------------------------------
-------------------------------
model running time:  10.53388786315918
-------------------------------
-------------------------------
model running time:  27.41747283935547
-------------------------------
Vision time :  85.79676818847656
Action time :  104.78182220458984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.661439895629883
-------------------------------
-------------------------------
model running time:  8.40294361114502
-------------------------------
-------------------------------
model running time:  27.593759536743164
-------------------------------
-------------------------------
model running time:  10.54310417175293
-------------------------------
-------------------------------
model running time:  27.50054359436035
-------------------------------
Vision time :  85.7845458984375
Action time :  104.33126068115234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.031103134155273
-------------------------------
-------------------------------
model running time:  8.481823921203613
-------------------------------
-------------------------------
model running time:  27.685888290405273
-------------------------------
-------------------------------
model running time:  10.541055679321289
-------------------------------
-------------------------------
model running time:  30.29497528076172
-------------------------------
Vision time :  85.81353759765625
Action time :  108.06476593017578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.70537567138672
-------------------------------
-------------------------------
model running time:  8.406047821044922
-------------------------------
-------------------------------
model running time:  33.247230529785156
-------------------------------
-------------------------------
model running time:  10.463104248046875
-------------------------------
-------------------------------
model running time:  27.30905532836914
-------------------------------
Vision time :  85.77721405029297
Action time :  109.61510467529297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.977279663085938
-------------------------------
-------------------------------
model running time:  8.479743957519531
-------------------------------
-------------------------------
model running time:  27.805696487426758
-------------------------------
-------------------------------
model running time:  10.57487964630127
-------------------------------
-------------------------------
model running time:  27.595775604248047
-------------------------------
Vision time :  85.85935974121094
Action time :  106.62297821044922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.998336791992188
-------------------------------
-------------------------------
model running time:  8.41919994354248
-------------------------------
-------------------------------
model running time:  27.63983917236328
-------------------------------
-------------------------------
model running time:  10.455039978027344
-------------------------------
-------------------------------
model running time:  35.56147384643555
-------------------------------
Vision time :  85.7883529663086
Action time :  113.1520004272461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.58348846435547
-------------------------------
-------------------------------
model running time:  8.408224105834961
-------------------------------
-------------------------------
model running time:  29.270015716552734
-------------------------------
-------------------------------
model running time:  10.585087776184082
-------------------------------
-------------------------------
model running time:  27.571264266967773
-------------------------------
Vision time :  85.80726623535156
Action time :  106.07427215576172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.033151626586914
-------------------------------
-------------------------------
model running time:  8.443903923034668
-------------------------------
-------------------------------
model running time:  27.69817543029785
-------------------------------
-------------------------------
model running time:  10.484736442565918
-------------------------------
-------------------------------
model running time:  33.21343994140625
-------------------------------
Vision time :  85.7613754272461
Action time :  111.20944213867188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.978879928588867
-------------------------------
-------------------------------
model running time:  8.41113567352295
-------------------------------
-------------------------------
model running time:  27.719680786132812
-------------------------------
-------------------------------
model running time:  10.48367977142334
-------------------------------
-------------------------------
model running time:  33.776641845703125
-------------------------------
Vision time :  85.78668975830078
Action time :  111.11837005615234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9553279876709
-------------------------------
-------------------------------
model running time:  13.616127967834473
-------------------------------
-------------------------------
model running time:  27.71455955505371
-------------------------------
-------------------------------
model running time:  10.500255584716797
-------------------------------
-------------------------------
model running time:  27.50771141052246
-------------------------------
Vision time :  85.77276611328125
Action time :  110.49472045898438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.850879669189453
-------------------------------
-------------------------------
model running time:  8.457247734069824
-------------------------------
-------------------------------
model running time:  27.585535049438477
-------------------------------
-------------------------------
model running time:  10.502047538757324
-------------------------------
-------------------------------
model running time:  27.435007095336914
-------------------------------
Vision time :  85.83920288085938
Action time :  104.95283508300781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.98297691345215
-------------------------------
-------------------------------
model running time:  8.427519798278809
-------------------------------
-------------------------------
model running time:  27.640832901000977
-------------------------------
-------------------------------
model running time:  10.464223861694336
-------------------------------
-------------------------------
model running time:  27.435007095336914
-------------------------------
Vision time :  85.83174133300781
Action time :  105.5283203125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.820159912109375
-------------------------------
-------------------------------
model running time:  8.457216262817383
-------------------------------
-------------------------------
model running time:  33.73664093017578
-------------------------------
-------------------------------
model running time:  10.541055679321289
-------------------------------
-------------------------------
model running time:  27.60089683532715
-------------------------------
Vision time :  85.80569458007812
Action time :  111.19001770019531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.14169692993164
-------------------------------
-------------------------------
model running time:  8.439807891845703
-------------------------------
-------------------------------
model running time:  27.661312103271484
-------------------------------
-------------------------------
model running time:  10.505375862121582
-------------------------------
-------------------------------
model running time:  27.49951934814453
-------------------------------
Vision time :  85.80252838134766
Action time :  104.91887664794922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.82111930847168
-------------------------------
-------------------------------
model running time:  8.475647926330566
-------------------------------
-------------------------------
model running time:  27.645952224731445
-------------------------------
-------------------------------
model running time:  10.470399856567383
-------------------------------
-------------------------------
model running time:  27.479135513305664
-------------------------------
Vision time :  85.81388854980469
Action time :  105.16678619384766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048


 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:23<01:20,  4.46s/it][A[A-------------------------------
model running time:  27.34592056274414
-------------------------------
-------------------------------
model running time:  8.93222427368164
-------------------------------
-------------------------------
model running time:  29.152320861816406
-------------------------------
-------------------------------
model running time:  10.432640075683594
-------------------------------
-------------------------------
model running time:  27.51795196533203
-------------------------------
Vision time :  85.96470642089844
Action time :  108.86348724365234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.926687240600586
-------------------------------
-------------------------------
model running time:  8.440832138061523
-------------------------------
-------------------------------
model running time:  27.848735809326172
-------------------------------
-------------------------------
model running time:  10.497023582458496
-------------------------------
-------------------------------
model running time:  27.54047966003418
-------------------------------
Vision time :  85.81910705566406
Action time :  105.14022064208984
Trial 7 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.306560516357422
-------------------------------
-------------------------------
model running time:  16.37990379333496
-------------------------------
-------------------------------
model running time:  27.844608306884766
-------------------------------
-------------------------------
model running time:  10.605567932128906
-------------------------------
-------------------------------
model running time:  27.674623489379883
-------------------------------
Vision time :  85.7706527709961
Action time :  114.11046600341797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.988096237182617
-------------------------------
-------------------------------
model running time:  8.731648445129395
-------------------------------
-------------------------------
model running time:  28.40982437133789
-------------------------------
-------------------------------
model running time:  12.96678352355957
-------------------------------
-------------------------------
model running time:  27.522048950195312
-------------------------------
Vision time :  85.8088607788086
Action time :  108.2952651977539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.72697639465332
-------------------------------
-------------------------------
model running time:  8.443936347961426
-------------------------------
-------------------------------
model running time:  27.658239364624023
-------------------------------
-------------------------------
model running time:  10.554368019104004
-------------------------------
-------------------------------
model running time:  32.95743942260742
-------------------------------
Vision time :  85.80255889892578
Action time :  109.84857940673828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.777151107788086
-------------------------------
-------------------------------
model running time:  8.400863647460938
-------------------------------
-------------------------------
model running time:  57.133056640625
-------------------------------
-------------------------------
model running time:  10.561535835266113
-------------------------------
-------------------------------
model running time:  27.687936782836914
-------------------------------
Vision time :  85.80802917480469
Action time :  134.08041381835938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.888063430786133
-------------------------------
-------------------------------
model running time:  8.42956829071045
-------------------------------
-------------------------------
model running time:  27.567039489746094
-------------------------------
-------------------------------
model running time:  10.53593635559082
-------------------------------
-------------------------------
model running time:  27.42697525024414
-------------------------------
Vision time :  85.77737426757812
Action time :  107.47801971435547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.256383895874023
-------------------------------
-------------------------------
model running time:  8.52883243560791
-------------------------------
-------------------------------
model running time:  27.614336013793945
-------------------------------
-------------------------------
model running time:  10.452095985412598
-------------------------------
-------------------------------
model running time:  34.49241638183594
-------------------------------
Vision time :  85.81037139892578
Action time :  112.00418853759766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.86419105529785
-------------------------------
-------------------------------
model running time:  8.698975563049316
-------------------------------
-------------------------------
model running time:  30.658655166625977
-------------------------------
-------------------------------
model running time:  11.423744201660156
-------------------------------
-------------------------------
model running time:  27.696128845214844
-------------------------------
Vision time :  85.85209655761719
Action time :  109.36627197265625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.860095977783203
-------------------------------
-------------------------------
model running time:  13.113344192504883
-------------------------------
-------------------------------
model running time:  27.692096710205078
-------------------------------
-------------------------------
model running time:  10.52774429321289
-------------------------------
-------------------------------
model running time:  27.502592086791992
-------------------------------
Vision time :  85.8100814819336
Action time :  111.47468566894531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.956544876098633
-------------------------------
-------------------------------
model running time:  8.455167770385742
-------------------------------
-------------------------------
model running time:  27.638784408569336
-------------------------------
-------------------------------
model running time:  10.473471641540527
-------------------------------
-------------------------------
model running time:  27.57219123840332
-------------------------------
Vision time :  85.8333740234375
Action time :  109.7523193359375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.819040298461914
-------------------------------
-------------------------------
model running time:  8.424448013305664
-------------------------------
-------------------------------
model running time:  27.50771141052246
-------------------------------
-------------------------------
model running time:  10.506239891052246
-------------------------------
-------------------------------
model running time:  34.786399841308594
-------------------------------
Vision time :  85.8252182006836
Action time :  111.64057922363281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.809919357299805
-------------------------------
-------------------------------
model running time:  8.475647926330566
-------------------------------
-------------------------------
model running time:  31.832063674926758
-------------------------------
-------------------------------
model running time:  10.52569580078125
-------------------------------
-------------------------------
model running time:  27.53638458251953
-------------------------------
Vision time :  85.8397445678711
Action time :  108.8358383178711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.925504684448242
-------------------------------
-------------------------------
model running time:  8.389535903930664
-------------------------------
-------------------------------
model running time:  27.479040145874023
-------------------------------
-------------------------------
model running time:  10.466303825378418
-------------------------------
-------------------------------
model running time:  27.450368881225586
-------------------------------
Vision time :  85.8012466430664
Action time :  104.32115173339844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.777151107788086
-------------------------------
-------------------------------
model running time:  8.438783645629883
-------------------------------
-------------------------------
model running time:  27.593727111816406
-------------------------------
-------------------------------
model running time:  10.570752143859863
-------------------------------
-------------------------------
model running time:  27.442176818847656
-------------------------------
Vision time :  85.81600189208984
Action time :  104.3763198852539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.574848175048828
-------------------------------
-------------------------------
model running time:  8.478719711303711
-------------------------------
-------------------------------
model running time:  27.56403160095215
-------------------------------
-------------------------------
model running time:  10.441727638244629
-------------------------------
-------------------------------
model running time:  27.469696044921875
-------------------------------
Vision time :  85.78227233886719
Action time :  105.20575714111328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89900779724121
-------------------------------
-------------------------------
model running time:  8.453120231628418


 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:30<01:28,  5.20s/it][A[A-------------------------------
-------------------------------
model running time:  27.596704483032227
-------------------------------
-------------------------------
model running time:  10.501055717468262
-------------------------------
-------------------------------
model running time:  32.16998291015625
-------------------------------
Vision time :  85.7652816772461
Action time :  109.31501007080078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.7761287689209
-------------------------------
-------------------------------
model running time:  8.372223854064941
-------------------------------
-------------------------------
model running time:  27.563007354736328
-------------------------------
-------------------------------
model running time:  10.457088470458984
-------------------------------
-------------------------------
model running time:  27.446271896362305
-------------------------------
Vision time :  85.80025482177734
Action time :  104.17561340332031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.887680053710938
-------------------------------
-------------------------------
model running time:  14.4967679977417
-------------------------------
-------------------------------
model running time:  27.736928939819336
-------------------------------
-------------------------------
model running time:  10.53286361694336
-------------------------------
-------------------------------
model running time:  27.49648094177246
-------------------------------
Vision time :  85.84819030761719
Action time :  110.83277130126953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.866304397583008
-------------------------------
-------------------------------
model running time:  8.426495552062988
-------------------------------
-------------------------------
model running time:  31.8351993560791
-------------------------------
-------------------------------
model running time:  10.554304122924805
-------------------------------
-------------------------------
model running time:  27.596799850463867
-------------------------------
Vision time :  85.8116455078125
Action time :  108.96588897705078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.850879669189453
-------------------------------
-------------------------------
model running time:  8.453120231628418
-------------------------------
-------------------------------
model running time:  27.602943420410156
-------------------------------
-------------------------------
model running time:  10.469375610351562
-------------------------------
-------------------------------
model running time:  27.422719955444336
-------------------------------
Vision time :  85.83139038085938
Action time :  104.65074920654297
Trial 8 finished, success: tensor([True]), steps: 295
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.812992095947266
-------------------------------
-------------------------------
model running time:  8.418144226074219
-------------------------------
-------------------------------
model running time:  27.57529640197754
-------------------------------
-------------------------------
model running time:  10.438655853271484
-------------------------------
-------------------------------
model running time:  30.575584411621094
-------------------------------
Vision time :  85.80892944335938
Action time :  107.47698974609375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.641984939575195
-------------------------------
-------------------------------
model running time:  8.38969612121582
-------------------------------
-------------------------------
model running time:  32.0
-------------------------------
-------------------------------
model running time:  10.476544380187988
-------------------------------
-------------------------------
model running time:  27.38275146484375
-------------------------------
Vision time :  85.83920288085938
Action time :  108.60749053955078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.6889591217041
-------------------------------
-------------------------------
model running time:  8.475647926330566
-------------------------------
-------------------------------
model running time:  27.51487922668457
-------------------------------
-------------------------------
model running time:  13.188096046447754
-------------------------------
-------------------------------
model running time:  27.356159210205078
-------------------------------
Vision time :  85.81878662109375
Action time :  106.90048217773438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.862911224365234
-------------------------------
-------------------------------
model running time:  8.479743957519531
-------------------------------
-------------------------------
model running time:  27.585535049438477
-------------------------------
-------------------------------
model running time:  10.589183807373047
-------------------------------
-------------------------------
model running time:  27.374591827392578
-------------------------------
Vision time :  85.8431396484375
Action time :  109.36748504638672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.090368270874023
-------------------------------
-------------------------------
model running time:  8.46025562286377
-------------------------------
-------------------------------
model running time:  27.687936782836914
-------------------------------
-------------------------------
model running time:  10.574848175048828
-------------------------------
-------------------------------
model running time:  27.471872329711914
-------------------------------
Vision time :  85.8025894165039
Action time :  110.23363494873047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.991167068481445
-------------------------------
-------------------------------
model running time:  13.222911834716797
-------------------------------
-------------------------------
model running time:  27.833343505859375
-------------------------------
-------------------------------
model running time:  10.564607620239258
-------------------------------
-------------------------------
model running time:  27.596799850463867
-------------------------------
Vision time :  85.78502655029297
Action time :  110.33293151855469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.835519790649414
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  27.56915283203125
-------------------------------
-------------------------------
model running time:  10.457951545715332
-------------------------------
-------------------------------
model running time:  32.1341438293457
-------------------------------
Vision time :  85.8090591430664
Action time :  109.80147552490234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.879552841186523
-------------------------------
-------------------------------
model running time:  10.63219165802002
-------------------------------
-------------------------------
model running time:  27.716480255126953
-------------------------------
-------------------------------
model running time:  10.532896041870117
-------------------------------
-------------------------------
model running time:  27.598848342895508
-------------------------------
Vision time :  85.78076934814453
Action time :  107.76268768310547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.287296295166016
-------------------------------
-------------------------------
model running time:  8.433600425720215
-------------------------------
-------------------------------
model running time:  27.443199157714844
-------------------------------
-------------------------------
model running time:  10.425344467163086
-------------------------------
-------------------------------
model running time:  27.274240493774414
-------------------------------
Vision time :  85.79888153076172
Action time :  110.18844604492188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.447391510009766
-------------------------------
-------------------------------
model running time:  8.467455863952637
-------------------------------
-------------------------------
model running time:  27.677696228027344
-------------------------------
-------------------------------
model running time:  10.4519681930542
-------------------------------
-------------------------------
model running time:  27.503616333007812
-------------------------------
Vision time :  85.85526275634766
Action time :  106.7325439453125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.585695266723633
-------------------------------
-------------------------------
model running time:  8.369152069091797
-------------------------------
-------------------------------
model running time:  27.32032012939453
-------------------------------
-------------------------------
model running time:  10.455039978027344
-------------------------------
-------------------------------
model running time:  27.212799072265625
-------------------------------
Vision time :  85.8095703125
Action time :  103.88480377197266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.74025535583496
-------------------------------
-------------------------------
model running time:  8.441856384277344
-------------------------------
-------------------------------
model running time:  31.909727096557617
-------------------------------
-------------------------------
model running time:  10.430463790893555
-------------------------------
-------------------------------
model running time:  27.397119522094727
-------------------------------
Vision time :  85.81011199951172
Action time :  109.4471664428711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.755647659301758
-------------------------------
-------------------------------
model running time:  8.412320137023926
-------------------------------
-------------------------------
model running time:  27.50150489807129
-------------------------------
-------------------------------
model running time:  10.4335355758667
-------------------------------
-------------------------------
model running time:  34.2803840637207
-------------------------------
Vision time :  85.81155395507812
Action time :  112.11366271972656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9051513671875
-------------------------------
-------------------------------
model running time:  8.42956829071045
-------------------------------
-------------------------------
model running time:  35.532798767089844
-------------------------------
-------------------------------
model running time:  10.40176010131836
-------------------------------
-------------------------------
model running time:  27.736064910888672
-------------------------------
Vision time :  85.83760070800781
Action time :  113.62115478515625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.656320571899414
-------------------------------
-------------------------------
model running time:  8.398847579956055
-------------------------------
-------------------------------
model running time:  27.495424270629883
-------------------------------
-------------------------------
model running time:  10.510335922241211
-------------------------------
-------------------------------
model running time:  27.344928741455078
-------------------------------
Vision time :  85.83123016357422
Action time :  104.24320220947266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.53958511352539
-------------------------------
-------------------------------
model running time:  8.432640075683594
-------------------------------
-------------------------------
model running time:  27.551679611206055
-------------------------------
-------------------------------
model running time:  10.497023582458496
-------------------------------
-------------------------------
model running time:  27.241472244262695
-------------------------------
Vision time :  85.80802917480469
Action time :  111.55661010742188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.1712646484375
-------------------------------
-------------------------------
model running time:  8.43887996673584
-------------------------------
-------------------------------
model running time:  27.93484878540039
-------------------------------
-------------------------------
model running time:  10.551456451416016
-------------------------------
-------------------------------
model running time:  27.675647735595703
-------------------------------
Vision time :  85.8338851928711
Action time :  108.04230499267578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.94611167907715
-------------------------------
-------------------------------
model running time:  8.441856384277344
-------------------------------
-------------------------------
model running time:  27.578367233276367
-------------------------------
-------------------------------
model running time:  10.490880012512207
-------------------------------
-------------------------------
model running time:  33.47455978393555
-------------------------------
Vision time :  85.80079650878906
Action time :  111.02617645263672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.90719985961914
-------------------------------
-------------------------------
model running time:  8.458239555358887
-------------------------------
-------------------------------
model running time:  29.107200622558594
-------------------------------
-------------------------------
model running time:  10.540960311889648
-------------------------------
-------------------------------
model running time:  27.419647216796875
-------------------------------
Vision time :  85.79296112060547
Action time :  107.03651428222656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.988224029541016
-------------------------------
-------------------------------
model running time:  8.476672172546387
-------------------------------
-------------------------------
model running time:  27.659135818481445
-------------------------------
-------------------------------
model running time:  16.07263946533203
-------------------------------
-------------------------------
model running time:  27.476991653442383
-------------------------------
Vision time :  

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:38<01:41,  6.35s/it][A[A85.84716796875
Action time :  111.15404510498047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.227455139160156
-------------------------------
-------------------------------
model running time:  8.458239555358887
-------------------------------
-------------------------------
model running time:  27.510784149169922
-------------------------------
-------------------------------
model running time:  10.493951797485352
-------------------------------
-------------------------------
model running time:  27.463712692260742
-------------------------------
Vision time :  85.82931518554688
Action time :  109.7317123413086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.868288040161133
-------------------------------
-------------------------------
model running time:  8.462335586547852
-------------------------------
-------------------------------
model running time:  37.13740921020508
-------------------------------
-------------------------------
model running time:  10.48572826385498
-------------------------------
-------------------------------
model running time:  27.426816940307617
-------------------------------
Vision time :  85.84659576416016
Action time :  114.93679809570312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.688064575195312
-------------------------------
-------------------------------
model running time:  14.780415534973145
-------------------------------
-------------------------------
model running time:  27.58348846435547
-------------------------------
-------------------------------
model running time:  10.424320220947266
-------------------------------
-------------------------------
model running time:  27.303903579711914
-------------------------------
Vision time :  85.86198425292969
Action time :  110.95356750488281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.786367416381836
-------------------------------
-------------------------------
model running time:  8.3886079788208
-------------------------------
-------------------------------
model running time:  27.36128044128418
-------------------------------
-------------------------------
model running time:  10.47152042388916
-------------------------------
-------------------------------
model running time:  27.14214324951172
-------------------------------
Vision time :  85.79174041748047
Action time :  104.15001678466797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.788864135742188
-------------------------------
-------------------------------
model running time:  8.443903923034668
-------------------------------
-------------------------------
model running time:  27.438079833984375
-------------------------------
-------------------------------
model running time:  10.41100788116455
-------------------------------
-------------------------------
model running time:  32.22323226928711
-------------------------------
Vision time :  85.81330871582031
Action time :  110.56230163574219
Trial 9 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.794559478759766
-------------------------------
-------------------------------
model running time:  8.457216262817383
-------------------------------
-------------------------------
model running time:  27.5098876953125
-------------------------------
-------------------------------
model running time:  10.587136268615723
-------------------------------
-------------------------------
model running time:  27.412479400634766
-------------------------------
Vision time :  85.82217407226562
Action time :  105.19245147705078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.12940788269043
-------------------------------
-------------------------------
model running time:  8.523584365844727
-------------------------------
-------------------------------
model running time:  28.1343994140625
-------------------------------
-------------------------------
model running time:  10.668160438537598
-------------------------------
-------------------------------
model running time:  31.923200607299805
-------------------------------
Vision time :  85.80854034423828
Action time :  110.28275299072266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.016511917114258
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  27.602943420410156
-------------------------------
-------------------------------
model running time:  10.565631866455078
-------------------------------
-------------------------------
model running time:  27.402240753173828
-------------------------------
Vision time :  85.82176208496094
Action time :  109.17887878417969


 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:41<01:15,  5.06s/it][A[Abefore pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  34.61529541015625
-------------------------------
-------------------------------
model running time:  8.438624382019043
-------------------------------
-------------------------------
model running time:  27.483135223388672
-------------------------------
-------------------------------
model running time:  10.490880012512207
-------------------------------
-------------------------------
model running time:  27.298816680908203
-------------------------------
Vision time :  85.85372924804688
Action time :  113.12947082519531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.826303482055664
-------------------------------
-------------------------------
model running time:  8.49407958984375
-------------------------------
-------------------------------
model running time:  28.669952392578125
-------------------------------
-------------------------------
model running time:  10.569727897644043
-------------------------------
-------------------------------
model running time:  27.55686378479004
-------------------------------
Vision time :  85.78092956542969
Action time :  105.78022766113281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.845184326171875
-------------------------------
-------------------------------
model running time:  14.564352035522461
-------------------------------
-------------------------------
model running time:  27.813888549804688
-------------------------------
-------------------------------
model running time:  10.480799674987793
-------------------------------
-------------------------------
model running time:  27.552671432495117
-------------------------------
Vision time :  85.82176208496094
Action time :  113.56988525390625
Trial 10 finished, success: tensor([True]), steps: 85
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.020864486694336
-------------------------------
-------------------------------
model running time:  8.437760353088379
-------------------------------
-------------------------------
model running time:  27.895776748657227
-------------------------------
-------------------------------
model running time:  10.552319526672363
-------------------------------
-------------------------------
model running time:  27.68499183654785
-------------------------------
Vision time :  85.82217407226562
Action time :  105.39008331298828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.042367935180664
-------------------------------
-------------------------------
model running time:  8.509440422058105
-------------------------------
-------------------------------
model running time:  27.8721923828125
-------------------------------
-------------------------------
model running time:  10.537983894348145
-------------------------------
-------------------------------
model running time:  27.588607788085938
-------------------------------
Vision time :  85.81385803222656
Action time :  105.2958755493164
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.635263442993164
-------------------------------
-------------------------------
model running time:  14.449664115905762
-------------------------------
-------------------------------
model running time:  27.989152908325195
-------------------------------
-------------------------------
model running time:  10.540032386779785
-------------------------------
-------------------------------
model running time:  27.668479919433594
-------------------------------
Vision time :  85.82633972167969
Action time :  112.86630249023438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.884672164916992
-------------------------------
-------------------------------
model running time:  8.457216262817383
-------------------------------
-------------------------------
model running time:  27.57427215576172
-------------------------------
-------------------------------
model running time:  10.483712196350098
-------------------------------
-------------------------------
model running time:  27.402240753173828
-------------------------------
Vision time :  85.8213119506836
Action time :  104.44790649414062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9051513671875
-------------------------------
-------------------------------
model running time:  8.433664321899414
-------------------------------
-------------------------------
model running time:  27.7923526763916
-------------------------------
-------------------------------
model running time:  10.487808227539062
-------------------------------
-------------------------------
model running time:  27.564960479736328
-------------------------------
Vision time :  85.82508850097656
Action time :  104.76953887939453
before pruning: 


 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:44<01:03,  4.50s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.994144439697266
-------------------------------
-------------------------------
model running time:  8.431615829467773
-------------------------------
-------------------------------
model running time:  27.7073917388916
-------------------------------
-------------------------------
model running time:  10.45299243927002
-------------------------------
-------------------------------
model running time:  27.53023910522461
-------------------------------
Vision time :  85.82176208496094
Action time :  104.81356811523438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.869312286376953
-------------------------------
-------------------------------
model running time:  8.443872451782227
-------------------------------
-------------------------------
model running time:  31.902687072753906
-------------------------------
-------------------------------
model running time:  13.920255661010742
-------------------------------
-------------------------------
model running time:  27.60089683532715
-------------------------------
Vision time :  85.81260681152344
Action time :  116.05705261230469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.051584243774414
-------------------------------
-------------------------------
model running time:  8.43769645690918
-------------------------------
-------------------------------
model running time:  27.619327545166016
-------------------------------
-------------------------------
model running time:  10.513312339782715
-------------------------------
-------------------------------
model running time:  27.57529640197754
-------------------------------
Vision time :  85.801025390625
Action time :  104.90573120117188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.99951934814453
-------------------------------
-------------------------------
model running time:  8.457216262817383
-------------------------------
-------------------------------
model running time:  28.471359252929688
-------------------------------
-------------------------------
model running time:  10.568703651428223
-------------------------------
-------------------------------
model running time:  27.819007873535156
-------------------------------
Vision time :  85.85212707519531
Action time :  105.95123291015625
Trial 11 finished, success: tensor([True]), steps: 137
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.99724769592285
-------------------------------
-------------------------------
model running time:  8.452095985412598
-------------------------------
-------------------------------
model running time:  27.912288665771484
-------------------------------
-------------------------------
model running time:  10.543071746826172
-------------------------------
-------------------------------
model running time:  27.705215454101562
-------------------------------
Vision time :  85.81027221679688
Action time :  105.3380126953125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.13862419128418
-------------------------------
-------------------------------
model running time:  8.476672172546387
-------------------------------
-------------------------------
model running time:  27.74323272705078
-------------------------------
-------------------------------
model running time:  10.527615547180176
-------------------------------
-------------------------------
model running time:  27.658239364624023
-------------------------------
Vision time :  85.86809539794922
Action time :  105.14832305908203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.93177604675293
-------------------------------
-------------------------------
model running time:  8.480863571166992
-------------------------------
-------------------------------
model running time:  33.737728118896484
-------------------------------
-------------------------------
model running time:  10.502143859863281
-------------------------------
-------------------------------
model running time:  27.465728759765625
-------------------------------
Vision time :  85.81334686279297
Action time :  110.76812744140625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.90822410583496
-------------------------------
-------------------------------
model running time:  8.39577579498291
-------------------------------
-------------------------------
model running time:  27.653120040893555
-------------------------------
-------------------------------
model running time:  10.471424102783203
-------------------------------
-------------------------------
model running time:  27.418495178222656
-------------------------------
Vision time :  85.82582092285156
Action time :  104.47154998779297
before pruning: 


 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:46<00:47,  3.68s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.80838394165039
-------------------------------
-------------------------------
model running time:  8.453120231628418
-------------------------------
-------------------------------
model running time:  28.904447555541992
-------------------------------
-------------------------------
model running time:  10.505215644836426
-------------------------------
-------------------------------
model running time:  27.593727111816406
-------------------------------
Vision time :  85.9195556640625
Action time :  107.40223693847656
Trial 12 finished, success: tensor([True]), steps: 78
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.235904693603516
-------------------------------
-------------------------------
model running time:  8.539135932922363
-------------------------------
-------------------------------
model running time:  28.242944717407227
-------------------------------
-------------------------------
model running time:  10.69968032836914
-------------------------------
-------------------------------
model running time:  28.12825584411621
-------------------------------
Vision time :  85.83302307128906
Action time :  106.55232238769531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.376384735107422
-------------------------------
-------------------------------
model running time:  8.474623680114746
-------------------------------
-------------------------------
model running time:  27.67475128173828
-------------------------------
-------------------------------
model running time:  10.515456199645996
-------------------------------
-------------------------------
model running time:  27.635711669921875
-------------------------------
Vision time :  85.82803344726562
Action time :  110.28070068359375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.43199920654297
-------------------------------
-------------------------------
model running time:  8.509344100952148
-------------------------------
-------------------------------
model running time:  27.72172737121582
-------------------------------
-------------------------------
model running time:  10.561440467834473
-------------------------------
-------------------------------
model running time:  27.635711669921875
-------------------------------
Vision time :  85.82998657226562
Action time :  106.4796142578125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.886720657348633
-------------------------------
-------------------------------
model running time:  8.417280197143555
-------------------------------
-------------------------------
model running time:  27.7093448638916
-------------------------------
-------------------------------
model running time:  10.541055679321289
-------------------------------
-------------------------------
model running time:  34.3480339050293
-------------------------------
Vision time :  85.81523132324219
Action time :  111.56275177001953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9368953704834
-------------------------------
-------------------------------
model running time:  8.42956829071045
-------------------------------
-------------------------------
model running time:  27.704320907592773
-------------------------------
-------------------------------
model running time:  10.556415557861328
-------------------------------
-------------------------------
model running time:  32.301055908203125
-------------------------------
Vision time :  85.81062316894531
Action time :  109.61510467529297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.179584503173828
-------------------------------
-------------------------------
model running time:  8.472576141357422
-------------------------------
-------------------------------
model running time:  27.97551918029785
-------------------------------
-------------------------------
model running time:  15.566847801208496
-------------------------------
-------------------------------
model running time:  27.990079879760742
-------------------------------
Vision time :  85.7977294921875
Action time :  110.96473693847656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.35264015197754
-------------------------------
-------------------------------
model running time:  8.42249584197998
-------------------------------
-------------------------------
model running time:  27.998207092285156
-------------------------------
-------------------------------
model running time:  10.520575523376465
-------------------------------
-------------------------------
model running time:  27.896831512451172
-------------------------------
Vision time :  85.86697387695312
Action time :  105.97277069091797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:49<00:41,  3.47s/it][A[A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:51<00:35,  3.21s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.082304000854492
-------------------------------
-------------------------------
model running time:  8.476672172546387
-------------------------------
-------------------------------
model running time:  27.99001693725586
-------------------------------
-------------------------------
model running time:  10.575679779052734
-------------------------------
-------------------------------
model running time:  27.837343215942383
-------------------------------
Vision time :  85.82774353027344
Action time :  105.76383972167969
Trial 13 finished, success: tensor([True]), steps: 125
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.12019157409668
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  27.9869441986084
-------------------------------
-------------------------------
model running time:  10.564607620239258
-------------------------------
-------------------------------
model running time:  27.936767578125
-------------------------------
Vision time :  85.7874526977539
Action time :  105.8150405883789
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.077056884765625
-------------------------------
-------------------------------
model running time:  9.167872428894043
-------------------------------
-------------------------------
model running time:  28.0053768157959
-------------------------------
-------------------------------
model running time:  10.504192352294922
-------------------------------
-------------------------------
model running time:  27.810815811157227
-------------------------------
Vision time :  85.82572937011719
Action time :  106.30860900878906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.071807861328125
-------------------------------
-------------------------------
model running time:  8.489983558654785
-------------------------------
-------------------------------
model running time:  27.929439544677734
-------------------------------
-------------------------------
model running time:  10.510335922241211
-------------------------------
-------------------------------
model running time:  27.807743072509766
-------------------------------
Vision time :  85.81391906738281
Action time :  109.4277114868164
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  38.57612609863281
-------------------------------
-------------------------------
model running time:  13.534272193908691
-------------------------------
-------------------------------
model running time:  30.527488708496094
-------------------------------
-------------------------------
model running time:  10.537983894348145
-------------------------------
-------------------------------
model running time:  27.870208740234375
-------------------------------
Vision time :  85.81343841552734
Action time :  129.69676208496094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.34342384338379
-------------------------------
-------------------------------
model running time:  10.539039611816406
-------------------------------
-------------------------------
model running time:  28.654464721679688
-------------------------------
-------------------------------
model running time:  10.94041633605957
-------------------------------
-------------------------------
model running time:  28.293119430541992
-------------------------------
Vision time :  85.83574676513672
Action time :  109.60384368896484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.072063446044922
-------------------------------
-------------------------------
model running time:  8.466464042663574
-------------------------------
-------------------------------
model running time:  28.27779197692871
-------------------------------
-------------------------------
model running time:  10.60863971710205
-------------------------------
-------------------------------
model running time:  28.01260757446289
-------------------------------
Vision time :  85.83734130859375
Action time :  106.1928939819336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.26959991455078
-------------------------------
-------------------------------
model running time:  8.469504356384277
-------------------------------
-------------------------------
model running time:  27.93779182434082
-------------------------------
-------------------------------
model running time:  19.510271072387695
-------------------------------
-------------------------------
model running time:  27.815040588378906
-------------------------------
Vision time :  85.82064056396484
Action time :  114.66957092285156
Trial 14 finished, success: tensor([True]), steps: 112
policy.alpha = 1.0policy.temp = 0.01
before pruning: 


 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:53<00:29,  2.91s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.04857635498047
-------------------------------
-------------------------------
model running time:  8.550399780273438
-------------------------------
-------------------------------
model running time:  28.230655670166016
-------------------------------
-------------------------------
model running time:  10.660863876342773
-------------------------------
-------------------------------
model running time:  27.931743621826172
-------------------------------
Vision time :  85.78966522216797
Action time :  113.1704330444336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.93075180053711
-------------------------------
-------------------------------
model running time:  8.440832138061523
-------------------------------
-------------------------------
model running time:  27.811840057373047
-------------------------------
-------------------------------
model running time:  10.451871871948242
-------------------------------
-------------------------------
model running time:  28.892160415649414
-------------------------------
Vision time :  85.83446502685547
Action time :  106.32511901855469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.865280151367188
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  27.7708797454834
-------------------------------
-------------------------------
model running time:  10.454015731811523
-------------------------------
-------------------------------
model running time:  27.579391479492188
-------------------------------
Vision time :  85.85855865478516
Action time :  104.87391662597656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.292831420898438
-------------------------------
-------------------------------
model running time:  8.427359580993652
-------------------------------
-------------------------------
model running time:  27.702335357666016
-------------------------------
-------------------------------
model running time:  15.518719673156738
-------------------------------
-------------------------------
model running time:  27.805696487426758
-------------------------------
Vision time :  85.81011199951172
Action time :  111.47980499267578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9102725982666
-------------------------------
-------------------------------
model running time:  8.440799713134766
-------------------------------
-------------------------------
model running time:  27.72889518737793
-------------------------------
-------------------------------
model running time:  10.574751853942871
-------------------------------
-------------------------------
model running time:  27.632640838623047
-------------------------------
Vision time :  85.82418823242188
Action time :  105.0511703491211
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.037599563598633
-------------------------------
-------------------------------
model running time:  11.992959976196289
-------------------------------
-------------------------------
model running time:  28.12928009033203
-------------------------------
-------------------------------
model running time:  10.474495887756348
-------------------------------
-------------------------------
model running time:  27.675647735595703
-------------------------------
Vision time :  85.92073822021484
Action time :  110.18550109863281
Trial 15 finished, success: tensor([True]), steps: 92
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.09663963317871
-------------------------------
-------------------------------
model running time:  8.377344131469727
-------------------------------
-------------------------------
model running time:  27.881568908691406
-------------------------------
-------------------------------
model running time:  10.465279579162598
-------------------------------
-------------------------------
model running time:  27.656192779541016
-------------------------------
Vision time :  85.79097747802734
Action time :  105.1800308227539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.263551712036133
-------------------------------
-------------------------------
model running time:  8.428544044494629
-------------------------------
-------------------------------
model running time:  27.710464477539062
-------------------------------
-------------------------------
model running time:  10.514431953430176
-------------------------------
-------------------------------
model running time:  32.874366760253906
-------------------------------
Vision time :  85.8572769165039
Action time :  110.9780502319336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.31475257873535
-------------------------------
-------------------------------
model running time:  8.464384078979492
-------------------------------
-------------------------------
model running time:  27.579391479492188
-------------------------------
-------------------------------
model running time:  10.476544380187988
-------------------------------
-------------------------------
model running time:  27.563007354736328
-------------------------------
Vision time :  85.8463363647461
Action time :  105.55596923828125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.392480850219727
-------------------------------
-------------------------------
model running time:  8.423423767089844
-------------------------------
-------------------------------
model running time:  27.734111785888672
-------------------------------
-------------------------------
model running time:  10.494976043701172
-------------------------------
-------------------------------
model running time:  27.624448776245117
-------------------------------
Vision time :  85.82809448242188
Action time :  105.55289459228516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92972755432129
-------------------------------
-------------------------------
model running time:  8.39782428741455
-------------------------------
-------------------------------
model running time:  27.842559814453125
-------------------------------
-------------------------------
model running time:  10.549247741699219
-------------------------------
-------------------------------
model running time:  27.799488067626953
-------------------------------
Vision time :  85.81228637695312
Action time :  105.27439880371094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.067968368530273
-------------------------------
-------------------------------
model running time:  8.460288047790527
-------------------------------
-------------------------------
model running time:  31.112192153930664
-------------------------------
-------------------------------
model running time:  10.463295936584473
-------------------------------
-------------------------------
model running time:  27.649023056030273
-------------------------------
Vision time :  85.8465576171875
Action time :  108.55731201171875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.943967819213867
-------------------------------
-------------------------------
model running time:  8.469504356384277
-------------------------------
-------------------------------
model running time:  27.93471908569336
-------------------------------
-------------------------------
model running time:  10.494976043701172
-------------------------------
-------------------------------
model running time:  27.75347137451172
-------------------------------
Vision time :  85.83529663085938
Action time :  106.04863739013672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.166271209716797
-------------------------------
-------------------------------
model running time:  8.4203519821167
-------------------------------
-------------------------------
model running time:  27.811840057373047
-------------------------------
-------------------------------
model running time:  10.51852798461914
-------------------------------
-------------------------------
model running time:  27.723648071289062
-------------------------------
Vision time :  85.82211303710938
Action time :  105.98291015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.346399307250977
-------------------------------
-------------------------------
model running time:  8.482815742492676
-------------------------------
-------------------------------
model running time:  32.42393493652344
-------------------------------
-------------------------------
model running time:  10.612735748291016
-------------------------------
-------------------------------
model running time:  27.968576431274414
-------------------------------
Vision time :  85.8532485961914
Action time :  110.66675567626953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.02252960205078
-------------------------------
-------------------------------
model running time:  8.498175621032715
-------------------------------
-------------------------------
model running time:  27.864063262939453
-------------------------------
-------------------------------
model running time:  10.6527681350708
-------------------------------
-------------------------------
model running time:  27.79033660888672
-------------------------------
Vision time :  85.83577728271484
Action time :  111.46546936035156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.19603157043457
-------------------------------
-------------------------------
model running time:  8.482815742492676
-------------------------------
-------------------------------
model running time:  27.967487335205078
-------------------------------
-------------------------------
model running time:  10.548224449157715
-------------------------------
-------------------------------
model running time:  29.24847984313965
-------------------------------
Vision time :  85.81100463867188
Action time :  107.23133087158203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.30348777770996
-------------------------------
-------------------------------
model running time:  8.458239555358887
-------------------------------
-------------------------------
model running time:  27.94291114807129
-------------------------------
-------------------------------
model running time:  10.481599807739258
-------------------------------
-------------------------------
model running time:  29.16864013671875
-------------------------------
Vision time :  85.8853759765625
Action time :  107.17183685302734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.12633514404297
-------------------------------
-------------------------------
model running time:  8.421248435974121
-------------------------------
-------------------------------
model running time:  27.94495964050293
-------------------------------
-------------------------------
model running time:  10.481663703918457
-------------------------------
-------------------------------
model running time:  27.830272674560547
-------------------------------
Vision time :  85.8326416015625
Action time :  106.18163299560547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.29427146911621
-------------------------------
-------------------------------
model running time:  8.466431617736816
-------------------------------
-------------------------------
model running time:  28.068832397460938
-------------------------------
-------------------------------
model running time:  10.519712448120117
-------------------------------
-------------------------------
model running time:  30.706560134887695
-------------------------------
Vision time :  85.82637023925781
Action time :  108.86758422851562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.951263427734375
-------------------------------
-------------------------------
model running time:  8.462335586547852
-------------------------------
-------------------------------
model running time:  27.817983627319336
-------------------------------
-------------------------------
model running time:  10.505375862121582
-------------------------------
-------------------------------
model running time:  33.3752326965332
-------------------------------
Vision time :  85.84505462646484
Action time :  110.68307495117188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.099712371826172
-------------------------------
-------------------------------
model running time:  8.438847541809082
-------------------------------
-------------------------------
model running time:  33.01375961303711
-------------------------------
-------------------------------
model running time:  10.512384414672852
-------------------------------
-------------------------------
model running time:  27.701248168945312
-------------------------------
Vision time :  85.83100891113281
Action time :  110.42816162109375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.32921600341797
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  28.010496139526367
-------------------------------
-------------------------------
model running time:  10.539008140563965
-------------------------------
-------------------------------
model running time:  32.084896087646484
-------------------------------
Vision time :  85.84291076660156
Action time :  111.54841613769531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.193920135498047
-------------------------------
-------------------------------
model running time:  8.46735954284668
-------------------------------
-------------------------------
model running time:  27.95929527282715
-------------------------------
-------------------------------
model running time:  10.586112022399902
-------------------------------
-------------------------------
model running time:  27.787263870239258
-------------------------------
Vision time :  85.84349060058594
Action time :  106.47039794921875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [01:03<00:43,  4.78s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.036224365234375
-------------------------------
-------------------------------
model running time:  8.454048156738281
-------------------------------
-------------------------------
model running time:  27.874399185180664
-------------------------------
-------------------------------
model running time:  10.51638412475586
-------------------------------
-------------------------------
model running time:  34.76076889038086
-------------------------------
Vision time :  85.78511810302734
Action time :  112.9717788696289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.12224006652832
-------------------------------
-------------------------------
model running time:  8.39577579498291
-------------------------------
-------------------------------
model running time:  27.75142478942871
-------------------------------
-------------------------------
model running time:  10.4335355758667
-------------------------------
-------------------------------
model running time:  27.588607788085938
-------------------------------
Vision time :  85.84041595458984
Action time :  105.54380798339844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  34.863006591796875
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  28.05446434020996
-------------------------------
-------------------------------
model running time:  10.511360168457031
-------------------------------
-------------------------------
model running time:  27.86524772644043
-------------------------------
Vision time :  85.82854461669922
Action time :  114.85798645019531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.004512786865234
-------------------------------
-------------------------------
model running time:  8.986656188964844
-------------------------------
-------------------------------
model running time:  27.9050235748291
-------------------------------
-------------------------------
model running time:  15.226816177368164
-------------------------------
-------------------------------
model running time:  27.809663772583008
-------------------------------
Vision time :  85.81391906738281
Action time :  110.73638153076172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.051584243774414
-------------------------------
-------------------------------
model running time:  8.423583984375
-------------------------------
-------------------------------
model running time:  27.90822410583496
-------------------------------
-------------------------------
model running time:  15.847423553466797
-------------------------------
-------------------------------
model running time:  27.819007873535156
-------------------------------
Vision time :  85.82637023925781
Action time :  110.86233520507812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.267648696899414
-------------------------------
-------------------------------
model running time:  8.447999954223633
-------------------------------
-------------------------------
model running time:  27.857791900634766
-------------------------------
-------------------------------
model running time:  17.538976669311523
-------------------------------
-------------------------------
model running time:  27.738239288330078
-------------------------------
Vision time :  85.85110473632812
Action time :  113.31686401367188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.019840240478516
-------------------------------
-------------------------------
model running time:  8.392704010009766
-------------------------------
-------------------------------
model running time:  27.856895446777344
-------------------------------
-------------------------------
model running time:  10.522624015808105
-------------------------------
-------------------------------
model running time:  29.136831283569336
-------------------------------
Vision time :  85.83773040771484
Action time :  107.50361633300781
Trial 16 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.11609649658203
-------------------------------
-------------------------------
model running time:  11.231295585632324
-------------------------------
-------------------------------
model running time:  28.14873504638672
-------------------------------
-------------------------------
model running time:  10.588159561157227
-------------------------------
-------------------------------
model running time:  28.040191650390625
-------------------------------
Vision time :  85.81302642822266
Action time :  109.57107543945312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [01:06<00:33,  4.24s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.068096160888672
-------------------------------
-------------------------------
model running time:  13.180928230285645
-------------------------------
-------------------------------
model running time:  28.31769561767578
-------------------------------
-------------------------------
model running time:  10.550271987915039
-------------------------------
-------------------------------
model running time:  28.042240142822266
-------------------------------
Vision time :  85.8154525756836
Action time :  111.41126251220703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.3690242767334
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  27.825151443481445
-------------------------------
-------------------------------
model running time:  10.557439804077148
-------------------------------
-------------------------------
model running time:  27.597824096679688
-------------------------------
Vision time :  85.87455749511719
Action time :  105.91961669921875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.477567672729492
-------------------------------
-------------------------------
model running time:  12.289888381958008
-------------------------------
-------------------------------
model running time:  28.371936798095703
-------------------------------
-------------------------------
model running time:  10.521568298339844
-------------------------------
-------------------------------
model running time:  27.641855239868164
-------------------------------
Vision time :  85.87042999267578
Action time :  110.66162872314453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.88057518005371
-------------------------------
-------------------------------
model running time:  8.465408325195312
-------------------------------
-------------------------------
model running time:  29.483007431030273
-------------------------------
-------------------------------
model running time:  10.792960166931152
-------------------------------
-------------------------------
model running time:  27.80246353149414
-------------------------------
Vision time :  85.84028625488281
Action time :  110.51222229003906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.948223114013672
-------------------------------
-------------------------------
model running time:  8.450943946838379
-------------------------------
-------------------------------
model running time:  27.663423538208008
-------------------------------
-------------------------------
model running time:  10.516480445861816
-------------------------------
-------------------------------
model running time:  27.448352813720703
-------------------------------
Vision time :  85.8367691040039
Action time :  105.18511962890625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.798656463623047
-------------------------------
-------------------------------
model running time:  8.458271980285645
-------------------------------
-------------------------------
model running time:  27.471744537353516
-------------------------------
-------------------------------
model running time:  10.452896118164062
-------------------------------
-------------------------------
model running time:  27.446271896362305
-------------------------------
Vision time :  85.834716796875
Action time :  104.52582550048828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.96659278869629
-------------------------------
-------------------------------
model running time:  8.45417594909668
-------------------------------
-------------------------------
model running time:  27.67558479309082
-------------------------------
-------------------------------
model running time:  10.503168106079102
-------------------------------
-------------------------------
model running time:  27.611135482788086
-------------------------------
Vision time :  85.82249450683594
Action time :  104.95481872558594
Trial 17 finished, success: tensor([True]), steps: 127
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89798355102539
-------------------------------
-------------------------------
model running time:  8.489983558654785
-------------------------------
-------------------------------
model running time:  27.79136085510254
-------------------------------
-------------------------------
model running time:  10.563679695129395
-------------------------------
-------------------------------
model running time:  27.529216766357422
-------------------------------
Vision time :  85.77830505371094
Action time :  104.93132781982422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.949216842651367
-------------------------------
-------------------------------
model running time:  14.379008293151855
-------------------------------
-------------------------------
model running time:  27.821056365966797
-------------------------------
-------------------------------
model running time:  10.482687950134277
-------------------------------
-------------------------------
model running time:  27.54662322998047
-------------------------------
Vision time :  85.81475067138672
Action time :  110.81523132324219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.902080535888672
-------------------------------
-------------------------------
model running time:  8.449024200439453
-------------------------------
-------------------------------
model running time:  27.675647735595703
-------------------------------
-------------------------------
model running time:  10.500096321105957
-------------------------------
-------------------------------
model running time:  32.032833099365234
-------------------------------
Vision time :  85.8388442993164
Action time :  111.78598022460938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.068992614746094
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  27.609088897705078
-------------------------------
-------------------------------
model running time:  10.49078369140625
-------------------------------
-------------------------------
model running time:  27.419647216796875
-------------------------------
Vision time :  85.84441375732422
Action time :  104.83097839355469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.850879669189453
-------------------------------
-------------------------------
model running time:  8.41436767578125
-------------------------------
-------------------------------
model running time:  27.521024703979492
-------------------------------
-------------------------------
model running time:  10.529888153076172
-------------------------------
-------------------------------
model running time:  33.247230529785156
-------------------------------
Vision time :  85.84025573730469
Action time :  110.31244659423828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.55232048034668
-------------------------------
-------------------------------
model running time:  8.395648002624512
-------------------------------
-------------------------------
model running time:  27.55174446105957
-------------------------------
-------------------------------
model running time:  10.491904258728027
-------------------------------
-------------------------------
model running time:  34.286590576171875
-------------------------------
Vision time :  85.9104995727539
Action time :  112.00717163085938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.83228874206543
-------------------------------
-------------------------------
model running time:  8.442943572998047
-------------------------------
-------------------------------
model running time:  27.653120040893555
-------------------------------
-------------------------------
model running time:  10.472448348999023
-------------------------------
-------------------------------
model running time:  31.438880920410156
-------------------------------
Vision time :  85.82819366455078
Action time :  108.55926513671875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.945087432861328
-------------------------------
-------------------------------
model running time:  8.49407958984375
-------------------------------
-------------------------------
model running time:  27.609088897705078
-------------------------------
-------------------------------
model running time:  10.484736442565918
-------------------------------
-------------------------------
model running time:  27.444223403930664
-------------------------------
Vision time :  85.81619262695312
Action time :  107.46880340576172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89695930480957
-------------------------------
-------------------------------
model running time:  8.436863899230957
-------------------------------
-------------------------------
model running time:  27.69615936279297
-------------------------------
-------------------------------
model running time:  10.403840065002441
-------------------------------
-------------------------------
model running time:  27.572223663330078
-------------------------------
Vision time :  85.82498931884766
Action time :  104.63948822021484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.020864486694336
-------------------------------
-------------------------------
model running time:  8.522751808166504
-------------------------------
-------------------------------
model running time:  27.73094367980957
-------------------------------
-------------------------------
model running time:  10.481663703918457
-------------------------------
-------------------------------
model running time:  27.54662322998047
-------------------------------
Vision time :  85.81158447265625
Action time :  105.0091552734375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.75974464416504
-------------------------------
-------------------------------
model running time:  8.491007804870605
-------------------------------
-------------------------------
model running time:  27.672576904296875
-------------------------------
-------------------------------
model running time:  10.516480445861816
-------------------------------
-------------------------------
model running time:  27.57734489440918
-------------------------------
Vision time :  85.8446044921875
Action time :  104.6476821899414
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92255973815918
-------------------------------
-------------------------------
model running time:  8.463359832763672
-------------------------------
-------------------------------
model running time:  27.655168533325195
-------------------------------
-------------------------------
model running time:  10.64140796661377
-------------------------------
-------------------------------
model running time:  35.286014556884766
-------------------------------
Vision time :  85.84579467773438
Action time :  112.6461410522461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.39129638671875
-------------------------------
-------------------------------
model running time:  8.408063888549805
-------------------------------
-------------------------------
model running time:  27.560863494873047
-------------------------------
-------------------------------
model running time:  10.520575523376465
-------------------------------
-------------------------------
model running time:  27.438079833984375
-------------------------------
Vision time :  85.83257293701172
Action time :  108.8880615234375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.016767501831055
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  31.049728393554688
-------------------------------
-------------------------------
model running time:  10.478495597839355
-------------------------------
-------------------------------
model running time:  27.689119338989258
-------------------------------
Vision time :  85.91561889648438
Action time :  109.23212432861328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.875455856323242
-------------------------------
-------------------------------
model running time:  8.458239555358887
-------------------------------
-------------------------------
model running time:  27.810815811157227
-------------------------------
-------------------------------
model running time:  10.54412841796875
-------------------------------
-------------------------------
model running time:  27.677696228027344
-------------------------------
Vision time :  85.86367797851562
Action time :  105.38086700439453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.040319442749023
-------------------------------
-------------------------------
model running time:  8.525823593139648
-------------------------------
-------------------------------
model running time:  28.004352569580078
-------------------------------
-------------------------------
model running time:  10.572832107543945
-------------------------------
-------------------------------
model running time:  27.680896759033203
-------------------------------
Vision time :  85.85481262207031
Action time :  105.99014282226562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.217472076416016
-------------------------------
-------------------------------
model running time:  8.483903884887695
-------------------------------
-------------------------------
model running time:  27.72377586364746
-------------------------------
-------------------------------
model running time:  10.49289608001709
-------------------------------
-------------------------------
model running time:  27.56403160095215
-------------------------------
Vision time :  85.87353515625
Action time :  105.40451049804688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.33011245727539
-------------------------------
-------------------------------
model running time: 

 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [01:15<00:39,  5.67s/it][A[A 8.52889633178711
-------------------------------
-------------------------------
model running time:  27.91417694091797
-------------------------------
-------------------------------
model running time:  10.547200202941895
-------------------------------
-------------------------------
model running time:  27.51487922668457
-------------------------------
Vision time :  85.87506866455078
Action time :  106.56678771972656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.779199600219727
-------------------------------
-------------------------------
model running time:  8.462335586547852
-------------------------------
-------------------------------
model running time:  27.678720474243164
-------------------------------
-------------------------------
model running time:  10.511360168457031
-------------------------------
-------------------------------
model running time:  27.58348846435547
-------------------------------
Vision time :  85.84909057617188
Action time :  104.62617492675781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.21913528442383
-------------------------------
-------------------------------
model running time:  8.491071701049805
-------------------------------
-------------------------------
model running time:  27.70636749267578
-------------------------------
-------------------------------
model running time:  10.492799758911133
-------------------------------
-------------------------------
model running time:  27.438079833984375
-------------------------------
Vision time :  85.84345245361328
Action time :  110.99545288085938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.674816131591797
-------------------------------
-------------------------------
model running time:  8.38758373260498
-------------------------------
-------------------------------
model running time:  27.768831253051758
-------------------------------
-------------------------------
model running time:  10.484800338745117
-------------------------------
-------------------------------
model running time:  29.234176635742188
-------------------------------
Vision time :  85.85433959960938
Action time :  106.24188995361328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.11097526550293
-------------------------------
-------------------------------
model running time:  8.481792449951172
-------------------------------
-------------------------------
model running time:  27.727872848510742
-------------------------------
-------------------------------
model running time:  16.81407928466797
-------------------------------
-------------------------------
model running time:  27.598751068115234
-------------------------------
Vision time :  85.86669158935547
Action time :  113.14790344238281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.707487106323242
-------------------------------
-------------------------------
model running time:  8.436832427978516
-------------------------------
-------------------------------
model running time:  27.471872329711914
-------------------------------
-------------------------------
model running time:  10.501119613647461
-------------------------------
-------------------------------
model running time:  27.315200805664062
-------------------------------
Vision time :  85.88601684570312
Action time :  104.08038330078125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.4965763092041
-------------------------------
-------------------------------
model running time:  8.386719703674316
-------------------------------
-------------------------------
model running time:  27.433984756469727
-------------------------------
-------------------------------
model running time:  10.514431953430176
-------------------------------
-------------------------------
model running time:  27.372671127319336
-------------------------------
Vision time :  85.8406753540039
Action time :  103.71372985839844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.375743865966797
-------------------------------
-------------------------------
model running time:  8.377344131469727
-------------------------------
-------------------------------
model running time:  27.485183715820312
-------------------------------
-------------------------------
model running time:  10.492927551269531
-------------------------------
-------------------------------
model running time:  27.36128044128418
-------------------------------
Vision time :  85.80239868164062
Action time :  103.86841583251953
Trial 18 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.648128509521484
-------------------------------
-------------------------------
model running time:  8.456192016601562
-------------------------------


 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [01:17<00:27,  4.60s/it][A[A-------------------------------
model running time:  27.712543487548828
-------------------------------
-------------------------------
model running time:  10.59017562866211
-------------------------------
-------------------------------
model running time:  27.595775604248047
-------------------------------
Vision time :  85.83618927001953
Action time :  104.6692123413086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.704448699951172
-------------------------------
-------------------------------
model running time:  8.463359832763672
-------------------------------
-------------------------------
model running time:  27.665407180786133
-------------------------------
-------------------------------
model running time:  10.604543685913086
-------------------------------
-------------------------------
model running time:  27.432960510253906
-------------------------------
Vision time :  85.87532806396484
Action time :  104.49510192871094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.32601547241211
-------------------------------
-------------------------------
model running time:  8.416255950927734
-------------------------------
-------------------------------
model running time:  27.418624877929688
-------------------------------
-------------------------------
model running time:  10.545120239257812
-------------------------------
-------------------------------
model running time:  27.36947250366211
-------------------------------
Vision time :  85.85254669189453
Action time :  104.69888305664062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.637887954711914
-------------------------------
-------------------------------
model running time:  8.416255950927734
-------------------------------
-------------------------------
model running time:  27.440128326416016
-------------------------------
-------------------------------
model running time:  10.459136009216309
-------------------------------
-------------------------------
model running time:  27.760639190673828
-------------------------------
Vision time :  85.85100555419922
Action time :  104.35686492919922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.577472686767578
-------------------------------
-------------------------------
model running time:  8.404095649719238
-------------------------------
-------------------------------
model running time:  27.406335830688477
-------------------------------
-------------------------------
model running time:  10.44480037689209
-------------------------------
-------------------------------
model running time:  27.34899139404297
-------------------------------
Vision time :  85.86070251464844
Action time :  104.09779357910156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.5600643157959
-------------------------------
-------------------------------
model running time:  8.391679763793945
-------------------------------
-------------------------------
model running time:  27.410560607910156
-------------------------------
-------------------------------
model running time:  10.480640411376953
-------------------------------
-------------------------------
model running time:  27.436031341552734
-------------------------------
Vision time :  85.81651306152344
Action time :  103.73836517333984
Trial 19 finished, success: tensor([True]), steps: 94
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.816959381103516
-------------------------------
-------------------------------
model running time:  8.424448013305664
-------------------------------
-------------------------------
model running time:  27.91935920715332
-------------------------------
-------------------------------
model running time:  10.545151710510254
-------------------------------
-------------------------------
model running time:  27.471872329711914
-------------------------------
Vision time :  85.84671783447266
Action time :  104.78797149658203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.3787841796875
-------------------------------
-------------------------------
model running time:  8.330240249633789
-------------------------------
-------------------------------
model running time:  27.510784149169922
-------------------------------
-------------------------------
model running time:  10.464256286621094
-------------------------------
-------------------------------
model running time:  27.34796714782715
-------------------------------
Vision time :  85.82950592041016
Action time :  103.53459167480469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.410560607910156
-------------------------------
-------------------------------
model running time:  8.388480186462402
-------------------------------
-------------------------------
model running time:  27.402240753173828
-------------------------------
-------------------------------
model running time:  10.531840324401855
-------------------------------
-------------------------------
model running time:  27.33568000793457
-------------------------------
Vision time :  85.83385467529297
Action time :  103.59910583496094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.214399337768555
-------------------------------
-------------------------------
model running time:  8.663040161132812
-------------------------------
-------------------------------
model running time:  28.282880783081055
-------------------------------
-------------------------------
model running time:  10.704895973205566
-------------------------------
-------------------------------
model running time:  28.086271286010742
-------------------------------
Vision time :  85.85894775390625
Action time :  106.461181640625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.689088821411133
-------------------------------
-------------------------------
model running time:  8.426495552062988
-------------------------------
-------------------------------
model running time:  27.567007064819336
-------------------------------
-------------------------------
model running time:  10.464256286621094
-------------------------------
-------------------------------
model running time:  27.36742401123047
-------------------------------
Vision time :  85.84579467773438
Action time :  104.09062194824219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.51296043395996
-------------------------------
-------------------------------
model running time:  8.365920066833496
-------------------------------
-------------------------------
model running time:  27.34489631652832
-------------------------------
-------------------------------
model running time:  10.439680099487305
-------------------------------
-------------------------------
model running time:  27.3940486907959
-------------------------------
Vision time :  85.8543701171875
Action time :  103.87865447998047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.332735061645508
-------------------------------
-------------------------------
model running time:  8.359935760498047
-------------------------------
-------------------------------
model running time:  27.420671463012695
-------------------------------
-------------------------------
model running time:  10.441727638244629
-------------------------------
-------------------------------
model running time:  27.425792694091797
-------------------------------
Vision time :  85.84194946289062
Action time :  104.43571472167969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.4454402923584
-------------------------------
-------------------------------
model running time:  8.398847579956055
-------------------------------
-------------------------------
model running time:  27.432960510253906
-------------------------------
-------------------------------
model running time:  10.521599769592285
-------------------------------
-------------------------------
model running time:  27.280384063720703
-------------------------------
Vision time :  85.85456085205078
Action time :  104.20121765136719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.403392791748047
-------------------------------
-------------------------------
model running time:  8.348671913146973
-------------------------------
-------------------------------
model running time:  27.447296142578125
-------------------------------
-------------------------------
model running time:  10.522560119628906
-------------------------------
-------------------------------
model running time:  27.437055587768555
-------------------------------
Vision time :  85.84867095947266
Action time :  104.76953887939453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.590784072875977
-------------------------------
-------------------------------
model running time:  8.352767944335938
-------------------------------
-------------------------------
model running time:  27.280384063720703
-------------------------------
-------------------------------
model running time:  10.534912109375
-------------------------------
-------------------------------
model running time:  27.214847564697266
-------------------------------
Vision time :  85.81350708007812
Action time :  103.69833374023438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.350143432617188
-------------------------------
-------------------------------
model running time:  8.418399810791016
-------------------------------
-------------------------------
model running time:  27.313152313232422
-------------------------------
-------------------------------
model running time:  10.668959617614746
-------------------------------
-------------------------------
model running time:  32.454654693603516
-------------------------------
Vision time :  85.81267547607422
Action time :  110.166015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.68191909790039
-------------------------------
-------------------------------
model running time:  8.39577579498291
-------------------------------
-------------------------------
model running time:  27.393024444580078
-------------------------------
-------------------------------
model running time:  10.461183547973633
-------------------------------
-------------------------------
model running time:  27.252704620361328
-------------------------------
Vision time :  85.85379028320312
Action time :  104.31999969482422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.393152236938477
-------------------------------
-------------------------------
model running time:  8.300543785095215
-------------------------------
-------------------------------
model running time:  27.286527633666992
-------------------------------
-------------------------------
model running time:  10.439776420593262
-------------------------------
-------------------------------
model running time:  27.074560165405273
-------------------------------
Vision time :  85.85379028320312
Action time :  103.27056121826172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.2938232421875
-------------------------------
-------------------------------
model running time:  8.383487701416016
-------------------------------
-------------------------------
model running time:  27.285375595092773
-------------------------------
-------------------------------
model running time:  10.500127792358398
-------------------------------
-------------------------------
model running time:  27.221120834350586
-------------------------------
Vision time :  85.82828521728516
Action time :  104.38365173339844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.403392791748047
-------------------------------
-------------------------------
model running time:  8.41539192199707
-------------------------------
-------------------------------
model running time:  27.3571834564209
-------------------------------
-------------------------------
model running time:  10.421248435974121
-------------------------------
-------------------------------
model running time:  27.2096004486084
-------------------------------
Vision time :  85.81977844238281
Action time :  104.72755432128906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.2805118560791
-------------------------------
-------------------------------
model running time:  8.49407958984375
-------------------------------
-------------------------------
model running time:  27.35308837890625
-------------------------------
-------------------------------
model running time:  10.475520133972168
-------------------------------
-------------------------------
model running time:  27.35411262512207
-------------------------------
Vision time :  85.83014678955078
Action time :  104.18482971191406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.192447662353516
-------------------------------
-------------------------------
model running time:  8.339455604553223
-------------------------------
-------------------------------
model running time:  27.294719696044922
-------------------------------
-------------------------------
model running time:  10.397791862487793
-------------------------------
-------------------------------
model running time:  27.233280181884766
-------------------------------
Vision time :  85.84083557128906
Action time :  104.22886657714844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.783424377441406
-------------------------------
-------------------------------
model running time:  8.353792190551758
-------------------------------
-------------------------------
model running time:  27.390975952148438
-------------------------------
-------------------------------
model running time:  10.4335355758667
-------------------------------
-------------------------------
model running time:  32.937889099121094
-------------------------------
Vision time :  85.88102722167969
Action time :  110.02873229980469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.28563117980957
-------------------------------
-------------------------------
model running time:  8.345600128173828
-------------------------------
-------------------------------
model running time:  27.30086326599121
-------------------------------
-------------------------------
model running time:  10.770432472229004
-------------------------------
-------------------------------
model running time:  27.34079933166504
-------------------------------
Vision time :  

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [01:26<00:29,  5.89s/it][A[A85.88380432128906
Action time :  104.64051055908203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.421823501586914
-------------------------------
-------------------------------
model running time:  8.366080284118652
-------------------------------
-------------------------------
model running time:  27.44825553894043
-------------------------------
-------------------------------
model running time:  10.480640411376953
-------------------------------
-------------------------------
model running time:  27.224063873291016
-------------------------------
Vision time :  85.8446044921875
Action time :  103.6410903930664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.275264739990234
-------------------------------
-------------------------------
model running time:  8.40601634979248
-------------------------------
-------------------------------
model running time:  27.921472549438477
-------------------------------
-------------------------------
model running time:  10.504159927368164
-------------------------------
-------------------------------
model running time:  27.329631805419922
-------------------------------
Vision time :  85.82601928710938
Action time :  104.8647689819336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.575424194335938
-------------------------------
-------------------------------
model running time:  8.424448013305664
-------------------------------
-------------------------------
model running time:  27.259904861450195
-------------------------------
-------------------------------
model running time:  10.491904258728027
-------------------------------
-------------------------------
model running time:  27.1646728515625
-------------------------------
Vision time :  85.83030700683594
Action time :  105.68498992919922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.970687866210938
-------------------------------
-------------------------------
model running time:  8.385536193847656
-------------------------------
-------------------------------
model running time:  27.32851219177246
-------------------------------
-------------------------------
model running time:  10.506239891052246
-------------------------------
-------------------------------
model running time:  27.295743942260742
-------------------------------
Vision time :  85.82294464111328
Action time :  105.01631927490234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.04662322998047
-------------------------------
-------------------------------
model running time:  8.421504020690918
-------------------------------
-------------------------------
model running time:  27.373567581176758
-------------------------------
-------------------------------
model running time:  10.467424392700195
-------------------------------
-------------------------------
model running time:  31.954944610595703
-------------------------------
Vision time :  85.85346984863281
Action time :  109.63353729248047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.7073917388916
-------------------------------
-------------------------------
model running time:  8.466431617736816
-------------------------------
-------------------------------
model running time:  27.660287857055664
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  27.456512451171875
-------------------------------
Vision time :  85.8861083984375
Action time :  105.14934539794922
Trial 20 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.883647918701172
-------------------------------
-------------------------------
model running time:  8.425472259521484
-------------------------------
-------------------------------
model running time:  27.75859260559082
-------------------------------
-------------------------------
model running time:  10.536064147949219
-------------------------------
-------------------------------
model running time:  33.362945556640625
-------------------------------
Vision time :  85.84246063232422
Action time :  111.5280990600586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.426816940307617
-------------------------------
-------------------------------
model running time:  8.455167770385742
-------------------------------
-------------------------------
model running time:  27.873279571533203
-------------------------------
-------------------------------
model running time:  10.639360427856445
-------------------------------
-------------------------------
model running time:  27.75142478942871
-------------------------------
Vision time :  85.96934509277344
Action time :  108.0863037109375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.54207992553711
-------------------------------
-------------------------------
model running time:  8.449024200439453
-------------------------------
-------------------------------
model running time:  31.17568016052246
-------------------------------
-------------------------------
model running time:  10.508288383483887
-------------------------------
-------------------------------
model running time:  27.529056549072266
-------------------------------
Vision time :  85.86409759521484
Action time :  110.60940551757812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9420166015625
-------------------------------
-------------------------------
model running time:  8.452095985412598
-------------------------------
-------------------------------
model running time:  27.643871307373047
-------------------------------
-------------------------------
model running time:  10.522624015808105
-------------------------------
-------------------------------
model running time:  27.486207962036133
-------------------------------
Vision time :  85.84534454345703
Action time :  105.87340545654297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.660287857055664
-------------------------------
-------------------------------
model running time:  8.432479858398438
-------------------------------
-------------------------------
model running time:  27.593727111816406
-------------------------------
-------------------------------
model running time:  10.454015731811523
-------------------------------
-------------------------------
model running time:  27.621376037597656
-------------------------------
Vision time :  85.83948516845703
Action time :  106.20822143554688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.860063552856445
-------------------------------
-------------------------------
model running time:  8.40601634979248
-------------------------------
-------------------------------
model running time:  27.57529640197754
-------------------------------
-------------------------------
model running time:  10.44700813293457
-------------------------------
-------------------------------
model running time:  27.425792694091797
-------------------------------
Vision time :  85.86678314208984
Action time :  105.18831634521484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.323423385620117
-------------------------------
-------------------------------
model running time:  8.51353645324707
-------------------------------
-------------------------------
model running time:  27.841535568237305
-------------------------------
-------------------------------
model running time:  10.478591918945312
-------------------------------
-------------------------------
model running time:  27.641855239868164
-------------------------------
Vision time :  85.84979248046875
Action time :  107.72684478759766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.91641616821289
-------------------------------
-------------------------------
model running time:  8.499199867248535
-------------------------------
-------------------------------
model running time:  27.75449562072754
-------------------------------
-------------------------------
model running time:  11.54047966003418
-------------------------------
-------------------------------
model running time:  32.370689392089844
-------------------------------
Vision time :  85.89612579345703
Action time :  112.57344055175781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89593505859375
-------------------------------
-------------------------------
model running time:  8.450048446655273
-------------------------------
-------------------------------
model running time:  27.643903732299805
-------------------------------
-------------------------------
model running time:  10.47766399383545
-------------------------------
-------------------------------
model running time:  27.536256790161133
-------------------------------
Vision time :  85.84003448486328
Action time :  105.49862670898438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.789344787597656
-------------------------------
-------------------------------
model running time:  8.349696159362793
-------------------------------
-------------------------------
model running time:  27.414527893066406
-------------------------------
-------------------------------
model running time:  10.431327819824219
-------------------------------
-------------------------------
model running time:  27.311168670654297
-------------------------------
Vision time :  85.86614227294922
Action time :  103.8387222290039
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952


 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [01:31<00:22,  5.70s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.5098876953125
-------------------------------
-------------------------------
model running time:  8.358912467956543
-------------------------------
-------------------------------
model running time:  34.177982330322266
-------------------------------
-------------------------------
model running time:  10.450943946838379
-------------------------------
-------------------------------
model running time:  27.37049674987793
-------------------------------
Vision time :  85.86083221435547
Action time :  111.15929412841797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.039295196533203
-------------------------------
-------------------------------
model running time:  8.443967819213867
-------------------------------
-------------------------------
model running time:  34.24051284790039
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  27.529216766357422
-------------------------------
Vision time :  85.88236999511719
Action time :  112.73216247558594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.84867286682129
-------------------------------
-------------------------------
model running time:  8.463359832763672
-------------------------------
-------------------------------
model running time:  27.594751358032227
-------------------------------
-------------------------------
model running time:  10.42636775970459
-------------------------------
-------------------------------
model running time:  27.445247650146484
-------------------------------
Vision time :  85.89433288574219
Action time :  104.82892608642578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.865215301513672
-------------------------------
-------------------------------
model running time:  8.422431945800781
-------------------------------
-------------------------------
model running time:  27.529216766357422
-------------------------------
-------------------------------
model running time:  10.488832473754883
-------------------------------
-------------------------------
model running time:  27.456512451171875
-------------------------------
Vision time :  85.8463363647461
Action time :  104.71731567382812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.704448699951172
-------------------------------
-------------------------------
model running time:  8.361984252929688
-------------------------------
-------------------------------
model running time:  27.54764747619629
-------------------------------
-------------------------------
model running time:  10.48588752746582
-------------------------------
-------------------------------
model running time:  27.494400024414062
-------------------------------
Vision time :  85.8855972290039
Action time :  104.32819366455078
Trial 21 finished, success: tensor([True]), steps: 231
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.72287940979004
-------------------------------
-------------------------------
model running time:  8.424448013305664
-------------------------------
-------------------------------
model running time:  32.97894287109375
-------------------------------
-------------------------------
model running time:  10.547200202941895
-------------------------------
-------------------------------
model running time:  27.629600524902344
-------------------------------
Vision time :  85.87648010253906
Action time :  110.33497619628906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.790464401245117
-------------------------------
-------------------------------
model running time:  8.49407958984375
-------------------------------
-------------------------------
model running time:  27.768831253051758
-------------------------------
-------------------------------
model running time:  10.549247741699219
-------------------------------
-------------------------------
model running time:  27.594751358032227
-------------------------------
Vision time :  85.86271667480469
Action time :  105.19961547851562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.79871940612793
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  27.620384216308594
-------------------------------
-------------------------------
model running time:  10.491040229797363
-------------------------------
-------------------------------
model running time:  27.36844825744629
-------------------------------
Vision time :  85.89459228515625
Action time :  104.48886108398438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952


 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [01:34<00:15,  5.04s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.86409568786621
-------------------------------
-------------------------------
model running time:  8.497152328491211
-------------------------------
-------------------------------
model running time:  29.833215713500977
-------------------------------
-------------------------------
model running time:  10.491904258728027
-------------------------------
-------------------------------
model running time:  27.75155258178711
-------------------------------
Vision time :  85.86182403564453
Action time :  109.79122924804688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.75152015686035
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  27.602943420410156
-------------------------------
-------------------------------
model running time:  10.441727638244629
-------------------------------
-------------------------------
model running time:  33.71926498413086
-------------------------------
Vision time :  85.86067199707031
Action time :  111.77369689941406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9737606048584
-------------------------------
-------------------------------
model running time:  8.370176315307617
-------------------------------
-------------------------------
model running time:  27.52409553527832
-------------------------------
-------------------------------
model running time:  10.462207794189453
-------------------------------
-------------------------------
model running time:  27.387903213500977
-------------------------------
Vision time :  85.85926055908203
Action time :  104.90573120117188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.69113540649414
-------------------------------
-------------------------------
model running time:  8.42137622833252
-------------------------------
-------------------------------
model running time:  27.444223403930664
-------------------------------
-------------------------------
model running time:  15.543168067932129
-------------------------------
-------------------------------
model running time:  27.4484806060791
-------------------------------
Vision time :  85.857666015625
Action time :  109.90694427490234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.73516845703125
-------------------------------
-------------------------------
model running time:  8.357824325561523
-------------------------------
-------------------------------
model running time:  27.4913272857666
-------------------------------
-------------------------------
model running time:  10.478591918945312
-------------------------------
-------------------------------
model running time:  27.629568099975586
-------------------------------
Vision time :  85.87104034423828
Action time :  104.52070617675781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.8538875579834
-------------------------------
-------------------------------
model running time:  8.427519798278809
-------------------------------
-------------------------------
model running time:  27.72480010986328
-------------------------------
-------------------------------
model running time:  10.544063568115234
-------------------------------
-------------------------------
model running time:  27.580415725708008
-------------------------------
Vision time :  85.83875274658203
Action time :  105.86726379394531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.981952667236328
-------------------------------
-------------------------------
model running time:  8.40601634979248
-------------------------------
-------------------------------
model running time:  28.13030433654785
-------------------------------
-------------------------------
model running time:  10.5349760055542
-------------------------------
-------------------------------
model running time:  27.455488204956055
-------------------------------
Vision time :  85.82736206054688
Action time :  105.1514892578125
Trial 22 finished, success: tensor([True]), steps: 147
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.8918399810791
-------------------------------
-------------------------------
model running time:  12.84825611114502
-------------------------------
-------------------------------
model running time:  28.622848510742188
-------------------------------
-------------------------------
model running time:  10.508288383483887
-------------------------------
-------------------------------
model running time:  29.475839614868164
-------------------------------
Vision time :  87.52416229248047
Action time :  112.33586883544922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.81497573852539
-------------------------------
-------------------------------
model running time:  8.474623680114746
-------------------------------
-------------------------------
model running time:  27.775999069213867
-------------------------------
-------------------------------
model running time:  18.010112762451172
-------------------------------
-------------------------------
model running time:  27.55174446105957
-------------------------------
Vision time :  85.87971496582031
Action time :  112.63590240478516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.72083282470703
-------------------------------
-------------------------------
model running time:  8.40601634979248
-------------------------------
-------------------------------
model running time:  27.51795196533203
-------------------------------
-------------------------------
model running time:  10.480640411376953
-------------------------------
-------------------------------
model running time:  30.894079208374023
-------------------------------
Vision time :  85.86431884765625
Action time :  108.23987579345703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.974655151367188
-------------------------------
-------------------------------
model running time:  8.418463706970215
-------------------------------
-------------------------------
model running time:  27.6777286529541
-------------------------------
-------------------------------
model running time:  10.505215644836426
-------------------------------
-------------------------------
model running time:  27.585535049438477
-------------------------------
Vision time :  85.8602523803711
Action time :  105.27334594726562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.90924835205078
-------------------------------
-------------------------------
model running time:  8.465408325195312
-------------------------------
-------------------------------
model running time:  35.748863220214844
-------------------------------
-------------------------------
model running time:  10.423295974731445
-------------------------------
-------------------------------
model running time:  27.446271896362305
-------------------------------
Vision time :  85.90211486816406
Action time :  112.6451187133789
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.780223846435547
-------------------------------
-------------------------------
model running time:  8.52889633178711
-------------------------------
-------------------------------
model running time:  28.248064041137695
-------------------------------
-------------------------------
model running time:  12.421119689941406
-------------------------------
-------------------------------
model running time:  27.418624877929688
-------------------------------
Vision time :  85.84355163574219
Action time :  108.8727035522461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.923551559448242
-------------------------------
-------------------------------
model running time:  8.435744285583496
-------------------------------
-------------------------------
model running time:  27.529216766357422
-------------------------------
-------------------------------
model running time:  10.440704345703125
-------------------------------
-------------------------------
model running time:  30.648319244384766
-------------------------------
Vision time :  85.8529281616211
Action time :  107.66028594970703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.894912719726562
-------------------------------
-------------------------------
model running time:  8.3886079788208
-------------------------------
-------------------------------
model running time:  27.38585662841797
-------------------------------
-------------------------------
model running time:  10.500096321105957
-------------------------------
-------------------------------
model running time:  27.315231323242188
-------------------------------
Vision time :  85.89532470703125
Action time :  107.73709106445312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.27686309814453
-------------------------------
-------------------------------
model running time:  8.450048446655273
-------------------------------
-------------------------------
model running time:  32.489566802978516
-------------------------------
-------------------------------
model running time:  10.488832473754883
-------------------------------
-------------------------------
model running time:  27.43404769897461
-------------------------------
Vision time :  85.97481536865234
Action time :  109.89568328857422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92255973815918
-------------------------------
-------------------------------
model running time:  8.41436767578125
-------------------------------
-------------------------------
model running time:  27.502527236938477
-------------------------------
-------------------------------
model running time:  10.489855766296387
-------------------------------
-------------------------------
model running time:  27.295743942260742
-------------------------------
Vision time :  85.98038482666016
Action time :  104.62838745117188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.704448699951172
-------------------------------
-------------------------------
model running time:  8.385663986206055
-------------------------------
-------------------------------
model running time:  27.405311584472656
-------------------------------
-------------------------------
model running time:  10.492927551269531
-------------------------------
-------------------------------
model running time:  27.210752487182617
-------------------------------
Vision time :  85.87088012695312
Action time :  103.88377380371094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.96566390991211
-------------------------------
-------------------------------
model running time:  8.416255950927734
-------------------------------
-------------------------------
model running time:  27.59676742553711
-------------------------------
-------------------------------
model running time:  10.45798397064209
-------------------------------
-------------------------------
model running time:  27.408384323120117
-------------------------------
Vision time :  85.92809295654297
Action time :  111.61190032958984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.75257682800293
-------------------------------
-------------------------------
model running time:  8.39475154876709
-------------------------------
-------------------------------
model running time:  27.412479400634766
-------------------------------
-------------------------------
model running time:  17.726463317871094
-------------------------------
-------------------------------
model running time:  27.34899139404297
-------------------------------
Vision time :  85.88166046142578
Action time :  112.5027847290039
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.976831436157227
-------------------------------
-------------------------------
model running time:  8.405023574829102
-------------------------------
-------------------------------
model running time:  31.755264282226562
-------------------------------
-------------------------------
model running time:  10.438655853271484
-------------------------------
-------------------------------
model running time:  27.464704513549805
-------------------------------
Vision time :  85.86726379394531
Action time :  108.80614471435547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.77008056640625
-------------------------------
-------------------------------
model running time:  8.40294361114502
-------------------------------
-------------------------------
model running time:  27.480064392089844
-------------------------------
-------------------------------
model running time:  17.045503616333008
-------------------------------
-------------------------------
model running time:  27.36947250366211
-------------------------------
Vision time :  85.88108825683594
Action time :  111.8545913696289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.035968780517578
-------------------------------
-------------------------------
model running time:  8.376319885253906
-------------------------------
-------------------------------
model running time:  27.54252815246582
-------------------------------
-------------------------------
model running time:  10.437631607055664
-------------------------------
-------------------------------
model running time:  27.37049674987793
-------------------------------
Vision time :  85.89734649658203
Action time :  109.33657836914062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.634815216064453
-------------------------------
-------------------------------
model running time:  8.425472259521484
-------------------------------
-------------------------------
model running time:  27.512832641601562
-------------------------------
-------------------------------
model running time:  10.51852798461914
-------------------------------
-------------------------------
model running time:  33.75513458251953
-------------------------------
Vision time :  85.87257385253906
Action time :  111.77164459228516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.859071731567383


 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [01:43<00:12,  6.22s/it][A[A-------------------------------
-------------------------------
model running time:  8.431615829467773
-------------------------------
-------------------------------
model running time:  27.59974479675293
-------------------------------
-------------------------------
model running time:  10.487808227539062
-------------------------------
-------------------------------
model running time:  27.3121280670166
-------------------------------
Vision time :  85.86553955078125
Action time :  108.13235473632812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.144447326660156
-------------------------------
-------------------------------
model running time:  8.401856422424316
-------------------------------
-------------------------------
model running time:  27.495424270629883
-------------------------------
-------------------------------
model running time:  10.445823669433594
-------------------------------
-------------------------------
model running time:  27.31110382080078
-------------------------------
Vision time :  85.84553527832031
Action time :  109.7000961303711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.608640670776367
-------------------------------
-------------------------------
model running time:  8.41318416595459
-------------------------------
-------------------------------
model running time:  27.561983108520508
-------------------------------
-------------------------------
model running time:  10.471424102783203
-------------------------------
-------------------------------
model running time:  31.23302459716797
-------------------------------
Vision time :  85.85964965820312
Action time :  109.27513885498047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.824256896972656
-------------------------------
-------------------------------
model running time:  8.452192306518555
-------------------------------
-------------------------------
model running time:  27.71660804748535
-------------------------------
-------------------------------
model running time:  14.211071968078613
-------------------------------
-------------------------------
model running time:  27.57529640197754
-------------------------------
Vision time :  85.86835479736328
Action time :  109.95187377929688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.125951766967773
-------------------------------
-------------------------------
model running time:  8.446944236755371
-------------------------------
-------------------------------
model running time:  27.496448516845703
-------------------------------
-------------------------------
model running time:  10.511360168457031
-------------------------------
-------------------------------
model running time:  27.488256454467773
-------------------------------
Vision time :  85.85842895507812
Action time :  109.48710632324219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.867263793945312
-------------------------------
-------------------------------
model running time:  8.424448013305664
-------------------------------
-------------------------------
model running time:  27.842559814453125
-------------------------------
-------------------------------
model running time:  10.465375900268555
-------------------------------
-------------------------------
model running time:  27.486207962036133
-------------------------------
Vision time :  85.86595153808594
Action time :  105.67782592773438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.86310386657715
-------------------------------
-------------------------------
model running time:  8.39577579498291
-------------------------------
-------------------------------
model running time:  27.498624801635742
-------------------------------
-------------------------------
model running time:  10.472448348999023
-------------------------------
-------------------------------
model running time:  27.411455154418945
-------------------------------
Vision time :  85.86518096923828
Action time :  104.85759735107422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.665536880493164
-------------------------------
-------------------------------
model running time:  8.400896072387695
-------------------------------
-------------------------------
model running time:  27.467775344848633
-------------------------------
-------------------------------
model running time:  10.44480037689209
-------------------------------
-------------------------------
model running time:  27.322368621826172
-------------------------------
Vision time :  85.89600372314453
Action time :  104.19404602050781
Trial 23 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.102783203125
-------------------------------


 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [01:46<00:05,  5.18s/it][A[A-------------------------------
model running time:  8.698880195617676
-------------------------------
-------------------------------
model running time:  27.91423988342285
-------------------------------
-------------------------------
model running time:  10.613759994506836
-------------------------------
-------------------------------
model running time:  27.94099235534668
-------------------------------
Vision time :  85.84646606445312
Action time :  106.36185455322266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.238815307617188
-------------------------------
-------------------------------
model running time:  8.534015655517578
-------------------------------
-------------------------------
model running time:  27.96236801147461
-------------------------------
-------------------------------
model running time:  10.575872421264648
-------------------------------
-------------------------------
model running time:  28.026880264282227
-------------------------------
Vision time :  85.8670425415039
Action time :  106.14988708496094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.53887939453125
-------------------------------
-------------------------------
model running time:  8.498175621032715
-------------------------------
-------------------------------
model running time:  27.661312103271484
-------------------------------
-------------------------------
model running time:  10.589183807373047
-------------------------------
-------------------------------
model running time:  27.9869441986084
-------------------------------
Vision time :  85.85689544677734
Action time :  106.10176086425781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.00339126586914
-------------------------------
-------------------------------
model running time:  8.499199867248535
-------------------------------
-------------------------------
model running time:  28.17638397216797
-------------------------------
-------------------------------
model running time:  10.686464309692383
-------------------------------
-------------------------------
model running time:  28.294015884399414
-------------------------------
Vision time :  85.86624145507812
Action time :  106.54515075683594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.690271377563477
-------------------------------
-------------------------------
model running time:  8.484864234924316
-------------------------------
-------------------------------
model running time:  32.493568420410156
-------------------------------
-------------------------------
model running time:  10.893312454223633
-------------------------------
-------------------------------
model running time:  27.95315170288086
-------------------------------
Vision time :  85.88153839111328
Action time :  110.20492553710938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.778112411499023
-------------------------------
-------------------------------
model running time:  8.407999992370605
-------------------------------
-------------------------------
model running time:  34.681854248046875
-------------------------------
-------------------------------
model running time:  10.469375610351562
-------------------------------
-------------------------------
model running time:  27.452415466308594
-------------------------------
Vision time :  85.86860656738281
Action time :  111.5995864868164
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.75155258178711
-------------------------------
-------------------------------
model running time:  8.393728256225586
-------------------------------
-------------------------------
model running time:  32.97792053222656
-------------------------------
-------------------------------
model running time:  10.417183876037598
-------------------------------
-------------------------------
model running time:  27.53433609008789
-------------------------------
Vision time :  85.84636688232422
Action time :  110.44351959228516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.932767868041992
-------------------------------
-------------------------------
model running time:  8.459263801574707
-------------------------------
-------------------------------
model running time:  34.539520263671875
-------------------------------
-------------------------------
model running time:  10.512384414672852
-------------------------------
-------------------------------
model running time:  27.579391479492188
-------------------------------
Vision time :  85.86073303222656
Action time :  111.86991882324219
Trial 24 finished, success: tensor([True]), steps: 117
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.003456115722656
-------------------------------
-------------------------------
model running time:  

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [01:48<00:00,  4.26s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [01:48<00:00,  4.35s/it]

 20%|â–ˆâ–ˆ        | 2/10 [03:24<13:46, 103.28s/it][A8.449151992797852
-------------------------------
-------------------------------
model running time:  27.841535568237305
-------------------------------
-------------------------------
model running time:  10.530816078186035
-------------------------------
-------------------------------
model running time:  27.604991912841797
-------------------------------
Vision time :  85.85100555419922
Action time :  105.20780944824219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.858047485351562
-------------------------------
-------------------------------
model running time:  8.460288047790527
-------------------------------
-------------------------------
model running time:  27.74015998840332
-------------------------------
-------------------------------
model running time:  10.51756763458252
-------------------------------
-------------------------------
model running time:  31.24006462097168
-------------------------------
Vision time :  85.85971069335938
Action time :  108.3892822265625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.45859146118164
-------------------------------
-------------------------------
model running time:  8.464384078979492
-------------------------------
-------------------------------
model running time:  27.704320907592773
-------------------------------
-------------------------------
model running time:  10.435487747192383
-------------------------------
-------------------------------
model running time:  27.47590446472168
-------------------------------
Vision time :  85.89894104003906
Action time :  108.24703979492188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.922496795654297
-------------------------------
-------------------------------
model running time:  8.38758373260498
-------------------------------
-------------------------------
model running time:  27.554880142211914
-------------------------------
-------------------------------
model running time:  10.53388786315918
-------------------------------
-------------------------------
model running time:  27.51692771911621
-------------------------------
Vision time :  85.88265228271484
Action time :  105.10745239257812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89507293701172
-------------------------------
-------------------------------
model running time:  8.441760063171387
-------------------------------
-------------------------------
model running time:  27.68694305419922
-------------------------------
-------------------------------
model running time:  10.512384414672852
-------------------------------
-------------------------------
model running time:  27.56595230102539
-------------------------------
Vision time :  85.87388610839844
Action time :  104.84729766845703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.93075180053711
-------------------------------
-------------------------------
model running time:  8.409088134765625
-------------------------------
-------------------------------
model running time:  27.5916805267334
-------------------------------
-------------------------------
model running time:  15.285344123840332
-------------------------------
-------------------------------
model running time:  27.459487915039062
-------------------------------
Vision time :  85.89081573486328
Action time :  109.30995178222656
Trial 25 finished, success: tensor([True]), steps: 91
policy.alpha = 1.0policy.temp = 0.01
policy.alpha = 1.0policy.temp = 0.01
Success rate: 76.0%
Running trial with alpha=1.0, temp=0.01. Re-seeding with 20241201.


  0%|          | 0/25 [00:00<?, ?it/s][A[A

  4%|â–         | 1/25 [00:02<01:07,  2.82s/it][A[Abefore pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.970687866210938
-------------------------------
-------------------------------
model running time:  8.470527648925781
-------------------------------
-------------------------------
model running time:  30.536800384521484
-------------------------------
-------------------------------
model running time:  10.544159889221191
-------------------------------
-------------------------------
model running time:  27.60089683532715
-------------------------------
Vision time :  85.84496307373047
Action time :  108.10265350341797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.834495544433594
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  27.889663696289062
-------------------------------
-------------------------------
model running time:  10.463135719299316
-------------------------------
-------------------------------
model running time:  31.38252830505371
-------------------------------
Vision time :  85.86390686035156
Action time :  108.70988464355469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.80784034729004
-------------------------------
-------------------------------
model running time:  8.40396785736084
-------------------------------
-------------------------------
model running time:  27.580415725708008
-------------------------------
-------------------------------
model running time:  10.462240219116211
-------------------------------
-------------------------------
model running time:  27.402271270751953
-------------------------------
Vision time :  85.84793853759766
Action time :  104.31692504882812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.765888214111328
-------------------------------
-------------------------------
model running time:  8.413215637207031
-------------------------------
-------------------------------
model running time:  35.60438537597656
-------------------------------
-------------------------------
model running time:  10.440704345703125
-------------------------------
-------------------------------
model running time:  27.444223403930664
-------------------------------
Vision time :  85.8524169921875
Action time :  112.30828857421875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92767906188965
-------------------------------
-------------------------------
model running time:  8.439840316772461
-------------------------------
-------------------------------
model running time:  27.618303298950195
-------------------------------
-------------------------------
model running time:  10.496000289916992
-------------------------------
-------------------------------
model running time:  27.430912017822266
-------------------------------
Vision time :  85.86656188964844
Action time :  105.72390747070312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.884672164916992
-------------------------------
-------------------------------
model running time:  8.427519798278809
-------------------------------
-------------------------------
model running time:  27.679744720458984
-------------------------------
-------------------------------
model running time:  10.54412841796875
-------------------------------
-------------------------------
model running time:  27.462656021118164
-------------------------------
Vision time :  85.8280029296875
Action time :  105.23340606689453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.821216583251953
-------------------------------
-------------------------------
model running time:  8.355839729309082
-------------------------------
-------------------------------
model running time:  27.536352157592773
-------------------------------
-------------------------------
model running time:  10.450943946838379
-------------------------------
-------------------------------
model running time:  27.54764747619629
-------------------------------
Vision time :  85.8826904296875
Action time :  104.416259765625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.01942443847656
-------------------------------
-------------------------------
model running time:  8.432767868041992
-------------------------------
-------------------------------
model running time:  28.398591995239258
-------------------------------
-------------------------------
model running time:  10.494112014770508
-------------------------------
-------------------------------
model running time:  27.553855895996094
-------------------------------
Vision time :  85.88105773925781
Action time :  111.55661010742188
Trial 1 finished, success: tensor([True]), steps: 126
policy.alpha = 1.0policy.temp = 0.01
before pruning: 


  8%|â–Š         | 2/25 [00:05<01:01,  2.67s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.846784591674805
-------------------------------
-------------------------------
model running time:  12.366687774658203
-------------------------------
-------------------------------
model running time:  27.72275161743164
-------------------------------
-------------------------------
model running time:  10.579968452453613
-------------------------------
-------------------------------
model running time:  27.710464477539062
-------------------------------
Vision time :  85.86224365234375
Action time :  109.38674926757812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.797760009765625
-------------------------------
-------------------------------
model running time:  8.418335914611816
-------------------------------
-------------------------------
model running time:  34.11763381958008
-------------------------------
-------------------------------
model running time:  10.435711860656738
-------------------------------
-------------------------------
model running time:  27.447296142578125
-------------------------------
Vision time :  85.87078094482422
Action time :  110.92479705810547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.71980857849121
-------------------------------
-------------------------------
model running time:  8.451071739196777
-------------------------------
-------------------------------
model running time:  27.438207626342773
-------------------------------
-------------------------------
model running time:  10.5032320022583
-------------------------------
-------------------------------
model running time:  27.32748794555664
-------------------------------
Vision time :  85.89801788330078
Action time :  104.22364807128906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.968639373779297
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  27.521024703979492
-------------------------------
-------------------------------
model running time:  10.513407707214355
-------------------------------
-------------------------------
model running time:  27.432960510253906
-------------------------------
Vision time :  85.87750244140625
Action time :  104.56063842773438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.956287384033203
-------------------------------
-------------------------------
model running time:  8.452128410339355
-------------------------------
-------------------------------
model running time:  27.78009605407715
-------------------------------
-------------------------------
model running time:  10.544095993041992
-------------------------------
-------------------------------
model running time:  27.612159729003906
-------------------------------
Vision time :  85.87430572509766
Action time :  105.05420684814453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  34.4637451171875
-------------------------------
-------------------------------
model running time:  8.47878360748291
-------------------------------
-------------------------------
model running time:  27.93062400817871
-------------------------------
-------------------------------
model running time:  10.582880020141602
-------------------------------
-------------------------------
model running time:  33.40595245361328
-------------------------------
Vision time :  85.86585235595703
Action time :  119.64739227294922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.95132827758789
-------------------------------
-------------------------------
model running time:  8.451071739196777
-------------------------------
-------------------------------
model running time:  31.486976623535156
-------------------------------
-------------------------------
model running time:  10.55129623413086
-------------------------------
-------------------------------
model running time:  27.810688018798828
-------------------------------
Vision time :  85.84374237060547
Action time :  109.00685119628906
Trial 2 finished, success: tensor([True]), steps: 104
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.929855346679688
-------------------------------
-------------------------------
model running time:  8.451935768127441
-------------------------------
-------------------------------
model running time:  27.828224182128906
-------------------------------
-------------------------------
model running time:  10.475520133972168
-------------------------------
-------------------------------
model running time:  32.93596649169922
-------------------------------
Vision time :  85.88253021240234
Action time :  110.83679962158203
before pruning: 


 12%|â–ˆâ–        | 3/25 [00:07<00:53,  2.43s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.145536422729492
-------------------------------
-------------------------------
model running time:  8.506367683410645
-------------------------------
-------------------------------
model running time:  27.853824615478516
-------------------------------
-------------------------------
model running time:  10.504192352294922
-------------------------------
-------------------------------
model running time:  27.76576042175293
-------------------------------
Vision time :  85.86758422851562
Action time :  109.47379302978516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  34.5088005065918
-------------------------------
-------------------------------
model running time:  8.441856384277344
-------------------------------
-------------------------------
model running time:  27.846656799316406
-------------------------------
-------------------------------
model running time:  10.52774429321289
-------------------------------
-------------------------------
model running time:  27.663360595703125
-------------------------------
Vision time :  85.88416290283203
Action time :  113.70188903808594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.643903732299805
-------------------------------
-------------------------------
model running time:  8.439807891845703
-------------------------------
-------------------------------
model running time:  27.76265525817871
-------------------------------
-------------------------------
model running time:  10.501119613647461
-------------------------------
-------------------------------
model running time:  34.87638473510742
-------------------------------
Vision time :  85.85311889648438
Action time :  113.9210205078125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.43564987182617
-------------------------------
-------------------------------
model running time:  8.439807891845703
-------------------------------
-------------------------------
model running time:  27.683839797973633
-------------------------------
-------------------------------
model running time:  10.494976043701172
-------------------------------
-------------------------------
model running time:  27.511808395385742
-------------------------------
Vision time :  85.89170837402344
Action time :  112.28864288330078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.15488052368164
-------------------------------
-------------------------------
model running time:  8.438783645629883
-------------------------------
-------------------------------
model running time:  27.797504425048828
-------------------------------
-------------------------------
model running time:  11.532320022583008
-------------------------------
-------------------------------
model running time:  27.777023315429688
-------------------------------
Vision time :  85.91712188720703
Action time :  108.38937377929688
Trial 3 finished, success: tensor([True]), steps: 94
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.13862419128418
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  32.991233825683594
-------------------------------
-------------------------------
model running time:  10.578047752380371
-------------------------------
-------------------------------
model running time:  27.77190399169922
-------------------------------
Vision time :  85.90870666503906
Action time :  110.70873260498047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.19046401977539
-------------------------------
-------------------------------
model running time:  8.451168060302734
-------------------------------
-------------------------------
model running time:  28.009376525878906
-------------------------------
-------------------------------
model running time:  10.54304027557373
-------------------------------
-------------------------------
model running time:  27.57632064819336
-------------------------------
Vision time :  85.89347076416016
Action time :  111.4131851196289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.871360778808594
-------------------------------
-------------------------------
model running time:  8.467455863952637
-------------------------------
-------------------------------
model running time:  28.900352478027344
-------------------------------
-------------------------------
model running time:  10.611712455749512
-------------------------------
-------------------------------
model running time:  27.602943420410156
-------------------------------
Vision time :  85.87513732910156
Action time :  106.03199768066406
before pruning: 


 16%|â–ˆâ–Œ        | 4/25 [00:10<00:53,  2.57s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.013696670532227
-------------------------------
-------------------------------
model running time:  8.455167770385742
-------------------------------
-------------------------------
model running time:  27.72377586364746
-------------------------------
-------------------------------
model running time:  10.530816078186035
-------------------------------
-------------------------------
model running time:  27.5097599029541
-------------------------------
Vision time :  85.87312316894531
Action time :  104.83814239501953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.977855682373047
-------------------------------
-------------------------------
model running time:  8.42956829071045
-------------------------------
-------------------------------
model running time:  31.365055084228516
-------------------------------
-------------------------------
model running time:  10.546175956726074
-------------------------------
-------------------------------
model running time:  27.691007614135742
-------------------------------
Vision time :  85.8892822265625
Action time :  108.6750717163086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.9006404876709
-------------------------------
-------------------------------
model running time:  8.468576431274414
-------------------------------
-------------------------------
model running time:  27.807680130004883
-------------------------------
-------------------------------
model running time:  10.53286361694336
-------------------------------
-------------------------------
model running time:  31.928319931030273
-------------------------------
Vision time :  85.87036895751953
Action time :  113.26361846923828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.996288299560547
-------------------------------
-------------------------------
model running time:  8.49619197845459
-------------------------------
-------------------------------
model running time:  27.814912796020508
-------------------------------
-------------------------------
model running time:  10.583040237426758
-------------------------------
-------------------------------
model running time:  27.54252815246582
-------------------------------
Vision time :  85.8617935180664
Action time :  108.23065948486328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.675519943237305
-------------------------------
-------------------------------
model running time:  8.455167770385742
-------------------------------
-------------------------------
model running time:  27.887615203857422
-------------------------------
-------------------------------
model running time:  10.497152328491211
-------------------------------
-------------------------------
model running time:  27.60086441040039
-------------------------------
Vision time :  85.95855712890625
Action time :  108.86975860595703
Trial 4 finished, success: tensor([True]), steps: 116
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.093568801879883
-------------------------------
-------------------------------
model running time:  8.483839988708496
-------------------------------
-------------------------------
model running time:  29.498432159423828
-------------------------------
-------------------------------
model running time:  10.502143859863281
-------------------------------
-------------------------------
model running time:  27.896831512451172
-------------------------------
Vision time :  85.87760162353516
Action time :  106.94656372070312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.007551193237305
-------------------------------
-------------------------------
model running time:  8.483839988708496
-------------------------------
-------------------------------
model running time:  28.02079963684082
-------------------------------
-------------------------------
model running time:  10.499967575073242
-------------------------------
-------------------------------
model running time:  27.88140869140625
-------------------------------
Vision time :  85.87554931640625
Action time :  105.88262176513672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.662208557128906
-------------------------------
-------------------------------
model running time:  8.443903923034668
-------------------------------
-------------------------------
model running time:  27.928672790527344
-------------------------------
-------------------------------
model running time:  10.554400444030762
-------------------------------
-------------------------------
model running time:  27.62531280517578
-------------------------------
Vision time :  85.88195037841797
Action time :  108.91567993164062
before pruning: 


 20%|â–ˆâ–ˆ        | 5/25 [00:12<00:47,  2.37s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.075071334838867
-------------------------------
-------------------------------
model running time:  8.42137622833252
-------------------------------
-------------------------------
model running time:  27.72275161743164
-------------------------------
-------------------------------
model running time:  10.555392265319824
-------------------------------
-------------------------------
model running time:  27.69715118408203
-------------------------------
Vision time :  85.88396453857422
Action time :  105.21593475341797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.157920837402344
-------------------------------
-------------------------------
model running time:  8.518655776977539
-------------------------------
-------------------------------
model running time:  32.00204849243164
-------------------------------
-------------------------------
model running time:  10.496000289916992
-------------------------------
-------------------------------
model running time:  27.74732780456543
-------------------------------
Vision time :  85.88480377197266
Action time :  109.7000961303711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.084543228149414
-------------------------------
-------------------------------
model running time:  8.449024200439453
-------------------------------
-------------------------------
model running time:  27.993087768554688
-------------------------------
-------------------------------
model running time:  10.576895713806152
-------------------------------
-------------------------------
model running time:  27.715648651123047
-------------------------------
Vision time :  85.86630249023438
Action time :  110.67903900146484
Trial 5 finished, success: tensor([True]), steps: 84
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92153549194336
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  27.662336349487305
-------------------------------
-------------------------------
model running time:  10.613759994506836
-------------------------------
-------------------------------
model running time:  27.76166343688965
-------------------------------
Vision time :  85.88652801513672
Action time :  105.0798110961914
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.001407623291016
-------------------------------
-------------------------------
model running time:  8.474623680114746
-------------------------------
-------------------------------
model running time:  27.866111755371094
-------------------------------
-------------------------------
model running time:  10.526687622070312
-------------------------------
-------------------------------
model running time:  37.23276901245117
-------------------------------
Vision time :  85.9681625366211
Action time :  114.83135986328125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.038272857666016
-------------------------------
-------------------------------
model running time:  8.419327735900879
-------------------------------
-------------------------------
model running time:  27.878400802612305
-------------------------------
-------------------------------
model running time:  10.516480445861816
-------------------------------
-------------------------------
model running time:  27.638784408569336
-------------------------------
Vision time :  85.88275146484375
Action time :  105.216064453125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.278976440429688
-------------------------------
-------------------------------
model running time:  8.532992362976074
-------------------------------
-------------------------------
model running time:  35.4150390625
-------------------------------
-------------------------------
model running time:  10.529791831970215
-------------------------------
-------------------------------
model running time:  27.917312622070312
-------------------------------
Vision time :  85.90396881103516
Action time :  113.6416015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.841663360595703
-------------------------------
-------------------------------
model running time:  8.438783645629883
-------------------------------
-------------------------------
model running time:  33.704959869384766
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  27.857919692993164
-------------------------------
Vision time :  85.91107177734375
Action time :  110.97708892822266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 24%|â–ˆâ–ˆâ–       | 6/25 [00:14<00:44,  2.32s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.857471466064453
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  31.936511993408203
-------------------------------
-------------------------------
model running time:  10.536959648132324
-------------------------------
-------------------------------
model running time:  27.829248428344727
-------------------------------
Vision time :  85.90092468261719
Action time :  110.44044494628906
Trial 6 finished, success: tensor([True]), steps: 95
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.08028793334961
-------------------------------
-------------------------------
model running time:  8.446911811828613
-------------------------------
-------------------------------
model running time:  27.828224182128906
-------------------------------
-------------------------------
model running time:  10.462207794189453
-------------------------------
-------------------------------
model running time:  27.72172737121582
-------------------------------
Vision time :  85.89209747314453
Action time :  105.26310729980469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.10089683532715
-------------------------------
-------------------------------
model running time:  8.452095985412598
-------------------------------
-------------------------------
model running time:  28.12928009033203
-------------------------------
-------------------------------
model running time:  14.931967735290527
-------------------------------
-------------------------------
model running time:  27.78009605407715
-------------------------------
Vision time :  85.90825653076172
Action time :  110.30425262451172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.11916732788086
-------------------------------
-------------------------------
model running time:  8.416255950927734
-------------------------------
-------------------------------
model running time:  27.72889518737793
-------------------------------
-------------------------------
model running time:  10.661888122558594
-------------------------------
-------------------------------
model running time:  27.696128845214844
-------------------------------
Vision time :  85.90838623046875
Action time :  105.4197769165039
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.945472717285156
-------------------------------
-------------------------------
model running time:  8.476799964904785
-------------------------------
-------------------------------
model running time:  27.797504425048828
-------------------------------
-------------------------------
model running time:  10.467328071594238
-------------------------------
-------------------------------
model running time:  27.428863525390625
-------------------------------
Vision time :  85.884765625
Action time :  107.06022644042969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.672704696655273
-------------------------------
-------------------------------
model running time:  8.434687614440918
-------------------------------
-------------------------------
model running time:  27.54047966003418
-------------------------------
-------------------------------
model running time:  10.51750373840332
-------------------------------
-------------------------------
model running time:  32.82841491699219
-------------------------------
Vision time :  85.87635040283203
Action time :  109.93049621582031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.055679321289062
-------------------------------
-------------------------------
model running time:  8.404928207397461
-------------------------------
-------------------------------
model running time:  27.619327545166016
-------------------------------
-------------------------------
model running time:  10.424320220947266
-------------------------------
-------------------------------
model running time:  27.472896575927734
-------------------------------
Vision time :  85.88118743896484
Action time :  105.74336242675781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.952224731445312
-------------------------------
-------------------------------
model running time:  8.423423767089844
-------------------------------
-------------------------------
model running time:  27.815935134887695
-------------------------------
-------------------------------
model running time:  10.497983932495117
-------------------------------
-------------------------------
model running time:  27.673599243164062
-------------------------------
Vision time :  85.86589050292969
Action time :  105.91744232177734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.11199951171875
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  27.757568359375
-------------------------------
-------------------------------
model running time:  10.514431953430176
-------------------------------
-------------------------------
model running time:  27.616256713867188
-------------------------------
Vision time :  85.8583984375
Action time :  106.06591796875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.911296844482422
-------------------------------
-------------------------------
model running time:  11.23840045928955
-------------------------------
-------------------------------
model running time:  27.78214454650879
-------------------------------
-------------------------------
model running time:  10.513407707214355
-------------------------------
-------------------------------
model running time:  27.668479919433594
-------------------------------
Vision time :  85.86339569091797
Action time :  108.65135955810547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.996288299560547
-------------------------------
-------------------------------
model running time:  8.432640075683594
-------------------------------
-------------------------------
model running time:  27.662336349487305
-------------------------------
-------------------------------
model running time:  10.546175956726074
-------------------------------
-------------------------------
model running time:  27.652095794677734
-------------------------------
Vision time :  85.86073303222656
Action time :  105.22624206542969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.807872772216797
-------------------------------
-------------------------------
model running time:  8.469504356384277
-------------------------------
-------------------------------
model running time:  27.579391479492188
-------------------------------
-------------------------------
model running time:  10.497023582458496
-------------------------------
-------------------------------
model running time:  31.882112503051758
-------------------------------
Vision time :  85.92057800292969
Action time :  109.26898956298828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.601472854614258
-------------------------------
-------------------------------
model running time:  8.4367036819458
-------------------------------
-------------------------------
model running time:  27.836416244506836
-------------------------------
-------------------------------
model running time:  10.515456199645996
-------------------------------
-------------------------------
model running time:  27.610111236572266
-------------------------------
Vision time :  85.94124603271484
Action time :  105.9399642944336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.458112716674805
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  27.871231079101562
-------------------------------
-------------------------------
model running time:  10.490880012512207
-------------------------------
-------------------------------
model running time:  27.64179229736328
-------------------------------
Vision time :  85.92704010009766
Action time :  106.73065948486328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.486783981323242
-------------------------------
-------------------------------
model running time:  8.427519798278809
-------------------------------
-------------------------------
model running time:  27.787263870239258
-------------------------------
-------------------------------
model running time:  10.456159591674805
-------------------------------
-------------------------------
model running time:  27.69715118408203
-------------------------------
Vision time :  85.93360137939453
Action time :  106.5185317993164
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.34239959716797
-------------------------------
-------------------------------
model running time:  8.497152328491211
-------------------------------
-------------------------------
model running time:  27.844608306884766
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  27.638912200927734
-------------------------------
Vision time :  85.8757095336914
Action time :  106.47551727294922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.331167221069336
-------------------------------
-------------------------------
model running time:  8.452095985412598
-------------------------------
-------------------------------
model running time:  27.710464477539062
-------------------------------
-------------------------------
model running time:  16.734207153320312
-------------------------------
-------------------------------
model running time:  27.617279052734375
-------------------------------
Vision time :  85.89667510986328
Action time :  112.2713623046875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.11404800415039
-------------------------------
-------------------------------
model running time:  8.378368377685547
-------------------------------
-------------------------------
model running time:  27.66748809814453
-------------------------------
-------------------------------
model running time:  10.480640411376953
-------------------------------
-------------------------------
model running time:  27.694080352783203
-------------------------------
Vision time :  85.93305969238281
Action time :  105.07161712646484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.474496841430664
-------------------------------
-------------------------------
model running time:  8.41318416595459
-------------------------------
-------------------------------
model running time:  29.863935470581055
-------------------------------
-------------------------------
model running time:  10.51750373840332
-------------------------------
-------------------------------
model running time:  27.783327102661133
-------------------------------
Vision time :  85.90425872802734
Action time :  109.64393615722656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.555391311645508
-------------------------------
-------------------------------
model running time:  8.444928169250488
-------------------------------
-------------------------------
model running time:  27.726783752441406
-------------------------------
-------------------------------
model running time:  10.477567672729492
-------------------------------
-------------------------------
model running time:  27.584415435791016
-------------------------------
Vision time :  85.92451477050781
Action time :  106.19391632080078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.30348777770996
-------------------------------
-------------------------------
model running time:  8.41215991973877
-------------------------------
-------------------------------
model running time:  27.501567840576172
-------------------------------
-------------------------------
model running time:  10.447872161865234
-------------------------------
-------------------------------
model running time:  31.14905548095703
-------------------------------
Vision time :  85.90326690673828
Action time :  108.77439880371094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.11916732788086
-------------------------------
-------------------------------
model running time:  8.40499210357666
-------------------------------
-------------------------------
model running time:  31.02003288269043
-------------------------------
-------------------------------
model running time:  10.459136009216309
-------------------------------
-------------------------------
model running time:  27.546592712402344
-------------------------------
Vision time :  85.88297271728516
Action time :  109.16864013671875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.172607421875
-------------------------------
-------------------------------
model running time:  8.576000213623047
-------------------------------
-------------------------------
model running time:  27.736064910888672
-------------------------------
-------------------------------
model running time:  10.497023582458496
-------------------------------
-------------------------------
model running time:  27.620351791381836
-------------------------------
Vision time :  85.90531158447266
Action time :  111.00160217285156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.192895889282227
-------------------------------
-------------------------------
model running time:  8.49407958984375
-------------------------------
-------------------------------
model running time:  35.557376861572266
-------------------------------
-------------------------------
model running time:  10.456064224243164
-------------------------------
-------------------------------
model running time:  27.54867172241211
-------------------------------
Vision time :  85.94137573242188
Action time :  114.1585922241211
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952


 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:23<01:21,  4.55s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.352479934692383
-------------------------------
-------------------------------
model running time:  8.408160209655762
-------------------------------
-------------------------------
model running time:  27.5548152923584
-------------------------------
-------------------------------
model running time:  10.455039978027344
-------------------------------
-------------------------------
model running time:  27.445247650146484
-------------------------------
Vision time :  85.92729949951172
Action time :  105.35731506347656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.257408142089844
-------------------------------
-------------------------------
model running time:  8.42137622833252
-------------------------------
-------------------------------
model running time:  27.632640838623047
-------------------------------
-------------------------------
model running time:  17.063936233520508
-------------------------------
-------------------------------
model running time:  27.56608009338379
-------------------------------
Vision time :  85.89337921142578
Action time :  112.04402923583984
Trial 7 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.488832473754883
-------------------------------
-------------------------------
model running time:  8.469504356384277
-------------------------------
-------------------------------
model running time:  27.850751876831055
-------------------------------
-------------------------------
model running time:  10.605567932128906
-------------------------------
-------------------------------
model running time:  27.90108871459961
-------------------------------
Vision time :  85.90131378173828
Action time :  107.3878402709961
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.489856719970703
-------------------------------
-------------------------------
model running time:  8.483839988708496
-------------------------------
-------------------------------
model running time:  27.92959976196289
-------------------------------
-------------------------------
model running time:  10.498016357421875
-------------------------------
-------------------------------
model running time:  30.556255340576172
-------------------------------
Vision time :  85.93714904785156
Action time :  109.20047760009766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.472448348999023
-------------------------------
-------------------------------
model running time:  8.493120193481445
-------------------------------
-------------------------------
model running time:  27.836383819580078
-------------------------------
-------------------------------
model running time:  10.550271987915039
-------------------------------
-------------------------------
model running time:  27.672576904296875
-------------------------------
Vision time :  85.92726135253906
Action time :  106.08946990966797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.46214485168457
-------------------------------
-------------------------------
model running time:  8.4203519821167
-------------------------------
-------------------------------
model running time:  27.646976470947266
-------------------------------
-------------------------------
model running time:  10.490752220153809
-------------------------------
-------------------------------
model running time:  27.419679641723633
-------------------------------
Vision time :  85.8812484741211
Action time :  106.60147094726562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.275808334350586
-------------------------------
-------------------------------
model running time:  8.482815742492676
-------------------------------
-------------------------------
model running time:  27.78214454650879
-------------------------------
-------------------------------
model running time:  10.570752143859863
-------------------------------
-------------------------------
model running time:  27.642976760864258
-------------------------------
Vision time :  85.89801788330078
Action time :  105.75251007080078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.09561538696289
-------------------------------
-------------------------------
model running time:  8.472576141357422
-------------------------------
-------------------------------
model running time:  31.143936157226562
-------------------------------
-------------------------------
model running time:  10.537055969238281
-------------------------------
-------------------------------
model running time:  28.09040069580078
-------------------------------
Vision time :  85.89424133300781
Action time :  109.34579467773438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.937536239624023
-------------------------------
-------------------------------
model running time:  8.40499210357666
-------------------------------
-------------------------------
model running time:  27.700223922729492
-------------------------------
-------------------------------
model running time:  10.516480445861816
-------------------------------
-------------------------------
model running time:  27.51487922668457
-------------------------------
Vision time :  85.88674926757812
Action time :  110.87667083740234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.794719696044922
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  27.493375778198242
-------------------------------
-------------------------------
model running time:  10.485759735107422
-------------------------------
-------------------------------
model running time:  27.476896286010742
-------------------------------
Vision time :  85.83757019042969
Action time :  104.28620910644531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.872352600097656
-------------------------------
-------------------------------
model running time:  8.447999954223633
-------------------------------
-------------------------------
model running time:  34.063358306884766
-------------------------------
-------------------------------
model running time:  10.569727897644043
-------------------------------
-------------------------------
model running time:  27.676671981811523
-------------------------------
Vision time :  85.87260437011719
Action time :  111.33235168457031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92153549194336
-------------------------------
-------------------------------
model running time:  8.51968002319336
-------------------------------
-------------------------------
model running time:  27.727840423583984
-------------------------------
-------------------------------
model running time:  10.508288383483887
-------------------------------
-------------------------------
model running time:  27.52409553527832
-------------------------------
Vision time :  85.85747528076172
Action time :  104.90265655517578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.779199600219727
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  32.55500793457031
-------------------------------
-------------------------------
model running time:  10.520575523376465
-------------------------------
-------------------------------
model running time:  27.495424270629883
-------------------------------
Vision time :  85.92134094238281
Action time :  109.52909088134766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9368953704834
-------------------------------
-------------------------------
model running time:  11.131711959838867
-------------------------------
-------------------------------
model running time:  27.672544479370117
-------------------------------
-------------------------------
model running time:  10.445792198181152
-------------------------------
-------------------------------
model running time:  27.510784149169922
-------------------------------
Vision time :  85.89164733886719
Action time :  107.29369354248047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.840063095092773
-------------------------------
-------------------------------
model running time:  8.49407958984375
-------------------------------
-------------------------------
model running time:  27.55379295349121
-------------------------------
-------------------------------
model running time:  10.489855766296387
-------------------------------
-------------------------------
model running time:  27.632640838623047
-------------------------------
Vision time :  85.88307189941406
Action time :  105.63481903076172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.795711517333984
-------------------------------
-------------------------------
model running time:  8.648575782775879
-------------------------------
-------------------------------
model running time:  33.27180862426758
-------------------------------
-------------------------------
model running time:  10.596256256103516
-------------------------------
-------------------------------
model running time:  27.54857635498047
-------------------------------
Vision time :  85.89321899414062
Action time :  110.49164581298828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.80988883972168


 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:30<01:29,  5.26s/it][A[A-------------------------------
-------------------------------
model running time:  8.506367683410645
-------------------------------
-------------------------------
model running time:  27.852800369262695
-------------------------------
-------------------------------
model running time:  10.594304084777832
-------------------------------
-------------------------------
model running time:  27.678720474243164
-------------------------------
Vision time :  85.86457824707031
Action time :  106.09458923339844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.081279754638672
-------------------------------
-------------------------------
model running time:  16.620576858520508
-------------------------------
-------------------------------
model running time:  27.498624801635742
-------------------------------
-------------------------------
model running time:  10.463135719299316
-------------------------------
-------------------------------
model running time:  27.289600372314453
-------------------------------
Vision time :  85.90128326416016
Action time :  112.59075164794922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.764768600463867
-------------------------------
-------------------------------
model running time:  8.40499210357666
-------------------------------
-------------------------------
model running time:  27.401216506958008
-------------------------------
-------------------------------
model running time:  17.230911254882812
-------------------------------
-------------------------------
model running time:  27.374752044677734
-------------------------------
Vision time :  85.89625549316406
Action time :  110.87359619140625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.905088424682617
-------------------------------
-------------------------------
model running time:  8.49612808227539
-------------------------------
-------------------------------
model running time:  27.627519607543945
-------------------------------
-------------------------------
model running time:  10.477567672729492
-------------------------------
-------------------------------
model running time:  33.670143127441406
-------------------------------
Vision time :  85.92160034179688
Action time :  110.91865539550781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.95123291015625
-------------------------------
-------------------------------
model running time:  8.442879676818848
-------------------------------
-------------------------------
model running time:  27.586559295654297
-------------------------------
-------------------------------
model running time:  10.519519805908203
-------------------------------
-------------------------------
model running time:  27.469823837280273
-------------------------------
Vision time :  85.88655853271484
Action time :  104.67839813232422
Trial 8 finished, success: tensor([True]), steps: 295
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.014720916748047
-------------------------------
-------------------------------
model running time:  8.446975708007812
-------------------------------
-------------------------------
model running time:  29.043712615966797
-------------------------------
-------------------------------
model running time:  10.62604808807373
-------------------------------
-------------------------------
model running time:  32.16175842285156
-------------------------------
Vision time :  85.9110107421875
Action time :  113.3803482055664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.858047485351562
-------------------------------
-------------------------------
model running time:  8.563712120056152
-------------------------------
-------------------------------
model running time:  28.046335220336914
-------------------------------
-------------------------------
model running time:  10.529791831970215
-------------------------------
-------------------------------
model running time:  27.513856887817383
-------------------------------
Vision time :  85.90656280517578
Action time :  105.18016052246094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.93382453918457
-------------------------------
-------------------------------
model running time:  8.41113567352295
-------------------------------
-------------------------------
model running time:  27.55379295349121
-------------------------------
-------------------------------
model running time:  10.500096321105957
-------------------------------
-------------------------------
model running time:  34.12684631347656
-------------------------------
Vision time :  85.8719711303711
Action time :  111.14189147949219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.567039489746094
-------------------------------
-------------------------------
model running time:  8.454143524169922
-------------------------------
-------------------------------
model running time:  27.94905662536621
-------------------------------
-------------------------------
model running time:  10.470399856567383
-------------------------------
-------------------------------
model running time:  27.461599349975586
-------------------------------
Vision time :  85.88473510742188
Action time :  108.60851287841797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.09459114074707
-------------------------------
-------------------------------
model running time:  8.41420841217041
-------------------------------
-------------------------------
model running time:  27.4800968170166
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  27.421695709228516
-------------------------------
Vision time :  85.87974548339844
Action time :  104.46147155761719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.170368194580078
-------------------------------
-------------------------------
model running time:  8.423423767089844
-------------------------------
-------------------------------
model running time:  33.70399856567383
-------------------------------
-------------------------------
model running time:  10.504192352294922
-------------------------------
-------------------------------
model running time:  27.73401641845703
-------------------------------
Vision time :  85.89862060546875
Action time :  111.19817352294922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.011743545532227
-------------------------------
-------------------------------
model running time:  8.473600387573242
-------------------------------
-------------------------------
model running time:  30.18342399597168
-------------------------------
-------------------------------
model running time:  10.54310417175293
-------------------------------
-------------------------------
model running time:  27.662336349487305
-------------------------------
Vision time :  85.90675354003906
Action time :  107.7176284790039
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.046335220336914
-------------------------------
-------------------------------
model running time:  8.462335586547852
-------------------------------
-------------------------------
model running time:  27.853824615478516
-------------------------------
-------------------------------
model running time:  10.431488037109375
-------------------------------
-------------------------------
model running time:  32.44851303100586
-------------------------------
Vision time :  85.8851547241211
Action time :  109.94585418701172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.72889518737793
-------------------------------
-------------------------------
model running time:  8.416383743286133
-------------------------------
-------------------------------
model running time:  33.84211349487305
-------------------------------
-------------------------------
model running time:  10.492927551269531
-------------------------------
-------------------------------
model running time:  27.76678466796875
-------------------------------
Vision time :  85.87875366210938
Action time :  110.84393310546875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.201087951660156
-------------------------------
-------------------------------
model running time:  8.415231704711914
-------------------------------
-------------------------------
model running time:  28.677120208740234
-------------------------------
-------------------------------
model running time:  10.457088470458984
-------------------------------
-------------------------------
model running time:  27.528064727783203
-------------------------------
Vision time :  85.87382507324219
Action time :  105.96556854248047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.687040328979492
-------------------------------
-------------------------------
model running time:  8.415231704711914
-------------------------------
-------------------------------
model running time:  27.55583953857422
-------------------------------
-------------------------------
model running time:  10.476384162902832
-------------------------------
-------------------------------
model running time:  27.401216506958008
-------------------------------
Vision time :  85.90182495117188
Action time :  104.24320220947266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.998336791992188
-------------------------------
-------------------------------
model running time:  8.416255950927734
-------------------------------
-------------------------------
model running time:  27.621376037597656
-------------------------------
-------------------------------
model running time:  10.515456199645996
-------------------------------
-------------------------------
model running time:  27.422719955444336
-------------------------------
Vision time :  85.88054656982422
Action time :  104.66508483886719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.037248611450195
-------------------------------
-------------------------------
model running time:  8.356863975524902
-------------------------------
-------------------------------
model running time:  31.994783401489258
-------------------------------
-------------------------------
model running time:  10.430463790893555
-------------------------------
-------------------------------
model running time:  27.457504272460938
-------------------------------
Vision time :  85.89398193359375
Action time :  108.93824005126953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.992191314697266
-------------------------------
-------------------------------
model running time:  8.389632225036621
-------------------------------
-------------------------------
model running time:  27.577312469482422
-------------------------------
-------------------------------
model running time:  10.633055686950684
-------------------------------
-------------------------------
model running time:  28.94233512878418
-------------------------------
Vision time :  85.87696075439453
Action time :  106.281982421875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.19705581665039
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  27.86729621887207
-------------------------------
-------------------------------
model running time:  10.511360168457031
-------------------------------
-------------------------------
model running time:  27.686912536621094
-------------------------------
Vision time :  85.9552993774414
Action time :  112.70246124267578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.791488647460938
-------------------------------
-------------------------------
model running time:  8.40396785736084
-------------------------------
-------------------------------
model running time:  27.729759216308594
-------------------------------
-------------------------------
model running time:  10.471391677856445
-------------------------------
-------------------------------
model running time:  27.625471115112305
-------------------------------
Vision time :  85.85926055908203
Action time :  104.56678771972656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.49964714050293
-------------------------------
-------------------------------
model running time:  8.436863899230957
-------------------------------
-------------------------------
model running time:  27.665407180786133
-------------------------------
-------------------------------
model running time:  10.53286361694336
-------------------------------
-------------------------------
model running time:  27.632511138916016
-------------------------------
Vision time :  85.86627197265625
Action time :  104.22067260742188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.697280883789062
-------------------------------
-------------------------------
model running time:  8.343680381774902
-------------------------------
-------------------------------
model running time:  27.859968185424805
-------------------------------
-------------------------------
model running time:  10.501119613647461
-------------------------------
-------------------------------
model running time:  27.611072540283203
-------------------------------
Vision time :  85.87395477294922
Action time :  104.55244445800781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.423871994018555
-------------------------------
-------------------------------
model running time:  8.40499210357666
-------------------------------
-------------------------------
model running time:  27.617279052734375
-------------------------------
-------------------------------
model running time:  10.496031761169434
-------------------------------
-------------------------------
model running time:  27.682815551757812
-------------------------------
Vision time :  85.86665344238281
Action time :  104.3927001953125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.800703048706055
-------------------------------
-------------------------------
model running time:  8.455167770385742
-------------------------------
-------------------------------
model running time:  27.646976470947266
-------------------------------
-------------------------------
model running time:  10.478591918945312


 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:39<01:41,  6.36s/it][A[A-------------------------------
-------------------------------
model running time:  27.608064651489258
-------------------------------
Vision time :  85.8697280883789
Action time :  104.61788940429688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.031103134155273
-------------------------------
-------------------------------
model running time:  8.474623680114746
-------------------------------
-------------------------------
model running time:  27.84659194946289
-------------------------------
-------------------------------
model running time:  10.513504028320312
-------------------------------
-------------------------------
model running time:  27.651071548461914
-------------------------------
Vision time :  85.85321807861328
Action time :  105.169921875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.60095977783203
-------------------------------
-------------------------------
model running time:  8.383487701416016
-------------------------------
-------------------------------
model running time:  27.663360595703125
-------------------------------
-------------------------------
model running time:  10.460160255432129
-------------------------------
-------------------------------
model running time:  27.593727111816406
-------------------------------
Vision time :  85.88893127441406
Action time :  104.20121765136719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.624576568603516
-------------------------------
-------------------------------
model running time:  8.380415916442871
-------------------------------
-------------------------------
model running time:  27.611135482788086
-------------------------------
-------------------------------
model running time:  10.480640411376953
-------------------------------
-------------------------------
model running time:  27.589632034301758
-------------------------------
Vision time :  85.94624328613281
Action time :  104.31692504882812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.875455856323242
-------------------------------
-------------------------------
model running time:  8.433728218078613
-------------------------------
-------------------------------
model running time:  27.73811149597168
-------------------------------
-------------------------------
model running time:  10.49078369140625
-------------------------------
-------------------------------
model running time:  27.633663177490234
-------------------------------
Vision time :  85.89440155029297
Action time :  104.9702377319336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.705472946166992
-------------------------------
-------------------------------
model running time:  8.407008171081543
-------------------------------
-------------------------------
model running time:  27.826175689697266
-------------------------------
-------------------------------
model running time:  10.500096321105957
-------------------------------
-------------------------------
model running time:  27.874303817749023
-------------------------------
Vision time :  85.87289428710938
Action time :  104.89958190917969
Trial 9 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.024959564208984
-------------------------------
-------------------------------
model running time:  8.423328399658203
-------------------------------
-------------------------------
model running time:  27.84467124938965
-------------------------------
-------------------------------
model running time:  10.607711791992188
-------------------------------
-------------------------------
model running time:  27.75129508972168
-------------------------------
Vision time :  85.84857940673828
Action time :  105.23442840576172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.66457748413086
-------------------------------
-------------------------------
model running time:  8.48588752746582
-------------------------------
-------------------------------
model running time:  28.057695388793945
-------------------------------
-------------------------------
model running time:  10.562560081481934
-------------------------------
-------------------------------
model running time:  29.640703201293945
-------------------------------
Vision time :  85.86886596679688
Action time :  114.09919738769531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.803775787353516
-------------------------------
-------------------------------
model running time:  8.463520050048828
-------------------------------
-------------------------------
model running time:  27.868160247802734
-------------------------------
-------------------------------
model running time:  10.561535835266113
-------------------------------


 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:41<01:15,  5.04s/it][A[A-------------------------------
model running time:  27.827199935913086
-------------------------------
Vision time :  85.8662109375
Action time :  105.15763092041016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.783296585083008
-------------------------------
-------------------------------
model running time:  8.40294361114502
-------------------------------
-------------------------------
model running time:  27.71468734741211
-------------------------------
-------------------------------
model running time:  10.560511589050293
-------------------------------
-------------------------------
model running time:  27.670528411865234
-------------------------------
Vision time :  85.86243438720703
Action time :  104.627197265625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.623552322387695
-------------------------------
-------------------------------
model running time:  8.426495552062988
-------------------------------
-------------------------------
model running time:  27.678720474243164
-------------------------------
-------------------------------
model running time:  10.53593635559082
-------------------------------
-------------------------------
model running time:  27.711488723754883
-------------------------------
Vision time :  85.86640167236328
Action time :  104.50125122070312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.654207229614258
-------------------------------
-------------------------------
model running time:  8.39475154876709
-------------------------------
-------------------------------
model running time:  27.71251106262207
-------------------------------
-------------------------------
model running time:  10.522624015808105
-------------------------------
-------------------------------
model running time:  27.609088897705078
-------------------------------
Vision time :  85.82450866699219
Action time :  104.49305725097656
Trial 10 finished, success: tensor([True]), steps: 85
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.817087173461914
-------------------------------
-------------------------------
model running time:  8.484864234924316
-------------------------------
-------------------------------
model running time:  27.805696487426758
-------------------------------
-------------------------------
model running time:  10.535967826843262
-------------------------------
-------------------------------
model running time:  27.71558380126953
-------------------------------
Vision time :  85.85222625732422
Action time :  104.86886596679688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.605119705200195
-------------------------------
-------------------------------
model running time:  8.457216262817383
-------------------------------
-------------------------------
model running time:  27.867136001586914
-------------------------------
-------------------------------
model running time:  10.531840324401855
-------------------------------
-------------------------------
model running time:  27.675647735595703
-------------------------------
Vision time :  85.84288024902344
Action time :  104.60364532470703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.1079044342041
-------------------------------
-------------------------------
model running time:  8.456192016601562
-------------------------------
-------------------------------
model running time:  27.76678466796875
-------------------------------
-------------------------------
model running time:  10.493951797485352
-------------------------------
-------------------------------
model running time:  27.642879486083984
-------------------------------
Vision time :  85.91718292236328
Action time :  105.10643005371094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.839616775512695
-------------------------------
-------------------------------
model running time:  8.514559745788574
-------------------------------
-------------------------------
model running time:  27.75142478942871
-------------------------------
-------------------------------
model running time:  10.507264137268066
-------------------------------
-------------------------------
model running time:  27.595775604248047
-------------------------------
Vision time :  85.8780517578125
Action time :  104.72857666015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.753536224365234
-------------------------------
-------------------------------
model running time:  8.42137622833252
-------------------------------
-------------------------------
model running time:  27.724672317504883
-------------------------------
-------------------------------
model running time:  10.502143859863281
-------------------------------
-------------------------------
model running time:  

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:44<01:02,  4.47s/it][A[A27.57427215576172
-------------------------------
Vision time :  85.87651062011719
Action time :  104.52169799804688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.71059226989746
-------------------------------
-------------------------------
model running time:  8.389632225036621
-------------------------------
-------------------------------
model running time:  27.678720474243164
-------------------------------
-------------------------------
model running time:  10.44480037689209
-------------------------------
-------------------------------
model running time:  27.666431427001953
-------------------------------
Vision time :  85.85926055908203
Action time :  104.34662628173828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.70035171508789
-------------------------------
-------------------------------
model running time:  8.40499210357666
-------------------------------
-------------------------------
model running time:  27.622400283813477
-------------------------------
-------------------------------
model running time:  10.554368019104004
-------------------------------
-------------------------------
model running time:  27.55686378479004
-------------------------------
Vision time :  85.83638763427734
Action time :  104.3763198852539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.738239288330078
-------------------------------
-------------------------------
model running time:  8.410112380981445
-------------------------------
-------------------------------
model running time:  27.625471115112305
-------------------------------
-------------------------------
model running time:  10.530655860900879
-------------------------------
-------------------------------
model running time:  27.473920822143555
-------------------------------
Vision time :  85.93360137939453
Action time :  104.37312316894531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.149887084960938
-------------------------------
-------------------------------
model running time:  8.365056037902832
-------------------------------
-------------------------------
model running time:  32.50175857543945
-------------------------------
-------------------------------
model running time:  10.522720336914062
-------------------------------
-------------------------------
model running time:  27.64089584350586
-------------------------------
Vision time :  85.8677749633789
Action time :  109.6846694946289
Trial 11 finished, success: tensor([True]), steps: 137
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.76793670654297
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  27.91321563720703
-------------------------------
-------------------------------
model running time:  10.541055679321289
-------------------------------
-------------------------------
model running time:  27.501567840576172
-------------------------------
Vision time :  85.88716888427734
Action time :  104.7357406616211
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.853952407836914
-------------------------------
-------------------------------
model running time:  8.355711936950684
-------------------------------
-------------------------------
model running time:  27.53638458251953
-------------------------------
-------------------------------
model running time:  10.457088470458984
-------------------------------
-------------------------------
model running time:  27.503616333007812
-------------------------------
Vision time :  85.87964630126953
Action time :  104.35469055175781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.541536331176758
-------------------------------
-------------------------------
model running time:  8.40601634979248
-------------------------------
-------------------------------
model running time:  27.757728576660156
-------------------------------
-------------------------------
model running time:  10.50931167602539
-------------------------------
-------------------------------
model running time:  27.54764747619629
-------------------------------
Vision time :  85.8818588256836
Action time :  104.8156509399414
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.070880889892578
-------------------------------
-------------------------------
model running time:  8.481792449951172
-------------------------------
-------------------------------
model running time:  27.906047821044922
-------------------------------
-------------------------------
model running time:  10.571776390075684
-------------------------------
-------------------------------
model running time:  28.474367141723633
-------------------------------


 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:46<00:47,  3.65s/it][A[AVision time :  85.8716812133789
Action time :  106.96806335449219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.622528076171875
-------------------------------
-------------------------------
model running time:  8.401920318603516
-------------------------------
-------------------------------
model running time:  27.766847610473633
-------------------------------
-------------------------------
model running time:  10.546048164367676
-------------------------------
-------------------------------
model running time:  27.77292823791504
-------------------------------
Vision time :  85.88428497314453
Action time :  105.26412963867188
Trial 12 finished, success: tensor([True]), steps: 78
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.858015060424805
-------------------------------
-------------------------------
model running time:  8.449024200439453
-------------------------------
-------------------------------
model running time:  27.96339225769043
-------------------------------
-------------------------------
model running time:  10.676287651062012
-------------------------------
-------------------------------
model running time:  27.702272415161133
-------------------------------
Vision time :  85.87612915039062
Action time :  105.62355041503906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9737606048584
-------------------------------
-------------------------------
model running time:  8.488960266113281
-------------------------------
-------------------------------
model running time:  27.77712059020996
-------------------------------
-------------------------------
model running time:  10.53593635559082
-------------------------------
-------------------------------
model running time:  27.651071548461914
-------------------------------
Vision time :  85.91024017333984
Action time :  105.1382064819336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.851903915405273
-------------------------------
-------------------------------
model running time:  8.432640075683594
-------------------------------
-------------------------------
model running time:  27.795488357543945
-------------------------------
-------------------------------
model running time:  10.560511589050293
-------------------------------
-------------------------------
model running time:  27.78112030029297
-------------------------------
Vision time :  85.90160369873047
Action time :  104.95795440673828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.756671905517578
-------------------------------
-------------------------------
model running time:  8.423423767089844
-------------------------------
-------------------------------
model running time:  27.572223663330078
-------------------------------
-------------------------------
model running time:  10.603520393371582
-------------------------------
-------------------------------
model running time:  27.53945541381836
-------------------------------
Vision time :  85.85977935791016
Action time :  104.40704345703125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.93529510498047
-------------------------------
-------------------------------
model running time:  8.51968002319336
-------------------------------
-------------------------------
model running time:  27.89289665222168
-------------------------------
-------------------------------
model running time:  10.566656112670898
-------------------------------
-------------------------------
model running time:  32.696319580078125
-------------------------------
Vision time :  85.96797180175781
Action time :  111.36819458007812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.36390495300293
-------------------------------
-------------------------------
model running time:  8.464384078979492
-------------------------------
-------------------------------
model running time:  27.845632553100586
-------------------------------
-------------------------------
model running time:  10.492927551269531
-------------------------------
-------------------------------
model running time:  27.610111236572266
-------------------------------
Vision time :  85.9031982421875
Action time :  106.44889831542969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.3536319732666
-------------------------------
-------------------------------
model running time:  8.48588752746582
-------------------------------
-------------------------------
model running time:  27.9418888092041
-------------------------------
-------------------------------
model running time:  10.539008140563965
-------------------------------
-------------------------------
model running time:  27.794431686401367
-------------------------------
Vision time :  85.93180847167969
Action time :  

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:49<00:40,  3.41s/it][A[A106.76223754882812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.72083282470703
-------------------------------
-------------------------------
model running time:  8.447999954223633
-------------------------------
-------------------------------
model running time:  27.748416900634766
-------------------------------
-------------------------------
model running time:  14.67084789276123
-------------------------------
-------------------------------
model running time:  27.751392364501953
-------------------------------
Vision time :  85.9211196899414
Action time :  110.65241241455078
Trial 13 finished, success: tensor([True]), steps: 125
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.635263442993164
-------------------------------
-------------------------------
model running time:  8.424448013305664
-------------------------------
-------------------------------
model running time:  27.830272674560547
-------------------------------
-------------------------------
model running time:  10.537983894348145
-------------------------------
-------------------------------
model running time:  27.803647994995117
-------------------------------
Vision time :  85.87763214111328
Action time :  105.87648010253906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.7392635345459
-------------------------------
-------------------------------
model running time:  8.44707202911377
-------------------------------
-------------------------------
model running time:  27.696128845214844
-------------------------------
-------------------------------
model running time:  10.597375869750977
-------------------------------
-------------------------------
model running time:  27.66035270690918
-------------------------------
Vision time :  85.86758422851562
Action time :  104.60671997070312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.444799423217773
-------------------------------
-------------------------------
model running time:  8.41318416595459
-------------------------------
-------------------------------
model running time:  27.72377586364746
-------------------------------
-------------------------------
model running time:  10.499072074890137
-------------------------------
-------------------------------
model running time:  27.55583953857422
-------------------------------
Vision time :  85.91734313964844
Action time :  107.34899139404297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.10380744934082
-------------------------------
-------------------------------
model running time:  8.473535537719727
-------------------------------
-------------------------------
model running time:  31.38150405883789
-------------------------------
-------------------------------
model running time:  10.504192352294922
-------------------------------
-------------------------------
model running time:  27.456512451171875
-------------------------------
Vision time :  85.93244934082031
Action time :  109.19833374023438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.84480094909668
-------------------------------
-------------------------------
model running time:  8.399904251098633
-------------------------------
-------------------------------
model running time:  27.53433609008789
-------------------------------
-------------------------------
model running time:  10.515328407287598
-------------------------------
-------------------------------
model running time:  27.444223403930664
-------------------------------
Vision time :  85.90038299560547
Action time :  105.84883117675781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.783296585083008
-------------------------------
-------------------------------
model running time:  8.416255950927734
-------------------------------
-------------------------------
model running time:  27.522048950195312
-------------------------------
-------------------------------
model running time:  10.439680099487305
-------------------------------
-------------------------------
model running time:  27.54252815246582
-------------------------------
Vision time :  85.8861083984375
Action time :  105.6337890625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.656768798828125
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  28.067840576171875
-------------------------------
-------------------------------
model running time:  10.5032320022583
-------------------------------
-------------------------------
model running time:  32.85504150390625
-------------------------------
Vision time :  85.95008087158203
Action time :  112.49152374267578


 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:51<00:34,  3.12s/it][A[A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:53<00:28,  2.84s/it][A[ATrial 14 finished, success: tensor([True]), steps: 112
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.482624053955078
-------------------------------
-------------------------------
model running time:  8.481792449951172
-------------------------------
-------------------------------
model running time:  27.825151443481445
-------------------------------
-------------------------------
model running time:  10.585087776184082
-------------------------------
-------------------------------
model running time:  27.73504066467285
-------------------------------
Vision time :  85.9037094116211
Action time :  106.48371124267578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.51136016845703
-------------------------------
-------------------------------
model running time:  8.491968154907227
-------------------------------
-------------------------------
model running time:  28.154752731323242
-------------------------------
-------------------------------
model running time:  10.458111763000488
-------------------------------
-------------------------------
model running time:  27.69817543029785
-------------------------------
Vision time :  85.93315124511719
Action time :  107.52716827392578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.22211265563965
-------------------------------
-------------------------------
model running time:  8.493056297302246
-------------------------------
-------------------------------
model running time:  27.983871459960938
-------------------------------
-------------------------------
model running time:  10.504192352294922
-------------------------------
-------------------------------
model running time:  27.764671325683594
-------------------------------
Vision time :  85.98438262939453
Action time :  107.18208312988281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.514432907104492
-------------------------------
-------------------------------
model running time:  8.480768203735352
-------------------------------
-------------------------------
model running time:  27.866111755371094
-------------------------------
-------------------------------
model running time:  10.601311683654785
-------------------------------
-------------------------------
model running time:  27.758655548095703
-------------------------------
Vision time :  85.90972900390625
Action time :  106.08844757080078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.389503479003906
-------------------------------
-------------------------------
model running time:  8.467455863952637
-------------------------------
-------------------------------
model running time:  27.69715118408203
-------------------------------
-------------------------------
model running time:  10.554368019104004
-------------------------------
-------------------------------
model running time:  27.666431427001953
-------------------------------
Vision time :  85.9315185546875
Action time :  105.57132720947266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.488895416259766
-------------------------------
-------------------------------
model running time:  8.596480369567871
-------------------------------
-------------------------------
model running time:  28.104703903198242
-------------------------------
-------------------------------
model running time:  10.617952346801758
-------------------------------
-------------------------------
model running time:  36.29056167602539
-------------------------------
Vision time :  85.92969512939453
Action time :  122.21644592285156
Trial 15 finished, success: tensor([True]), steps: 92
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.5533447265625
-------------------------------
-------------------------------
model running time:  8.43779182434082
-------------------------------
-------------------------------
model running time:  27.896831512451172
-------------------------------
-------------------------------
model running time:  10.50812816619873
-------------------------------
-------------------------------
model running time:  27.76473617553711
-------------------------------
Vision time :  85.91490936279297
Action time :  106.04541015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.448896408081055
-------------------------------
-------------------------------
model running time:  8.428383827209473
-------------------------------
-------------------------------
model running time:  27.971424102783203
-------------------------------
-------------------------------
model running time:  10.524831771850586
-------------------------------
-------------------------------
model running time:  27.743135452270508
-------------------------------
Vision time :  85.9202880859375
Action time :  105.95315551757812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.833791732788086
-------------------------------
-------------------------------
model running time:  8.477696418762207
-------------------------------
-------------------------------
model running time:  27.896831512451172
-------------------------------
-------------------------------
model running time:  10.497088432312012
-------------------------------
-------------------------------
model running time:  27.74425506591797
-------------------------------
Vision time :  85.92816162109375
Action time :  108.39958190917969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.346656799316406
-------------------------------
-------------------------------
model running time:  8.434687614440918
-------------------------------
-------------------------------
model running time:  27.651264190673828
-------------------------------
-------------------------------
model running time:  10.472448348999023
-------------------------------
-------------------------------
model running time:  27.634624481201172
-------------------------------
Vision time :  85.91852569580078
Action time :  105.43718719482422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.534912109375
-------------------------------
-------------------------------
model running time:  8.457088470458984
-------------------------------
-------------------------------
model running time:  30.127103805541992
-------------------------------
-------------------------------
model running time:  10.567680358886719
-------------------------------
-------------------------------
model running time:  27.423744201660156
-------------------------------
Vision time :  86.01074981689453
Action time :  108.13247680664062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.95372772216797
-------------------------------
-------------------------------
model running time:  8.433664321899414
-------------------------------
-------------------------------
model running time:  27.446176528930664
-------------------------------
-------------------------------
model running time:  10.512384414672852
-------------------------------
-------------------------------
model running time:  27.34182357788086
-------------------------------
Vision time :  85.91506958007812
Action time :  105.48121643066406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.953472137451172
-------------------------------
-------------------------------
model running time:  8.439807891845703
-------------------------------
-------------------------------
model running time:  27.633663177490234
-------------------------------
-------------------------------
model running time:  10.461183547973633
-------------------------------
-------------------------------
model running time:  27.418624877929688
-------------------------------
Vision time :  85.92585754394531
Action time :  110.06566619873047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.074111938476562
-------------------------------
-------------------------------
model running time:  8.384511947631836
-------------------------------
-------------------------------
model running time:  27.490304946899414
-------------------------------
-------------------------------
model running time:  10.459136009216309
-------------------------------
-------------------------------
model running time:  29.250560760498047
-------------------------------
Vision time :  85.90934753417969
Action time :  107.24658966064453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.020864486694336
-------------------------------
-------------------------------
model running time:  8.480863571166992
-------------------------------
-------------------------------
model running time:  27.599872589111328
-------------------------------
-------------------------------
model running time:  10.540032386779785
-------------------------------
-------------------------------
model running time:  27.460607528686523
-------------------------------
Vision time :  85.8700180053711
Action time :  105.70137786865234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.574848175048828
-------------------------------
-------------------------------
model running time:  8.468480110168457
-------------------------------
-------------------------------
model running time:  27.72889518737793
-------------------------------
-------------------------------
model running time:  10.53388786315918
-------------------------------
-------------------------------
model running time:  27.57427215576172
-------------------------------
Vision time :  85.92594909667969
Action time :  106.01074981689453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.961471557617188
-------------------------------
-------------------------------
model running time:  8.400832176208496
-------------------------------
-------------------------------
model running time:  27.509855270385742
-------------------------------
-------------------------------
model running time:  10.493056297302246
-------------------------------
-------------------------------
model running time:  27.524160385131836
-------------------------------
Vision time :  85.87542724609375
Action time :  105.48633575439453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.575040817260742
-------------------------------
-------------------------------
model running time:  8.444031715393066
-------------------------------
-------------------------------
model running time:  27.894847869873047
-------------------------------
-------------------------------
model running time:  10.540032386779785
-------------------------------
-------------------------------
model running time:  27.57427215576172
-------------------------------
Vision time :  85.8855972290039
Action time :  112.03382110595703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.31372833251953
-------------------------------
-------------------------------
model running time:  8.439807891845703
-------------------------------
-------------------------------
model running time:  32.19670486450195
-------------------------------
-------------------------------
model running time:  10.483712196350098
-------------------------------
-------------------------------
model running time:  27.659263610839844
-------------------------------
Vision time :  85.92054748535156
Action time :  110.57142639160156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.597503662109375
-------------------------------
-------------------------------
model running time:  8.521727561950684
-------------------------------
-------------------------------
model running time:  27.886592864990234
-------------------------------
-------------------------------
model running time:  10.502143859863281
-------------------------------
-------------------------------
model running time:  27.659263610839844
-------------------------------
Vision time :  85.90758514404297
Action time :  106.85740661621094
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.159103393554688
-------------------------------
-------------------------------
model running time:  8.452095985412598
-------------------------------
-------------------------------
model running time:  27.73811149597168
-------------------------------
-------------------------------
model running time:  10.488927841186523
-------------------------------
-------------------------------
model running time:  27.58451271057129
-------------------------------
Vision time :  85.90275573730469
Action time :  105.86112213134766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.52364730834961
-------------------------------
-------------------------------
model running time:  8.475647926330566
-------------------------------
-------------------------------
model running time:  27.828224182128906
-------------------------------
-------------------------------
model running time:  10.567680358886719
-------------------------------
-------------------------------
model running time:  27.893760681152344
-------------------------------
Vision time :  85.934814453125
Action time :  106.58099365234375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.22559928894043
-------------------------------
-------------------------------
model running time:  9.774080276489258
-------------------------------
-------------------------------
model running time:  27.613183975219727
-------------------------------
-------------------------------
model running time:  10.468352317810059
-------------------------------
-------------------------------
model running time:  27.71660804748535
-------------------------------
Vision time :  85.91334533691406
Action time :  107.40930938720703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.13043212890625
-------------------------------
-------------------------------
model running time:  8.40294361114502
-------------------------------
-------------------------------
model running time:  27.795455932617188
-------------------------------
-------------------------------
model running time:  10.496000289916992
-------------------------------
-------------------------------
model running time:  27.41641616821289
-------------------------------
Vision time :  85.87506866455078
Action time :  105.97990417480469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 


 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [01:02<00:42,  4.71s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.385663986206055
-------------------------------
-------------------------------
model running time:  8.488960266113281
-------------------------------
-------------------------------
model running time:  27.897855758666992
-------------------------------
-------------------------------
model running time:  10.529791831970215
-------------------------------
-------------------------------
model running time:  27.71558380126953
-------------------------------
Vision time :  85.90882873535156
Action time :  110.32575988769531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.879743576049805
-------------------------------
-------------------------------
model running time:  8.497152328491211
-------------------------------
-------------------------------
model running time:  27.912256240844727
-------------------------------
-------------------------------
model running time:  10.52569580078125
-------------------------------
-------------------------------
model running time:  27.70534324645996
-------------------------------
Vision time :  85.89708709716797
Action time :  110.87158203125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.979904174804688
-------------------------------
-------------------------------
model running time:  8.415136337280273
-------------------------------
-------------------------------
model running time:  27.811840057373047
-------------------------------
-------------------------------
model running time:  10.461183547973633
-------------------------------
-------------------------------
model running time:  27.53536033630371
-------------------------------
Vision time :  85.88829040527344
Action time :  105.35833740234375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.052671432495117
-------------------------------
-------------------------------
model running time:  8.475711822509766
-------------------------------
-------------------------------
model running time:  27.673471450805664
-------------------------------
-------------------------------
model running time:  10.501119613647461
-------------------------------
-------------------------------
model running time:  32.38092803955078
-------------------------------
Vision time :  85.90850830078125
Action time :  109.97248077392578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.149887084960938
-------------------------------
-------------------------------
model running time:  8.497152328491211
-------------------------------
-------------------------------
model running time:  27.661376953125
-------------------------------
-------------------------------
model running time:  10.489727973937988
-------------------------------
-------------------------------
model running time:  40.6220817565918
-------------------------------
Vision time :  85.9286117553711
Action time :  119.03692626953125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.636703491210938
-------------------------------
-------------------------------
model running time:  8.41318416595459
-------------------------------
-------------------------------
model running time:  29.239360809326172
-------------------------------
-------------------------------
model running time:  10.483712196350098
-------------------------------
-------------------------------
model running time:  27.53228759765625
-------------------------------
Vision time :  85.85689544677734
Action time :  107.20358276367188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.039295196533203
-------------------------------
-------------------------------
model running time:  8.442912101745605
-------------------------------
-------------------------------
model running time:  27.73708724975586
-------------------------------
-------------------------------
model running time:  10.449919700622559
-------------------------------
-------------------------------
model running time:  27.97875213623047
-------------------------------
Vision time :  85.87500762939453
Action time :  105.66860961914062
Trial 16 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.502464294433594
-------------------------------
-------------------------------
model running time:  8.475647926330566
-------------------------------
-------------------------------
model running time:  27.78112030029297
-------------------------------
-------------------------------
model running time:  10.600447654724121
-------------------------------
-------------------------------
model running time:  35.35366439819336
-------------------------------
Vision time :  85.84281921386719
Action time :  116.91315460205078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [01:05<00:33,  4.17s/it][A[A
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.13145637512207
-------------------------------
-------------------------------
model running time:  8.464384078979492
-------------------------------
-------------------------------
model running time:  27.984895706176758
-------------------------------
-------------------------------
model running time:  10.508383750915527
-------------------------------
-------------------------------
model running time:  28.329952239990234
-------------------------------
Vision time :  85.88006591796875
Action time :  107.1124496459961
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.2093448638916
-------------------------------
-------------------------------
model running time:  8.48588752746582
-------------------------------
-------------------------------
model running time:  28.076032638549805
-------------------------------
-------------------------------
model running time:  14.99238395690918
-------------------------------
-------------------------------
model running time:  27.872255325317383
-------------------------------
Vision time :  85.88304138183594
Action time :  111.25772857666016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.198015213012695
-------------------------------
-------------------------------
model running time:  8.482848167419434
-------------------------------
-------------------------------
model running time:  27.7073917388916
-------------------------------
-------------------------------
model running time:  10.485759735107422
-------------------------------
-------------------------------
model running time:  33.18374252319336
-------------------------------
Vision time :  85.91840362548828
Action time :  111.7286376953125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.334400177001953
-------------------------------
-------------------------------
model running time:  8.437760353088379
-------------------------------
-------------------------------
model running time:  27.571199417114258
-------------------------------
-------------------------------
model running time:  10.480640411376953
-------------------------------
-------------------------------
model running time:  27.2989444732666
-------------------------------
Vision time :  85.89904022216797
Action time :  108.34124755859375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.85036849975586
-------------------------------
-------------------------------
model running time:  8.475647926330566
-------------------------------
-------------------------------
model running time:  29.023231506347656
-------------------------------
-------------------------------
model running time:  10.494976043701172
-------------------------------
-------------------------------
model running time:  27.454463958740234
-------------------------------
Vision time :  85.88265228271484
Action time :  115.06585693359375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.688383102416992
-------------------------------
-------------------------------
model running time:  8.443903923034668
-------------------------------
-------------------------------
model running time:  27.736032485961914
-------------------------------
-------------------------------
model running time:  10.462207794189453
-------------------------------
-------------------------------
model running time:  27.60393524169922
-------------------------------
Vision time :  85.8647689819336
Action time :  108.20706939697266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.063871383666992
-------------------------------
-------------------------------
model running time:  8.465408325195312
-------------------------------
-------------------------------
model running time:  27.671424865722656
-------------------------------
-------------------------------
model running time:  10.513407707214355
-------------------------------
-------------------------------
model running time:  34.753536224365234
-------------------------------
Vision time :  85.87939453125
Action time :  112.85721588134766
Trial 17 finished, success: tensor([True]), steps: 127
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.755647659301758
-------------------------------
-------------------------------
model running time:  8.390656471252441
-------------------------------
-------------------------------
model running time:  27.74527931213379
-------------------------------
-------------------------------
model running time:  10.479616165161133
-------------------------------
-------------------------------
model running time:  32.33894348144531
-------------------------------
Vision time :  85.87999725341797
Action time :  109.3355484008789
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.88057518005371
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  27.845632553100586
-------------------------------
-------------------------------
model running time:  10.429535865783691
-------------------------------
-------------------------------
model running time:  27.421567916870117
-------------------------------
Vision time :  85.87554931640625
Action time :  104.84121704101562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.56787109375
-------------------------------
-------------------------------
model running time:  8.49612808227539
-------------------------------
-------------------------------
model running time:  27.92140769958496
-------------------------------
-------------------------------
model running time:  10.507264137268066
-------------------------------
-------------------------------
model running time:  27.55174446105957
-------------------------------
Vision time :  85.89071655273438
Action time :  110.70755004882812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.93382453918457
-------------------------------
-------------------------------
model running time:  8.506367683410645
-------------------------------
-------------------------------
model running time:  27.617279052734375
-------------------------------
-------------------------------
model running time:  10.455039978027344
-------------------------------
-------------------------------
model running time:  27.429792404174805
-------------------------------
Vision time :  85.85638427734375
Action time :  104.68659210205078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.715776443481445
-------------------------------
-------------------------------
model running time:  8.385536193847656
-------------------------------
-------------------------------
model running time:  27.50054359436035
-------------------------------
-------------------------------
model running time:  10.41708755493164
-------------------------------
-------------------------------
model running time:  29.816831588745117
-------------------------------
Vision time :  85.92073822021484
Action time :  106.54003143310547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.940832138061523
-------------------------------
-------------------------------
model running time:  8.415231704711914
-------------------------------
-------------------------------
model running time:  27.678720474243164
-------------------------------
-------------------------------
model running time:  10.555392265319824
-------------------------------
-------------------------------
model running time:  31.492095947265625
-------------------------------
Vision time :  85.86576080322266
Action time :  108.76319885253906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.816064834594727
-------------------------------
-------------------------------
model running time:  8.354816436767578
-------------------------------
-------------------------------
model running time:  27.53116798400879
-------------------------------
-------------------------------
model running time:  10.496000289916992
-------------------------------
-------------------------------
model running time:  33.79916763305664
-------------------------------
Vision time :  85.88944244384766
Action time :  110.64524841308594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.95123291015625
-------------------------------
-------------------------------
model running time:  8.408063888549805
-------------------------------
-------------------------------
model running time:  27.540319442749023
-------------------------------
-------------------------------
model running time:  10.541055679321289
-------------------------------
-------------------------------
model running time:  27.345823287963867
-------------------------------
Vision time :  85.89807891845703
Action time :  104.47154998779297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.600000381469727
-------------------------------
-------------------------------
model running time:  8.417152404785156
-------------------------------
-------------------------------
model running time:  34.480159759521484
-------------------------------
-------------------------------
model running time:  10.449824333190918
-------------------------------
-------------------------------
model running time:  27.412479400634766
-------------------------------
Vision time :  85.8721923828125
Action time :  110.94124603271484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.93075180053711
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  27.570016860961914
-------------------------------
-------------------------------
model running time:  10.44495964050293
-------------------------------
-------------------------------
model running time:  27.3756160736084
-------------------------------
Vision time :  85.86307525634766
Action time :  104.87398529052734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.785856246948242
-------------------------------
-------------------------------
model running time:  8.478719711303711
-------------------------------
-------------------------------
model running time:  27.96134376525879
-------------------------------
-------------------------------
model running time:  20.04172706604004
-------------------------------
-------------------------------
model running time:  27.800575256347656
-------------------------------
Vision time :  85.9645767211914
Action time :  116.07039642333984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.170495986938477
-------------------------------
-------------------------------
model running time:  8.497152328491211
-------------------------------
-------------------------------
model running time:  27.85296058654785
-------------------------------
-------------------------------
model running time:  10.546175956726074
-------------------------------
-------------------------------
model running time:  27.919200897216797
-------------------------------
Vision time :  85.86803436279297
Action time :  110.71488189697266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.063711166381836
-------------------------------
-------------------------------
model running time:  8.501248359680176
-------------------------------
-------------------------------
model running time:  27.864160537719727
-------------------------------
-------------------------------
model running time:  10.53593635559082
-------------------------------
-------------------------------
model running time:  27.653120040893555
-------------------------------
Vision time :  85.91136169433594
Action time :  106.19699096679688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.989120483398438
-------------------------------
-------------------------------
model running time:  12.114944458007812
-------------------------------
-------------------------------
model running time:  27.881471633911133
-------------------------------
-------------------------------
model running time:  10.498047828674316
-------------------------------
-------------------------------
model running time:  27.703296661376953
-------------------------------
Vision time :  86.84480285644531
Action time :  109.44515228271484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.829376220703125
-------------------------------
-------------------------------
model running time:  8.440832138061523
-------------------------------
-------------------------------
model running time:  27.891679763793945
-------------------------------
-------------------------------
model running time:  10.534912109375
-------------------------------
-------------------------------
model running time:  32.163841247558594
-------------------------------
Vision time :  85.8868179321289
Action time :  110.10546875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.091583251953125
-------------------------------
-------------------------------
model running time:  8.498016357421875
-------------------------------
-------------------------------
model running time:  27.804672241210938
-------------------------------
-------------------------------
model running time:  10.492927551269531
-------------------------------
-------------------------------
model running time:  27.485183715820312
-------------------------------
Vision time :  85.88553619384766
Action time :  105.27948760986328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.628799438476562
-------------------------------
-------------------------------
model running time:  8.390656471252441
-------------------------------
-------------------------------
model running time:  35.354591369628906
-------------------------------
-------------------------------
model running time:  10.467328071594238
-------------------------------
-------------------------------
model running time:  27.469728469848633
-------------------------------
Vision time :  85.89635467529297
Action time :  112.4853744506836
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.403839111328125
-------------------------------
-------------------------------


 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [01:14<00:39,  5.65s/it][A[Amodel running time:  8.453120231628418
-------------------------------
-------------------------------
model running time:  27.644927978515625
-------------------------------
-------------------------------
model running time:  10.472448348999023
-------------------------------
-------------------------------
model running time:  27.444223403930664
-------------------------------
Vision time :  85.86287689208984
Action time :  105.96761322021484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9102725982666
-------------------------------
-------------------------------
model running time:  8.465408325195312
-------------------------------
-------------------------------
model running time:  34.30195236206055
-------------------------------
-------------------------------
model running time:  10.520575523376465
-------------------------------
-------------------------------
model running time:  27.710464477539062
-------------------------------
Vision time :  85.91702270507812
Action time :  112.1495361328125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.067968368530273
-------------------------------
-------------------------------
model running time:  8.451071739196777
-------------------------------
-------------------------------
model running time:  27.73708724975586
-------------------------------
-------------------------------
model running time:  10.461248397827148
-------------------------------
-------------------------------
model running time:  27.598848342895508
-------------------------------
Vision time :  85.89334106445312
Action time :  105.76588439941406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.070016860961914
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  27.78009605407715
-------------------------------
-------------------------------
model running time:  10.55129623413086
-------------------------------
-------------------------------
model running time:  32.60723114013672
-------------------------------
Vision time :  85.91776275634766
Action time :  110.71794891357422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.79315185546875
-------------------------------
-------------------------------
model running time:  8.483839988708496
-------------------------------
-------------------------------
model running time:  27.975807189941406
-------------------------------
-------------------------------
model running time:  10.531840324401855
-------------------------------
-------------------------------
model running time:  27.85603141784668
-------------------------------
Vision time :  85.88137817382812
Action time :  111.82796478271484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.535615921020508
-------------------------------
-------------------------------
model running time:  8.487808227539062
-------------------------------
-------------------------------
model running time:  27.9234561920166
-------------------------------
-------------------------------
model running time:  10.561568260192871
-------------------------------
-------------------------------
model running time:  27.75961685180664
-------------------------------
Vision time :  85.8602523803711
Action time :  109.8977279663086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.76896095275879
-------------------------------
-------------------------------
model running time:  8.431615829467773
-------------------------------
-------------------------------
model running time:  27.667455673217773
-------------------------------
-------------------------------
model running time:  10.485759735107422
-------------------------------
-------------------------------
model running time:  27.602943420410156
-------------------------------
Vision time :  85.87696075439453
Action time :  104.58521270751953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.88876724243164
-------------------------------
-------------------------------
model running time:  8.4901123046875
-------------------------------
-------------------------------
model running time:  32.803680419921875
-------------------------------
-------------------------------
model running time:  10.472288131713867
-------------------------------
-------------------------------
model running time:  27.611135482788086
-------------------------------
Vision time :  85.86396789550781
Action time :  110.58796691894531
Trial 18 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.94611167907715
-------------------------------
-------------------------------
model running time:  8.42137622833252


 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [01:16<00:27,  4.57s/it][A[A-------------------------------
-------------------------------
model running time:  27.75347137451172
-------------------------------
-------------------------------
model running time:  10.548224449157715
-------------------------------
-------------------------------
model running time:  31.397823333740234
-------------------------------
Vision time :  85.8861083984375
Action time :  109.1256332397461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.944063186645508
-------------------------------
-------------------------------
model running time:  8.521727561950684
-------------------------------
-------------------------------
model running time:  28.073984146118164
-------------------------------
-------------------------------
model running time:  10.574848175048828
-------------------------------
-------------------------------
model running time:  27.478015899658203
-------------------------------
Vision time :  85.86406707763672
Action time :  110.54182434082031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.774080276489258
-------------------------------
-------------------------------
model running time:  8.4203519821167
-------------------------------
-------------------------------
model running time:  33.34860610961914
-------------------------------
-------------------------------
model running time:  10.534912109375
-------------------------------
-------------------------------
model running time:  28.295167922973633
-------------------------------
Vision time :  85.88813018798828
Action time :  111.19417572021484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.817087173461914
-------------------------------
-------------------------------
model running time:  8.416383743286133
-------------------------------
-------------------------------
model running time:  27.51795196533203
-------------------------------
-------------------------------
model running time:  10.460160255432129
-------------------------------
-------------------------------
model running time:  31.074304580688477
-------------------------------
Vision time :  85.88742065429688
Action time :  107.99513244628906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.01366424560547
-------------------------------
-------------------------------
model running time:  8.50432014465332
-------------------------------
-------------------------------
model running time:  27.815935134887695
-------------------------------
-------------------------------
model running time:  10.467264175415039
-------------------------------
-------------------------------
model running time:  27.54038429260254
-------------------------------
Vision time :  85.8815689086914
Action time :  105.14739227294922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.40380859375
-------------------------------
-------------------------------
model running time:  8.458239555358887
-------------------------------
-------------------------------
model running time:  28.50102424621582
-------------------------------
-------------------------------
model running time:  10.88419246673584
-------------------------------
-------------------------------
model running time:  27.70534324645996
-------------------------------
Vision time :  85.97468566894531
Action time :  107.19136047363281
Trial 19 finished, success: tensor([True]), steps: 88
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.868288040161133
-------------------------------
-------------------------------
model running time:  8.39782428741455
-------------------------------
-------------------------------
model running time:  38.048702239990234
-------------------------------
-------------------------------
model running time:  10.529791831970215
-------------------------------
-------------------------------
model running time:  27.75347137451172
-------------------------------
Vision time :  85.85913848876953
Action time :  115.57376098632812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.90105628967285
-------------------------------
-------------------------------
model running time:  8.37939167022705
-------------------------------
-------------------------------
model running time:  27.78112030029297
-------------------------------
-------------------------------
model running time:  10.446880340576172
-------------------------------
-------------------------------
model running time:  27.50048065185547
-------------------------------
Vision time :  85.90022277832031
Action time :  105.10233306884766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.050432205200195
-------------------------------
-------------------------------
model running time:  8.589311599731445
-------------------------------
-------------------------------
model running time:  27.93574333190918
-------------------------------
-------------------------------
model running time:  10.578944206237793
-------------------------------
-------------------------------
model running time:  31.18182373046875
-------------------------------
Vision time :  85.90198516845703
Action time :  109.74310302734375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.97065544128418
-------------------------------
-------------------------------
model running time:  8.402815818786621
-------------------------------
-------------------------------
model running time:  27.616256713867188
-------------------------------
-------------------------------
model running time:  10.494976043701172
-------------------------------
-------------------------------
model running time:  33.693695068359375
-------------------------------
Vision time :  85.8854751586914
Action time :  111.15331268310547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.915327072143555
-------------------------------
-------------------------------
model running time:  8.436767578125
-------------------------------
-------------------------------
model running time:  27.823104858398438
-------------------------------
-------------------------------
model running time:  10.476544380187988
-------------------------------
-------------------------------
model running time:  27.679744720458984
-------------------------------
Vision time :  85.86441802978516
Action time :  105.4760971069336
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.262527465820312
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  27.817888259887695
-------------------------------
-------------------------------
model running time:  10.46230411529541
-------------------------------
-------------------------------
model running time:  27.652095794677734
-------------------------------
Vision time :  85.91120147705078
Action time :  106.0843505859375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.989120483398438
-------------------------------
-------------------------------
model running time:  8.48588752746582
-------------------------------
-------------------------------
model running time:  27.809791564941406
-------------------------------
-------------------------------
model running time:  14.857151985168457
-------------------------------
-------------------------------
model running time:  27.686912536621094
-------------------------------
Vision time :  85.86605072021484
Action time :  110.71794891357422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.943552017211914
-------------------------------
-------------------------------
model running time:  8.51968002319336
-------------------------------
-------------------------------
model running time:  27.87945556640625
-------------------------------
-------------------------------
model running time:  10.521759986877441
-------------------------------
-------------------------------
model running time:  27.75551986694336
-------------------------------
Vision time :  85.90022277832031
Action time :  112.00511932373047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.935871124267578
-------------------------------
-------------------------------
model running time:  8.507391929626465
-------------------------------
-------------------------------
model running time:  27.889568328857422
-------------------------------
-------------------------------
model running time:  10.555392265319824
-------------------------------
-------------------------------
model running time:  27.805696487426758
-------------------------------
Vision time :  85.87344360351562
Action time :  106.13862609863281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.74995231628418
-------------------------------
-------------------------------
model running time:  8.405856132507324
-------------------------------
-------------------------------
model running time:  27.7891845703125
-------------------------------
-------------------------------
model running time:  10.52774429321289
-------------------------------
-------------------------------
model running time:  27.629568099975586
-------------------------------
Vision time :  85.93865966796875
Action time :  106.32704162597656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.95020866394043
-------------------------------
-------------------------------
model running time:  8.433664321899414
-------------------------------
-------------------------------
model running time:  27.73299217224121
-------------------------------
-------------------------------
model running time:  10.51852798461914
-------------------------------
-------------------------------
model running time:  27.5916805267334
-------------------------------
Vision time :  85.97596740722656
Action time :  105.21497344970703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.189823150634766
-------------------------------
-------------------------------
model running time:  8.460288047790527
-------------------------------
-------------------------------
model running time:  27.667455673217773
-------------------------------
-------------------------------
model running time:  10.462207794189453
-------------------------------
-------------------------------
model running time:  27.488256454467773
-------------------------------
Vision time :  85.88944244384766
Action time :  105.82425689697266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9420166015625
-------------------------------
-------------------------------
model running time:  8.370176315307617
-------------------------------
-------------------------------
model running time:  27.55276870727539
-------------------------------
-------------------------------
model running time:  10.498047828674316
-------------------------------
-------------------------------
model running time:  33.3568000793457
-------------------------------
Vision time :  85.95536041259766
Action time :  110.71078491210938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.637311935424805
-------------------------------
-------------------------------
model running time:  8.415328025817871
-------------------------------
-------------------------------
model running time:  32.80265426635742
-------------------------------
-------------------------------
model running time:  10.473471641540527
-------------------------------
-------------------------------
model running time:  27.589567184448242
-------------------------------
Vision time :  85.876220703125
Action time :  111.23609924316406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.792512893676758
-------------------------------
-------------------------------
model running time:  8.447999954223633
-------------------------------
-------------------------------
model running time:  27.594751358032227
-------------------------------
-------------------------------
model running time:  10.43558406829834
-------------------------------
-------------------------------
model running time:  27.452415466308594
-------------------------------
Vision time :  85.88531494140625
Action time :  105.01324462890625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.159103393554688
-------------------------------
-------------------------------
model running time:  8.522751808166504
-------------------------------
-------------------------------
model running time:  35.90553665161133
-------------------------------
-------------------------------
model running time:  10.508416175842285
-------------------------------
-------------------------------
model running time:  27.683839797973633
-------------------------------
Vision time :  85.87980651855469
Action time :  113.96915435791016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89276885986328
-------------------------------
-------------------------------
model running time:  8.412256240844727
-------------------------------
-------------------------------
model running time:  27.66547203063965
-------------------------------
-------------------------------
model running time:  10.449919700622559
-------------------------------
-------------------------------
model running time:  31.633407592773438
-------------------------------
Vision time :  85.89881896972656
Action time :  109.69715118408203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.12428855895996
-------------------------------
-------------------------------
model running time:  8.436863899230957
-------------------------------
-------------------------------
model running time:  27.74220848083496
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  32.81407928466797
-------------------------------
Vision time :  85.89974212646484
Action time :  110.50390625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.780223846435547
-------------------------------
-------------------------------
model running time:  8.41318416595459
-------------------------------
-------------------------------
model running time:  27.660287857055664
-------------------------------
-------------------------------
model running time:  10.480640411376953
-------------------------------
-------------------------------
model running time:  27.469823837280273
-------------------------------
Vision time :  

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [01:25<00:29,  5.87s/it][A[A85.89170837402344
Action time :  105.17298889160156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.101760864257812
-------------------------------
-------------------------------
model running time:  8.440799713134766
-------------------------------
-------------------------------
model running time:  27.76473617553711
-------------------------------
-------------------------------
model running time:  10.494976043701172
-------------------------------
-------------------------------
model running time:  29.750272750854492
-------------------------------
Vision time :  85.86787414550781
Action time :  107.91011047363281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  35.49798583984375
-------------------------------
-------------------------------
model running time:  8.503264427185059
-------------------------------
-------------------------------
model running time:  27.826175689697266
-------------------------------
-------------------------------
model running time:  10.512384414672852
-------------------------------
-------------------------------
model running time:  27.644927978515625
-------------------------------
Vision time :  85.90016174316406
Action time :  115.52774047851562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.229951858520508
-------------------------------
-------------------------------
model running time:  8.483839988708496
-------------------------------
-------------------------------
model running time:  27.73289680480957
-------------------------------
-------------------------------
model running time:  10.549247741699219
-------------------------------
-------------------------------
model running time:  27.588544845581055
-------------------------------
Vision time :  85.90076446533203
Action time :  110.98521423339844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.959423065185547
-------------------------------
-------------------------------
model running time:  8.42137622833252
-------------------------------
-------------------------------
model running time:  27.696191787719727
-------------------------------
-------------------------------
model running time:  10.483712196350098
-------------------------------
-------------------------------
model running time:  27.541471481323242
-------------------------------
Vision time :  85.90847778320312
Action time :  105.16377258300781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.95737648010254
-------------------------------
-------------------------------
model running time:  8.457216262817383
-------------------------------
-------------------------------
model running time:  27.720703125
-------------------------------
-------------------------------
model running time:  10.44275188446045
-------------------------------
-------------------------------
model running time:  27.614208221435547
-------------------------------
Vision time :  85.87216186523438
Action time :  105.61529541015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.083776473999023
-------------------------------
-------------------------------
model running time:  8.49407958984375
-------------------------------
-------------------------------
model running time:  27.884544372558594
-------------------------------
-------------------------------
model running time:  10.52467155456543
-------------------------------
-------------------------------
model running time:  27.55788803100586
-------------------------------
Vision time :  85.89814758300781
Action time :  110.52134704589844
Trial 20 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.075136184692383
-------------------------------
-------------------------------
model running time:  8.545280456542969
-------------------------------
-------------------------------
model running time:  27.835296630859375
-------------------------------
-------------------------------
model running time:  10.606592178344727
-------------------------------
-------------------------------
model running time:  27.59984016418457
-------------------------------
Vision time :  85.8985595703125
Action time :  106.16831970214844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.11712074279785
-------------------------------
-------------------------------
model running time:  8.469504356384277
-------------------------------
-------------------------------
model running time:  27.888639450073242
-------------------------------
-------------------------------
model running time:  10.571776390075684
-------------------------------
-------------------------------
model running time:  27.570144653320312
-------------------------------
Vision time :  85.90684509277344
Action time :  105.85906982421875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.8240966796875
-------------------------------
-------------------------------
model running time:  8.373248100280762
-------------------------------
-------------------------------
model running time:  27.645952224731445
-------------------------------
-------------------------------
model running time:  10.572799682617188
-------------------------------
-------------------------------
model running time:  33.524864196777344
-------------------------------
Vision time :  86.11811065673828
Action time :  111.17670440673828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.899648666381836
-------------------------------
-------------------------------
model running time:  8.59443187713623
-------------------------------
-------------------------------
model running time:  27.717632293701172
-------------------------------
-------------------------------
model running time:  10.53593635559082
-------------------------------
-------------------------------
model running time:  27.561983108520508
-------------------------------
Vision time :  85.89619445800781
Action time :  111.72249603271484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.56729507446289
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  27.693056106567383
-------------------------------
-------------------------------
model running time:  10.462207794189453
-------------------------------
-------------------------------
model running time:  27.50873565673828
-------------------------------
Vision time :  85.88009643554688
Action time :  112.21507263183594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.035200119018555
-------------------------------
-------------------------------
model running time:  8.448991775512695
-------------------------------
-------------------------------
model running time:  27.662336349487305
-------------------------------
-------------------------------
model running time:  10.520575523376465
-------------------------------
-------------------------------
model running time:  27.54969596862793
-------------------------------
Vision time :  85.90278625488281
Action time :  105.61116790771484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.858047485351562
-------------------------------
-------------------------------
model running time:  8.492032051086426
-------------------------------
-------------------------------
model running time:  35.07807922363281
-------------------------------
-------------------------------
model running time:  10.519552230834961
-------------------------------
-------------------------------
model running time:  27.635711669921875
-------------------------------
Vision time :  85.86892700195312
Action time :  112.67481231689453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.95840072631836
-------------------------------
-------------------------------
model running time:  8.433664321899414
-------------------------------
-------------------------------
model running time:  27.75040054321289
-------------------------------
-------------------------------
model running time:  10.530816078186035
-------------------------------
-------------------------------
model running time:  27.466751098632812
-------------------------------
Vision time :  85.87977600097656
Action time :  105.46073913574219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.462207794189453
-------------------------------
-------------------------------
model running time:  8.423423767089844
-------------------------------
-------------------------------
model running time:  31.009824752807617
-------------------------------
-------------------------------
model running time:  10.50931167602539
-------------------------------
-------------------------------
model running time:  27.612159729003906
-------------------------------
Vision time :  85.89462280273438
Action time :  108.72115325927734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.292224884033203
-------------------------------
-------------------------------
model running time:  8.54422378540039
-------------------------------
-------------------------------
model running time:  27.813888549804688
-------------------------------
-------------------------------
model running time:  10.468352317810059
-------------------------------
-------------------------------
model running time:  27.54252815246582
-------------------------------
Vision time :  85.90582275390625
Action time :  105.43001556396484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952


 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [01:31<00:22,  5.72s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.826303482055664
-------------------------------
-------------------------------
model running time:  11.566080093383789
-------------------------------
-------------------------------
model running time:  27.82102394104004
-------------------------------
-------------------------------
model running time:  10.550271987915039
-------------------------------
-------------------------------
model running time:  27.62233543395996
-------------------------------
Vision time :  85.8825912475586
Action time :  108.59004974365234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.364032745361328
-------------------------------
-------------------------------
model running time:  8.473631858825684
-------------------------------
-------------------------------
model running time:  27.857919692993164
-------------------------------
-------------------------------
model running time:  10.549247741699219
-------------------------------
-------------------------------
model running time:  27.848703384399414
-------------------------------
Vision time :  85.8917465209961
Action time :  110.56626892089844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.71766471862793
-------------------------------
-------------------------------
model running time:  12.319744110107422
-------------------------------
-------------------------------
model running time:  27.675647735595703
-------------------------------
-------------------------------
model running time:  10.437631607055664
-------------------------------
-------------------------------
model running time:  27.474943161010742
-------------------------------
Vision time :  85.92041778564453
Action time :  109.21881866455078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.377216339111328
-------------------------------
-------------------------------
model running time:  8.424544334411621
-------------------------------
-------------------------------
model running time:  27.521024703979492
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  27.572223663330078
-------------------------------
Vision time :  85.9184341430664
Action time :  111.8914566040039
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.250240325927734
-------------------------------
-------------------------------
model running time:  8.426495552062988
-------------------------------
-------------------------------
model running time:  27.559871673583984
-------------------------------
-------------------------------
model running time:  10.499072074890137
-------------------------------
-------------------------------
model running time:  27.5548152923584
-------------------------------
Vision time :  85.96249389648438
Action time :  105.36243438720703
Trial 21 finished, success: tensor([True]), steps: 231
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.54310417175293
-------------------------------
-------------------------------
model running time:  8.487936019897461
-------------------------------
-------------------------------
model running time:  27.814912796020508
-------------------------------
-------------------------------
model running time:  10.514431953430176
-------------------------------
-------------------------------
model running time:  27.74630355834961
-------------------------------
Vision time :  85.88304138183594
Action time :  106.18998718261719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.149887084960938
-------------------------------
-------------------------------
model running time:  8.446975708007812
-------------------------------
-------------------------------
model running time:  29.95199966430664
-------------------------------
-------------------------------
model running time:  10.492927551269531
-------------------------------
-------------------------------
model running time:  27.425792694091797
-------------------------------
Vision time :  85.90959930419922
Action time :  107.06841278076172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.224639892578125
-------------------------------
-------------------------------
model running time:  8.457216262817383
-------------------------------
-------------------------------
model running time:  27.669504165649414
-------------------------------
-------------------------------
model running time:  10.575872421264648
-------------------------------
-------------------------------
model running time:  27.57427215576172
-------------------------------
Vision time :  85.90764617919922
Action time :  105.35526275634766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952


 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [01:34<00:15,  5.09s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.371135711669922
-------------------------------
-------------------------------
model running time:  8.439680099487305
-------------------------------
-------------------------------
model running time:  27.629568099975586
-------------------------------
-------------------------------
model running time:  10.505215644836426
-------------------------------
-------------------------------
model running time:  27.50873565673828
-------------------------------
Vision time :  85.8984603881836
Action time :  105.29901123046875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.251264572143555
-------------------------------
-------------------------------
model running time:  8.438943862915039
-------------------------------
-------------------------------
model running time:  30.277727127075195
-------------------------------
-------------------------------
model running time:  10.53388786315918
-------------------------------
-------------------------------
model running time:  27.55174446105957
-------------------------------
Vision time :  85.89574432373047
Action time :  107.99513244628906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.3055362701416
-------------------------------
-------------------------------
model running time:  8.417280197143555
-------------------------------
-------------------------------
model running time:  27.465728759765625
-------------------------------
-------------------------------
model running time:  10.465279579162598
-------------------------------
-------------------------------
model running time:  31.360000610351562
-------------------------------
Vision time :  85.88706970214844
Action time :  108.74050903320312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.241024017333984
-------------------------------
-------------------------------
model running time:  8.449024200439453
-------------------------------
-------------------------------
model running time:  32.40550231933594
-------------------------------
-------------------------------
model running time:  10.523648262023926
-------------------------------
-------------------------------
model running time:  27.702272415161133
-------------------------------
Vision time :  85.89596557617188
Action time :  110.24700927734375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.272768020629883
-------------------------------
-------------------------------
model running time:  14.441472053527832
-------------------------------
-------------------------------
model running time:  27.669599533081055
-------------------------------
-------------------------------
model running time:  10.477567672729492
-------------------------------
-------------------------------
model running time:  27.39507293701172
-------------------------------
Vision time :  85.92034912109375
Action time :  111.03129577636719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.875423431396484
-------------------------------
-------------------------------
model running time:  8.389632225036621
-------------------------------
-------------------------------
model running time:  27.373567581176758
-------------------------------
-------------------------------
model running time:  10.500096321105957
-------------------------------
-------------------------------
model running time:  27.35526466369629
-------------------------------
Vision time :  85.8873291015625
Action time :  104.23804473876953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.478591918945312
-------------------------------
-------------------------------
model running time:  8.367199897766113
-------------------------------
-------------------------------
model running time:  31.085567474365234
-------------------------------
-------------------------------
model running time:  10.473567962646484
-------------------------------
-------------------------------
model running time:  27.304960250854492
-------------------------------
Vision time :  85.95536041259766
Action time :  108.43852996826172
Trial 22 finished, success: tensor([True]), steps: 147
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.149887084960938
-------------------------------
-------------------------------
model running time:  8.468480110168457
-------------------------------
-------------------------------
model running time:  27.603967666625977
-------------------------------
-------------------------------
model running time:  10.456064224243164
-------------------------------
-------------------------------
model running time:  27.496448516845703
-------------------------------
Vision time :  85.91897583007812
Action time :  105.02047729492188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.088319778442383
-------------------------------
-------------------------------
model running time:  8.376319885253906
-------------------------------
-------------------------------
model running time:  27.655168533325195
-------------------------------
-------------------------------
model running time:  10.501119613647461
-------------------------------
-------------------------------
model running time:  27.793407440185547
-------------------------------
Vision time :  85.91305541992188
Action time :  105.33888244628906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.233919143676758
-------------------------------
-------------------------------
model running time:  8.42137622833252
-------------------------------
-------------------------------
model running time:  28.181503295898438
-------------------------------
-------------------------------
model running time:  10.440704345703125
-------------------------------
-------------------------------
model running time:  27.375648498535156
-------------------------------
Vision time :  85.9247055053711
Action time :  105.41474914550781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.54310417175293
-------------------------------
-------------------------------
model running time:  8.439807891845703
-------------------------------
-------------------------------
model running time:  27.709440231323242
-------------------------------
-------------------------------
model running time:  10.481663703918457
-------------------------------
-------------------------------
model running time:  31.58732795715332
-------------------------------
Vision time :  85.92198181152344
Action time :  109.64991760253906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.29324722290039
-------------------------------
-------------------------------
model running time:  8.438783645629883
-------------------------------
-------------------------------
model running time:  27.593727111816406
-------------------------------
-------------------------------
model running time:  10.502143859863281
-------------------------------
-------------------------------
model running time:  33.481727600097656
-------------------------------
Vision time :  85.93353271484375
Action time :  111.13788604736328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.452735900878906
-------------------------------
-------------------------------
model running time:  8.434880256652832
-------------------------------
-------------------------------
model running time:  27.612287521362305
-------------------------------
-------------------------------
model running time:  10.492863655090332
-------------------------------
-------------------------------
model running time:  27.34284782409668
-------------------------------
Vision time :  85.9150390625
Action time :  109.13484954833984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.14169692993164
-------------------------------
-------------------------------
model running time:  8.41113567352295
-------------------------------
-------------------------------
model running time:  32.454654693603516
-------------------------------
-------------------------------
model running time:  10.457023620605469
-------------------------------
-------------------------------
model running time:  27.412479400634766
-------------------------------
Vision time :  85.9283218383789
Action time :  109.6941146850586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.02048110961914
-------------------------------
-------------------------------
model running time:  8.478655815124512
-------------------------------
-------------------------------
model running time:  27.5548152923584
-------------------------------
-------------------------------
model running time:  10.487808227539062
-------------------------------
-------------------------------
model running time:  27.33260726928711
-------------------------------
Vision time :  86.0499496459961
Action time :  110.86029052734375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.238975524902344
-------------------------------
-------------------------------
model running time:  8.435680389404297
-------------------------------
-------------------------------
model running time:  27.653120040893555
-------------------------------
-------------------------------
model running time:  10.493951797485352
-------------------------------
-------------------------------
model running time:  27.5548152923584
-------------------------------
Vision time :  85.9856948852539
Action time :  105.21190643310547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.33318328857422
-------------------------------
-------------------------------
model running time:  8.4203519821167
-------------------------------
-------------------------------
model running time:  33.115135192871094
-------------------------------
-------------------------------
model running time:  10.506239891052246
-------------------------------
-------------------------------
model running time:  27.522911071777344
-------------------------------
Vision time :  85.89167785644531
Action time :  111.34966278076172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.3133430480957
-------------------------------
-------------------------------
model running time:  8.454015731811523
-------------------------------
-------------------------------
model running time:  27.824127197265625
-------------------------------
-------------------------------
model running time:  10.482815742492676
-------------------------------
-------------------------------
model running time:  27.57632064819336
-------------------------------
Vision time :  86.02957153320312
Action time :  111.6917724609375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.98124885559082
-------------------------------
-------------------------------
model running time:  8.459424018859863
-------------------------------
-------------------------------
model running time:  27.694944381713867
-------------------------------
-------------------------------
model running time:  10.466303825378418
-------------------------------
-------------------------------
model running time:  27.632640838623047
-------------------------------
Vision time :  85.91600036621094
Action time :  106.08537292480469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.100736618041992
-------------------------------
-------------------------------
model running time:  8.408063888549805
-------------------------------
-------------------------------
model running time:  27.55891227722168
-------------------------------
-------------------------------
model running time:  10.446847915649414
-------------------------------
-------------------------------
model running time:  27.38483238220215
-------------------------------
Vision time :  85.90509033203125
Action time :  104.6661148071289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.393600463867188
-------------------------------
-------------------------------
model running time:  8.439807891845703
-------------------------------
-------------------------------
model running time:  27.597824096679688
-------------------------------
-------------------------------
model running time:  10.515456199645996
-------------------------------
-------------------------------
model running time:  27.381759643554688
-------------------------------
Vision time :  85.90060424804688
Action time :  105.57337951660156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.211360931396484
-------------------------------
-------------------------------
model running time:  8.393664360046387
-------------------------------
-------------------------------
model running time:  27.56403160095215
-------------------------------
-------------------------------
model running time:  10.497023582458496
-------------------------------
-------------------------------
model running time:  27.425792694091797
-------------------------------
Vision time :  85.90662384033203
Action time :  105.80697631835938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.27686309814453
-------------------------------
-------------------------------
model running time:  8.401920318603516
-------------------------------
-------------------------------
model running time:  27.55583953857422
-------------------------------
-------------------------------
model running time:  14.435327529907227
-------------------------------
-------------------------------
model running time:  27.5097599029541
-------------------------------
Vision time :  85.89734649658203
Action time :  109.25875091552734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.229663848876953
-------------------------------
-------------------------------
model running time:  8.488960266113281
-------------------------------
-------------------------------
model running time:  27.69715118408203
-------------------------------
-------------------------------
model running time:  10.460160255432129
-------------------------------
-------------------------------
model running time:  27.55072021484375
-------------------------------
Vision time :  85.96685028076172
Action time :  105.60399627685547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048


 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [01:43<00:12,  6.28s/it][A[A-------------------------------
model running time:  26.27686309814453
-------------------------------
-------------------------------
model running time:  8.455167770385742
-------------------------------
-------------------------------
model running time:  27.579391479492188
-------------------------------
-------------------------------
model running time:  10.472448348999023
-------------------------------
-------------------------------
model running time:  27.452415466308594
-------------------------------
Vision time :  85.90025329589844
Action time :  105.73414611816406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.31679916381836
-------------------------------
-------------------------------
model running time:  8.40396785736084
-------------------------------
-------------------------------
model running time:  27.659263610839844
-------------------------------
-------------------------------
model running time:  10.503168106079102
-------------------------------
-------------------------------
model running time:  27.7708797454834
-------------------------------
Vision time :  85.89385223388672
Action time :  105.7597427368164
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.77017593383789
-------------------------------
-------------------------------
model running time:  8.491007804870605
-------------------------------
-------------------------------
model running time:  27.73401641845703
-------------------------------
-------------------------------
model running time:  10.454912185668945
-------------------------------
-------------------------------
model running time:  27.53126335144043
-------------------------------
Vision time :  85.9051513671875
Action time :  109.69087982177734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.867263793945312
-------------------------------
-------------------------------
model running time:  8.428544044494629
-------------------------------
-------------------------------
model running time:  27.651071548461914
-------------------------------
-------------------------------
model running time:  10.459136009216309
-------------------------------
-------------------------------
model running time:  32.00409698486328
-------------------------------
Vision time :  85.90045166015625
Action time :  109.42361450195312
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92460823059082
-------------------------------
-------------------------------
model running time:  8.436736106872559
-------------------------------
-------------------------------
model running time:  27.73401641845703
-------------------------------
-------------------------------
model running time:  10.522624015808105
-------------------------------
-------------------------------
model running time:  27.442176818847656
-------------------------------
Vision time :  85.86768341064453
Action time :  105.3460464477539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.773056030273438
-------------------------------
-------------------------------
model running time:  8.423423767089844
-------------------------------
-------------------------------
model running time:  34.86924743652344
-------------------------------
-------------------------------
model running time:  10.507264137268066
-------------------------------
-------------------------------
model running time:  27.479103088378906
-------------------------------
Vision time :  85.89750671386719
Action time :  111.75936126708984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.189823150634766
-------------------------------
-------------------------------
model running time:  8.489824295043945
-------------------------------
-------------------------------
model running time:  27.691999435424805
-------------------------------
-------------------------------
model running time:  10.523648262023926
-------------------------------
-------------------------------
model running time:  27.620351791381836
-------------------------------
Vision time :  85.8845443725586
Action time :  105.82118225097656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.867263793945312
-------------------------------
-------------------------------
model running time:  8.50432014465332
-------------------------------
-------------------------------
model running time:  27.644927978515625
-------------------------------
-------------------------------
model running time:  10.515456199645996
-------------------------------
-------------------------------
model running time:  27.55583953857422
-------------------------------
Vision time :  85.90953826904297
Action time :  106.48780822753906
Trial 23 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  

 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [01:46<00:05,  5.25s/it][A[A26.066944122314453
-------------------------------
-------------------------------
model running time:  8.49619197845459
-------------------------------
-------------------------------
model running time:  27.91219139099121
-------------------------------
-------------------------------
model running time:  10.631168365478516
-------------------------------
-------------------------------
model running time:  34.84476852416992
-------------------------------
Vision time :  85.86688232421875
Action time :  113.70915222167969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.811967849731445
-------------------------------
-------------------------------
model running time:  8.447999954223633
-------------------------------
-------------------------------
model running time:  35.53792190551758
-------------------------------
-------------------------------
model running time:  10.497023582458496
-------------------------------
-------------------------------
model running time:  27.423744201660156
-------------------------------
Vision time :  85.87548828125
Action time :  112.88883209228516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.7761287689209
-------------------------------
-------------------------------
model running time:  8.50534439086914
-------------------------------
-------------------------------
model running time:  27.660287857055664
-------------------------------
-------------------------------
model running time:  10.568703651428223
-------------------------------
-------------------------------
model running time:  31.475616455078125
-------------------------------
Vision time :  85.85833740234375
Action time :  109.3918685913086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.692800521850586
-------------------------------
-------------------------------
model running time:  8.451071739196777
-------------------------------
-------------------------------
model running time:  27.709440231323242
-------------------------------
-------------------------------
model running time:  10.566656112670898
-------------------------------
-------------------------------
model running time:  27.605119705200195
-------------------------------
Vision time :  85.89820861816406
Action time :  111.0804443359375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.732128143310547
-------------------------------
-------------------------------
model running time:  17.286144256591797
-------------------------------
-------------------------------
model running time:  27.699199676513672
-------------------------------
-------------------------------
model running time:  10.56873607635498
-------------------------------
-------------------------------
model running time:  27.484159469604492
-------------------------------
Vision time :  85.9037094116211
Action time :  114.07257843017578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.390527725219727
-------------------------------
-------------------------------
model running time:  8.444928169250488
-------------------------------
-------------------------------
model running time:  27.607135772705078
-------------------------------
-------------------------------
model running time:  10.552319526672363
-------------------------------
-------------------------------
model running time:  27.50668716430664
-------------------------------
Vision time :  85.89933013916016
Action time :  106.39360046386719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9420166015625
-------------------------------
-------------------------------
model running time:  8.369152069091797
-------------------------------
-------------------------------
model running time:  27.454463958740234
-------------------------------
-------------------------------
model running time:  10.500096321105957
-------------------------------
-------------------------------
model running time:  27.412479400634766
-------------------------------
Vision time :  85.8887710571289
Action time :  105.05318450927734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.11302375793457
-------------------------------
-------------------------------
model running time:  8.484864234924316
-------------------------------
-------------------------------
model running time:  27.536256790161133
-------------------------------
-------------------------------
model running time:  10.537983894348145
-------------------------------
-------------------------------
model running time:  27.469823837280273
-------------------------------
Vision time :  85.90070343017578
Action time :  105.33888244628906
Trial 24 finished, success: tensor([True]), steps: 117
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.13555145263672
-------------------------------


100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [01:48<00:00,  4.32s/it][A[A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [01:48<00:00,  4.35s/it]

 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [05:13<12:20, 105.81s/it][A-------------------------------
model running time:  8.412032127380371
-------------------------------
-------------------------------
model running time:  27.644927978515625
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  27.56608009338379
-------------------------------
Vision time :  85.89756774902344
Action time :  104.99993896484375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.213375091552734
-------------------------------
-------------------------------
model running time:  8.457216262817383
-------------------------------
-------------------------------
model running time:  27.74835205078125
-------------------------------
-------------------------------
model running time:  10.483712196350098
-------------------------------
-------------------------------
model running time:  27.3654727935791
-------------------------------
Vision time :  85.91232299804688
Action time :  104.97740936279297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.001407623291016
-------------------------------
-------------------------------
model running time:  8.40499210357666
-------------------------------
-------------------------------
model running time:  27.56915283203125
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  27.593664169311523
-------------------------------
Vision time :  85.89654541015625
Action time :  104.69379425048828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.041791915893555
-------------------------------
-------------------------------
model running time:  8.451071739196777
-------------------------------
-------------------------------
model running time:  27.598880767822266
-------------------------------
-------------------------------
model running time:  10.570752143859863
-------------------------------
-------------------------------
model running time:  27.579391479492188
-------------------------------
Vision time :  86.03311920166016
Action time :  106.0976333618164
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.185855865478516
-------------------------------
-------------------------------
model running time:  8.459263801574707
-------------------------------
-------------------------------
model running time:  27.810815811157227
-------------------------------
-------------------------------
model running time:  10.638336181640625
-------------------------------
-------------------------------
model running time:  27.709375381469727
-------------------------------
Vision time :  85.89679718017578
Action time :  105.54879760742188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.647552490234375
-------------------------------
-------------------------------
model running time:  8.466431617736816
-------------------------------
-------------------------------
model running time:  27.626495361328125
-------------------------------
-------------------------------
model running time:  10.499072074890137
-------------------------------
-------------------------------
model running time:  27.51487922668457
-------------------------------
Vision time :  85.98051452636719
Action time :  105.72694396972656
Trial 25 finished, success: tensor([True]), steps: 91
policy.alpha = 1.0policy.temp = 0.01
policy.alpha = 1.0policy.temp = 0.01
Success rate: 76.0%
Running trial with alpha=1.0, temp=0.01. Re-seeding with 20241201.


  0%|          | 0/25 [00:00<?, ?it/s][A[A

  4%|â–         | 1/25 [00:02<01:07,  2.82s/it][A[Abefore pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.255359649658203
-------------------------------
-------------------------------
model running time:  8.449919700622559
-------------------------------
-------------------------------
model running time:  27.653120040893555
-------------------------------
-------------------------------
model running time:  10.510335922241211
-------------------------------
-------------------------------
model running time:  27.458560943603516
-------------------------------
Vision time :  85.89180755615234
Action time :  105.04704284667969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.652223587036133
-------------------------------
-------------------------------
model running time:  8.3886079788208
-------------------------------
-------------------------------
model running time:  27.841535568237305
-------------------------------
-------------------------------
model running time:  10.484736442565918
-------------------------------
-------------------------------
model running time:  27.5732479095459
-------------------------------
Vision time :  85.87471771240234
Action time :  104.48384094238281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.667583465576172
-------------------------------
-------------------------------
model running time:  8.418208122253418
-------------------------------
-------------------------------
model running time:  27.61814308166504
-------------------------------
-------------------------------
model running time:  10.500096321105957
-------------------------------
-------------------------------
model running time:  27.625471115112305
-------------------------------
Vision time :  85.9431381225586
Action time :  104.5032958984375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.38425636291504
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  27.74220848083496
-------------------------------
-------------------------------
model running time:  10.476544380187988
-------------------------------
-------------------------------
model running time:  27.54355239868164
-------------------------------
Vision time :  85.88374328613281
Action time :  107.30086517333984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.618431091308594
-------------------------------
-------------------------------
model running time:  8.427519798278809
-------------------------------
-------------------------------
model running time:  27.406272888183594
-------------------------------
-------------------------------
model running time:  10.432576179504395
-------------------------------
-------------------------------
model running time:  27.280384063720703
-------------------------------
Vision time :  85.88499450683594
Action time :  103.8571548461914
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.51193618774414
-------------------------------
-------------------------------
model running time:  8.361120223999023
-------------------------------
-------------------------------
model running time:  27.461631774902344
-------------------------------
-------------------------------
model running time:  10.469504356384277
-------------------------------
-------------------------------
model running time:  27.33363151550293
-------------------------------
Vision time :  85.88108825683594
Action time :  103.99641418457031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.31939125061035
-------------------------------
-------------------------------
model running time:  8.351743698120117
-------------------------------
-------------------------------
model running time:  27.407360076904297
-------------------------------
-------------------------------
model running time:  10.445823669433594
-------------------------------
-------------------------------
model running time:  27.418624877929688
-------------------------------
Vision time :  85.86271667480469
Action time :  103.61036682128906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.632768630981445
-------------------------------
-------------------------------
model running time:  8.415295600891113
-------------------------------
-------------------------------
model running time:  27.512832641601562
-------------------------------
-------------------------------
model running time:  10.461376190185547
-------------------------------
-------------------------------
model running time:  27.426816940307617
-------------------------------
Vision time :  85.8458251953125
Action time :  104.5381088256836
Trial 1 finished, success: tensor([True]), steps: 126
policy.alpha = 1.0policy.temp = 0.01
before pruning: 


  8%|â–Š         | 2/25 [00:05<00:59,  2.58s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.73311996459961
-------------------------------
-------------------------------
model running time:  8.398847579956055
-------------------------------
-------------------------------
model running time:  27.594751358032227
-------------------------------
-------------------------------
model running time:  10.57699203491211
-------------------------------
-------------------------------
model running time:  27.501567840576172
-------------------------------
Vision time :  85.84429168701172
Action time :  104.89033508300781
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.55081558227539
-------------------------------
-------------------------------
model running time:  8.389632225036621
-------------------------------
-------------------------------
model running time:  27.67241668701172
-------------------------------
-------------------------------
model running time:  10.461183547973633
-------------------------------
-------------------------------
model running time:  33.344512939453125
-------------------------------
Vision time :  85.86653137207031
Action time :  110.01757049560547
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.671680450439453
-------------------------------
-------------------------------
model running time:  8.401920318603516
-------------------------------
-------------------------------
model running time:  27.52614402770996
-------------------------------
-------------------------------
model running time:  10.500224113464355
-------------------------------
-------------------------------
model running time:  27.403263092041016
-------------------------------
Vision time :  85.86883544921875
Action time :  104.0926742553711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.735103607177734
-------------------------------
-------------------------------
model running time:  8.423423767089844
-------------------------------
-------------------------------
model running time:  27.486207962036133
-------------------------------
-------------------------------
model running time:  10.504192352294922
-------------------------------
-------------------------------
model running time:  27.458463668823242
-------------------------------
Vision time :  85.88934326171875
Action time :  104.43968200683594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.426944732666016
-------------------------------
-------------------------------
model running time:  8.385536193847656
-------------------------------
-------------------------------
model running time:  27.512832641601562
-------------------------------
-------------------------------
model running time:  10.472576141357422
-------------------------------
-------------------------------
model running time:  27.479040145874023
-------------------------------
Vision time :  85.89446258544922
Action time :  104.13065338134766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.466815948486328
-------------------------------
-------------------------------
model running time:  8.364928245544434
-------------------------------
-------------------------------
model running time:  27.529216766357422
-------------------------------
-------------------------------
model running time:  10.507264137268066
-------------------------------
-------------------------------
model running time:  27.435935974121094
-------------------------------
Vision time :  85.90211486816406
Action time :  104.03839874267578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.46892738342285
-------------------------------
-------------------------------
model running time:  8.33340835571289
-------------------------------
-------------------------------
model running time:  27.427839279174805
-------------------------------
-------------------------------
model running time:  10.45299243927002
-------------------------------
-------------------------------
model running time:  27.379680633544922
-------------------------------
Vision time :  85.8515853881836
Action time :  103.51615905761719
Trial 2 finished, success: tensor([True]), steps: 104
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.53446388244629
-------------------------------
-------------------------------
model running time:  8.396703720092773
-------------------------------
-------------------------------
model running time:  27.619327545166016
-------------------------------
-------------------------------
model running time:  10.449888229370117
-------------------------------
-------------------------------
model running time:  27.481088638305664
-------------------------------
Vision time :  85.8440933227539
Action time :  103.93599700927734
before pruning: 


 12%|â–ˆâ–        | 3/25 [00:07<00:52,  2.37s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.108800888061523
-------------------------------
-------------------------------
model running time:  8.488960266113281
-------------------------------
-------------------------------
model running time:  29.60691261291504
-------------------------------
-------------------------------
model running time:  10.480480194091797
-------------------------------
-------------------------------
model running time:  27.620351791381836
-------------------------------
Vision time :  85.88556671142578
Action time :  107.45037078857422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.644031524658203
-------------------------------
-------------------------------
model running time:  8.435647964477539
-------------------------------
-------------------------------
model running time:  27.676671981811523
-------------------------------
-------------------------------
model running time:  10.53593635559082
-------------------------------
-------------------------------
model running time:  27.644832611083984
-------------------------------
Vision time :  85.8782730102539
Action time :  104.66201782226562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.6942081451416
-------------------------------
-------------------------------
model running time:  8.438783645629883
-------------------------------
-------------------------------
model running time:  27.623424530029297
-------------------------------
-------------------------------
model running time:  10.491744041442871
-------------------------------
-------------------------------
model running time:  27.5097599029541
-------------------------------
Vision time :  85.85017395019531
Action time :  104.3773422241211
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.416736602783203
-------------------------------
-------------------------------
model running time:  8.427519798278809
-------------------------------
-------------------------------
model running time:  27.528095245361328
-------------------------------
-------------------------------
model running time:  10.477567672729492
-------------------------------
-------------------------------
model running time:  27.481151580810547
-------------------------------
Vision time :  85.86422729492188
Action time :  103.93804931640625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.54470443725586
-------------------------------
-------------------------------
model running time:  8.407039642333984
-------------------------------
-------------------------------
model running time:  27.435007095336914
-------------------------------
-------------------------------
model running time:  10.473407745361328
-------------------------------
-------------------------------
model running time:  27.404224395751953
-------------------------------
Vision time :  85.90115356445312
Action time :  103.78137969970703
Trial 3 finished, success: tensor([True]), steps: 94
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.597951889038086
-------------------------------
-------------------------------
model running time:  8.389632225036621
-------------------------------
-------------------------------
model running time:  27.50067138671875
-------------------------------
-------------------------------
model running time:  10.519552230834961
-------------------------------
-------------------------------
model running time:  27.39081573486328
-------------------------------
Vision time :  85.85040283203125
Action time :  103.92070770263672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.424896240234375
-------------------------------
-------------------------------
model running time:  8.426495552062988
-------------------------------
-------------------------------
model running time:  27.544607162475586
-------------------------------
-------------------------------
model running time:  10.515456199645996
-------------------------------
-------------------------------
model running time:  27.636735916137695
-------------------------------
Vision time :  85.87667083740234
Action time :  104.0711669921875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.60540771484375
-------------------------------
-------------------------------
model running time:  8.467455863952637
-------------------------------
-------------------------------
model running time:  27.619327545166016
-------------------------------
-------------------------------
model running time:  10.499168395996094
-------------------------------
-------------------------------
model running time:  27.430912017822266
-------------------------------
Vision time :  85.87452697753906
Action time :  109.18605041503906
before pruning: 


 16%|â–ˆâ–Œ        | 4/25 [00:10<00:53,  2.53s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.636863708496094
-------------------------------
-------------------------------
model running time:  8.390656471252441
-------------------------------
-------------------------------
model running time:  27.68079948425293
-------------------------------
-------------------------------
model running time:  10.550111770629883
-------------------------------
-------------------------------
model running time:  27.431936264038086
-------------------------------
Vision time :  85.90406036376953
Action time :  104.23187255859375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.662464141845703
-------------------------------
-------------------------------
model running time:  8.427647590637207
-------------------------------
-------------------------------
model running time:  27.709440231323242
-------------------------------
-------------------------------
model running time:  10.499168395996094
-------------------------------
-------------------------------
model running time:  27.561983108520508
-------------------------------
Vision time :  85.89292907714844
Action time :  104.49407958984375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.630720138549805
-------------------------------
-------------------------------
model running time:  8.42240047454834
-------------------------------
-------------------------------
model running time:  27.56915283203125
-------------------------------
-------------------------------
model running time:  14.137344360351562
-------------------------------
-------------------------------
model running time:  33.47545623779297
-------------------------------
Vision time :  85.8953628540039
Action time :  114.18418884277344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.791488647460938
-------------------------------
-------------------------------
model running time:  8.446975708007812
-------------------------------
-------------------------------
model running time:  27.52409553527832
-------------------------------
-------------------------------
model running time:  11.305983543395996
-------------------------------
-------------------------------
model running time:  27.511903762817383
-------------------------------
Vision time :  85.91343688964844
Action time :  105.206787109375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.029056549072266
-------------------------------
-------------------------------
model running time:  8.42137622833252
-------------------------------
-------------------------------
model running time:  27.649023056030273
-------------------------------
-------------------------------
model running time:  10.465279579162598
-------------------------------
-------------------------------
model running time:  27.578367233276367
-------------------------------
Vision time :  85.8581771850586
Action time :  112.34713745117188
Trial 4 finished, success: tensor([True]), steps: 116
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.207103729248047
-------------------------------
-------------------------------
model running time:  8.449024200439453
-------------------------------
-------------------------------
model running time:  27.888639450073242
-------------------------------
-------------------------------
model running time:  10.490880012512207
-------------------------------
-------------------------------
model running time:  27.632640838623047
-------------------------------
Vision time :  85.9053726196289
Action time :  109.8229751586914
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.72492790222168
-------------------------------
-------------------------------
model running time:  8.417183876037598
-------------------------------
-------------------------------
model running time:  27.738975524902344
-------------------------------
-------------------------------
model running time:  10.392576217651367
-------------------------------
-------------------------------
model running time:  27.54969596862793
-------------------------------
Vision time :  85.88256072998047
Action time :  104.40191650390625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.617408752441406
-------------------------------
-------------------------------
model running time:  8.367103576660156
-------------------------------
-------------------------------
model running time:  27.54662322998047
-------------------------------
-------------------------------
model running time:  10.502143859863281
-------------------------------
-------------------------------
model running time:  27.53536033630371
-------------------------------
Vision time :  85.87814331054688
Action time :  104.0771484375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 20%|â–ˆâ–ˆ        | 5/25 [00:12<00:47,  2.40s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.829376220703125
-------------------------------
-------------------------------
model running time:  8.451071739196777
-------------------------------
-------------------------------
model running time:  27.637760162353516
-------------------------------
-------------------------------
model running time:  10.534912109375
-------------------------------
-------------------------------
model running time:  27.53638458251953
-------------------------------
Vision time :  85.88511657714844
Action time :  104.80332946777344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.77952003479004
-------------------------------
-------------------------------
model running time:  8.392704010009766
-------------------------------
-------------------------------
model running time:  27.614208221435547
-------------------------------
-------------------------------
model running time:  10.41919994354248
-------------------------------
-------------------------------
model running time:  27.41971206665039
-------------------------------
Vision time :  85.88265228271484
Action time :  107.1984634399414
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.805824279785156
-------------------------------
-------------------------------
model running time:  8.370176315307617
-------------------------------
-------------------------------
model running time:  27.540512084960938
-------------------------------
-------------------------------
model running time:  10.4519681930542
-------------------------------
-------------------------------
model running time:  32.2344970703125
-------------------------------
Vision time :  85.88915252685547
Action time :  109.0324478149414
Trial 5 finished, success: tensor([True]), steps: 84
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.645055770874023
-------------------------------
-------------------------------
model running time:  8.391679763793945
-------------------------------
-------------------------------
model running time:  27.52409553527832
-------------------------------
-------------------------------
model running time:  10.53593635559082
-------------------------------
-------------------------------
model running time:  34.03059387207031
-------------------------------
Vision time :  85.88297271728516
Action time :  110.7649917602539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.73721694946289
-------------------------------
-------------------------------
model running time:  8.441856384277344
-------------------------------
-------------------------------
model running time:  27.639808654785156
-------------------------------
-------------------------------
model running time:  10.46019172668457
-------------------------------
-------------------------------
model running time:  27.451391220092773
-------------------------------
Vision time :  85.92374420166016
Action time :  104.3978271484375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.703584671020508
-------------------------------
-------------------------------
model running time:  8.369183540344238
-------------------------------
-------------------------------
model running time:  27.610111236572266
-------------------------------
-------------------------------
model running time:  10.484736442565918
-------------------------------
-------------------------------
model running time:  33.40800094604492
-------------------------------
Vision time :  85.8918685913086
Action time :  110.18854522705078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.255359649658203
-------------------------------
-------------------------------
model running time:  8.51353645324707
-------------------------------
-------------------------------
model running time:  28.098495483398438
-------------------------------
-------------------------------
model running time:  10.592255592346191
-------------------------------
-------------------------------
model running time:  27.957120895385742
-------------------------------
Vision time :  85.92505645751953
Action time :  106.09555053710938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.073087692260742
-------------------------------
-------------------------------
model running time:  8.480768203735352
-------------------------------
-------------------------------
model running time:  27.876352310180664
-------------------------------
-------------------------------
model running time:  10.550271987915039
-------------------------------
-------------------------------
model running time:  27.642784118652344
-------------------------------
Vision time :  85.87948608398438
Action time :  105.30611419677734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952


 24%|â–ˆâ–ˆâ–       | 6/25 [00:14<00:43,  2.30s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.35385513305664
-------------------------------
-------------------------------
model running time:  8.456031799316406
-------------------------------
-------------------------------
model running time:  27.65318489074707
-------------------------------
-------------------------------
model running time:  10.447967529296875
-------------------------------
-------------------------------
model running time:  27.55788803100586
-------------------------------
Vision time :  85.88966369628906
Action time :  110.16806030273438
Trial 6 finished, success: tensor([True]), steps: 95
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.90822410583496
-------------------------------
-------------------------------
model running time:  8.474623680114746
-------------------------------
-------------------------------
model running time:  37.085025787353516
-------------------------------
-------------------------------
model running time:  10.466303825378418
-------------------------------
-------------------------------
model running time:  27.772768020629883
-------------------------------
Vision time :  85.8939208984375
Action time :  114.41561889648438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.060800552368164
-------------------------------
-------------------------------
model running time:  8.523776054382324
-------------------------------
-------------------------------
model running time:  34.78015899658203
-------------------------------
-------------------------------
model running time:  10.594335556030273
-------------------------------
-------------------------------
model running time:  27.820032119750977
-------------------------------
Vision time :  85.90847778320312
Action time :  112.57855987548828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.562559127807617
-------------------------------
-------------------------------
model running time:  8.415231704711914
-------------------------------
-------------------------------
model running time:  27.729856491088867
-------------------------------
-------------------------------
model running time:  10.497023582458496
-------------------------------
-------------------------------
model running time:  27.71558380126953
-------------------------------
Vision time :  85.94390106201172
Action time :  105.83757019042969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.508159637451172
-------------------------------
-------------------------------
model running time:  8.474623680114746
-------------------------------
-------------------------------
model running time:  27.753503799438477
-------------------------------
-------------------------------
model running time:  10.557600021362305
-------------------------------
-------------------------------
model running time:  32.63283157348633
-------------------------------
Vision time :  85.90198516845703
Action time :  110.81011199951172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.253311157226562
-------------------------------
-------------------------------
model running time:  8.439807891845703
-------------------------------
-------------------------------
model running time:  27.611135482788086
-------------------------------
-------------------------------
model running time:  10.531840324401855
-------------------------------
-------------------------------
model running time:  27.560928344726562
-------------------------------
Vision time :  85.91817474365234
Action time :  105.1956787109375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.445823669433594
-------------------------------
-------------------------------
model running time:  13.5731201171875
-------------------------------
-------------------------------
model running time:  27.947071075439453
-------------------------------
-------------------------------
model running time:  10.482687950134277
-------------------------------
-------------------------------
model running time:  27.655168533325195
-------------------------------
Vision time :  85.92729949951172
Action time :  111.78598022460938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.874431610107422
-------------------------------
-------------------------------
model running time:  12.263423919677734
-------------------------------
-------------------------------
model running time:  27.859968185424805
-------------------------------
-------------------------------
model running time:  10.523648262023926
-------------------------------
-------------------------------
model running time:  28.124000549316406
-------------------------------
Vision time :  85.90300750732422
Action time :  109.32633972167969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.209280014038086
-------------------------------
-------------------------------
model running time:  8.452095985412598
-------------------------------
-------------------------------
model running time:  27.812864303588867
-------------------------------
-------------------------------
model running time:  10.481599807739258
-------------------------------
-------------------------------
model running time:  27.665407180786133
-------------------------------
Vision time :  85.89260864257812
Action time :  105.47926330566406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.095552444458008
-------------------------------
-------------------------------
model running time:  8.40396785736084
-------------------------------
-------------------------------
model running time:  27.829248428344727
-------------------------------
-------------------------------
model running time:  10.462207794189453
-------------------------------
-------------------------------
model running time:  33.83497619628906
-------------------------------
Vision time :  87.53497314453125
Action time :  112.13311767578125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.15500831604004
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  28.026880264282227
-------------------------------
-------------------------------
model running time:  10.556415557861328
-------------------------------
-------------------------------
model running time:  27.814912796020508
-------------------------------
Vision time :  85.87635040283203
Action time :  106.02393341064453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.88876724243164
-------------------------------
-------------------------------
model running time:  8.410112380981445
-------------------------------
-------------------------------
model running time:  33.41721725463867
-------------------------------
-------------------------------
model running time:  10.501119613647461
-------------------------------
-------------------------------
model running time:  27.787200927734375
-------------------------------
Vision time :  85.88719940185547
Action time :  110.8479995727539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.18060874938965
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  27.860960006713867
-------------------------------
-------------------------------
model running time:  10.44985580444336
-------------------------------
-------------------------------
model running time:  27.664384841918945
-------------------------------
Vision time :  85.90220642089844
Action time :  105.70355224609375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9553279876709
-------------------------------
-------------------------------
model running time:  8.399871826171875
-------------------------------
-------------------------------
model running time:  27.858943939208984
-------------------------------
-------------------------------
model running time:  10.434623718261719
-------------------------------
-------------------------------
model running time:  27.55900764465332
-------------------------------
Vision time :  85.9024658203125
Action time :  105.28870391845703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.031103134155273
-------------------------------
-------------------------------
model running time:  8.414239883422852
-------------------------------
-------------------------------
model running time:  27.808767318725586
-------------------------------
-------------------------------
model running time:  10.457183837890625
-------------------------------
-------------------------------
model running time:  27.510719299316406
-------------------------------
Vision time :  85.89103698730469
Action time :  105.2405776977539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  34.83030319213867
-------------------------------
-------------------------------
model running time:  8.488960266113281
-------------------------------
-------------------------------
model running time:  27.882495880126953
-------------------------------
-------------------------------
model running time:  10.485759735107422
-------------------------------
-------------------------------
model running time:  27.794431686401367
-------------------------------
Vision time :  85.88700866699219
Action time :  114.61325073242188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.590272903442383
-------------------------------
-------------------------------
model running time:  8.48691177368164
-------------------------------
-------------------------------
model running time:  27.915264129638672
-------------------------------
-------------------------------
model running time:  10.55129623413086
-------------------------------
-------------------------------
model running time:  27.878528594970703
-------------------------------
Vision time :  85.88579559326172
Action time :  111.43154907226562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.875455856323242
-------------------------------
-------------------------------
model running time:  8.432671546936035
-------------------------------
-------------------------------
model running time:  27.78214454650879
-------------------------------
-------------------------------
model running time:  10.52774429321289
-------------------------------
-------------------------------
model running time:  27.601024627685547
-------------------------------
Vision time :  85.88893127441406
Action time :  104.96717071533203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.926559448242188
-------------------------------
-------------------------------
model running time:  12.400639533996582
-------------------------------
-------------------------------
model running time:  27.75040054321289
-------------------------------
-------------------------------
model running time:  10.463232040405273
-------------------------------
-------------------------------
model running time:  27.620351791381836
-------------------------------
Vision time :  85.85782623291016
Action time :  109.3048324584961
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.643104553222656
-------------------------------
-------------------------------
model running time:  8.409088134765625
-------------------------------
-------------------------------
model running time:  27.631616592407227
-------------------------------
-------------------------------
model running time:  10.516480445861816
-------------------------------
-------------------------------
model running time:  27.816959381103516
-------------------------------
Vision time :  85.90016174316406
Action time :  106.66291046142578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.5412483215332
-------------------------------
-------------------------------
model running time:  8.41420841217041
-------------------------------
-------------------------------
model running time:  27.615232467651367
-------------------------------
-------------------------------
model running time:  10.417152404785156
-------------------------------
-------------------------------
model running time:  27.423744201660156
-------------------------------
Vision time :  85.86841583251953
Action time :  112.29286193847656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.764863967895508
-------------------------------
-------------------------------
model running time:  8.409088134765625
-------------------------------
-------------------------------
model running time:  31.738880157470703
-------------------------------
-------------------------------
model running time:  10.470399856567383
-------------------------------
-------------------------------
model running time:  27.456512451171875
-------------------------------
Vision time :  85.90332794189453
Action time :  109.2833251953125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.126272201538086
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  27.95724868774414
-------------------------------
-------------------------------
model running time:  10.478591918945312
-------------------------------
-------------------------------
model running time:  27.76678466796875
-------------------------------
Vision time :  85.89830780029297
Action time :  105.76383972167969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.70591926574707
-------------------------------
-------------------------------
model running time:  8.439743995666504
-------------------------------
-------------------------------
model running time:  27.72480010986328
-------------------------------
-------------------------------
model running time:  10.528672218322754
-------------------------------
-------------------------------
model running time:  27.580415725708008
-------------------------------
Vision time :  85.97894287109375
Action time :  106.45903778076172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048


 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:23<01:21,  4.54s/it][A[A-------------------------------
model running time:  26.2871036529541
-------------------------------
-------------------------------
model running time:  8.446975708007812
-------------------------------
-------------------------------
model running time:  27.837440490722656
-------------------------------
-------------------------------
model running time:  10.506239891052246
-------------------------------
-------------------------------
model running time:  33.43360137939453
-------------------------------
Vision time :  85.88220977783203
Action time :  111.25552368164062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.886720657348633
-------------------------------
-------------------------------
model running time:  8.455167770385742
-------------------------------
-------------------------------
model running time:  32.87859344482422
-------------------------------
-------------------------------
model running time:  10.546175956726074
-------------------------------
-------------------------------
model running time:  27.687936782836914
-------------------------------
Vision time :  85.89116668701172
Action time :  110.68927764892578
Trial 7 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.564512252807617
-------------------------------
-------------------------------
model running time:  8.470527648925781
-------------------------------
-------------------------------
model running time:  27.9050235748291
-------------------------------
-------------------------------
model running time:  10.583040237426758
-------------------------------
-------------------------------
model running time:  27.92438316345215
-------------------------------
Vision time :  85.8569564819336
Action time :  106.39775848388672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.315776824951172
-------------------------------
-------------------------------
model running time:  16.44553565979004
-------------------------------
-------------------------------
model running time:  28.10268783569336
-------------------------------
-------------------------------
model running time:  10.529791831970215
-------------------------------
-------------------------------
model running time:  27.677696228027344
-------------------------------
Vision time :  85.94319915771484
Action time :  113.87789154052734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.876480102539062
-------------------------------
-------------------------------
model running time:  8.440832138061523
-------------------------------
-------------------------------
model running time:  27.787263870239258
-------------------------------
-------------------------------
model running time:  10.488960266113281
-------------------------------
-------------------------------
model running time:  31.99283218383789
-------------------------------
Vision time :  85.89315032958984
Action time :  109.26080322265625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.030080795288086
-------------------------------
-------------------------------
model running time:  8.463359832763672
-------------------------------
-------------------------------
model running time:  27.778047561645508
-------------------------------
-------------------------------
model running time:  10.530816078186035
-------------------------------
-------------------------------
model running time:  27.673599243164062
-------------------------------
Vision time :  85.88489532470703
Action time :  105.27347564697266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89081573486328
-------------------------------
-------------------------------
model running time:  8.472576141357422
-------------------------------
-------------------------------
model running time:  27.72172737121582
-------------------------------
-------------------------------
model running time:  10.576864242553711
-------------------------------
-------------------------------
model running time:  27.617279052734375
-------------------------------
Vision time :  85.8861083984375
Action time :  105.03897857666016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.753599166870117
-------------------------------
-------------------------------
model running time:  8.48588752746582
-------------------------------
-------------------------------
model running time:  32.463775634765625
-------------------------------
-------------------------------
model running time:  10.469375610351562
-------------------------------
-------------------------------
model running time:  27.315135955810547
-------------------------------
Vision time :  85.91260528564453
Action time :  109.34185791015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.75049591064453
-------------------------------
-------------------------------
model running time:  8.41318416595459
-------------------------------
-------------------------------
model running time:  27.503616333007812
-------------------------------
-------------------------------
model running time:  14.943231582641602
-------------------------------
-------------------------------
model running time:  27.3756160736084
-------------------------------
Vision time :  85.8921890258789
Action time :  108.76518249511719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.772031784057617
-------------------------------
-------------------------------
model running time:  8.41215991973877
-------------------------------
-------------------------------
model running time:  27.5599365234375
-------------------------------
-------------------------------
model running time:  10.503199577331543
-------------------------------
-------------------------------
model running time:  27.392000198364258
-------------------------------
Vision time :  85.87017822265625
Action time :  104.31385803222656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.892864227294922
-------------------------------
-------------------------------
model running time:  8.428544044494629
-------------------------------
-------------------------------
model running time:  27.68169593811035
-------------------------------
-------------------------------
model running time:  13.285375595092773
-------------------------------
-------------------------------
model running time:  27.622400283813477
-------------------------------
Vision time :  85.90838623046875
Action time :  107.78009796142578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9051513671875
-------------------------------
-------------------------------
model running time:  15.718303680419922
-------------------------------
-------------------------------
model running time:  27.539615631103516
-------------------------------
-------------------------------
model running time:  10.40998363494873
-------------------------------
-------------------------------
model running time:  27.14726448059082
-------------------------------
Vision time :  85.88601684570312
Action time :  111.37535858154297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.855968475341797
-------------------------------
-------------------------------
model running time:  8.42137622833252
-------------------------------
-------------------------------
model running time:  30.693376541137695
-------------------------------
-------------------------------
model running time:  10.473343849182129
-------------------------------
-------------------------------
model running time:  27.29267120361328
-------------------------------
Vision time :  85.95951843261719
Action time :  107.50563049316406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.71980857849121
-------------------------------
-------------------------------
model running time:  8.398847579956055
-------------------------------
-------------------------------
model running time:  27.598751068115234
-------------------------------
-------------------------------
model running time:  10.424415588378906
-------------------------------
-------------------------------
model running time:  27.493375778198242
-------------------------------
Vision time :  85.88886260986328
Action time :  104.20838165283203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.084287643432617
-------------------------------
-------------------------------
model running time:  8.498175621032715
-------------------------------
-------------------------------
model running time:  27.662336349487305
-------------------------------
-------------------------------
model running time:  10.575872421264648
-------------------------------
-------------------------------
model running time:  27.31110382080078
-------------------------------
Vision time :  85.88304138183594
Action time :  104.8453140258789
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.90105628967285
-------------------------------
-------------------------------
model running time:  8.455167770385742
-------------------------------
-------------------------------
model running time:  30.026752471923828
-------------------------------
-------------------------------
model running time:  10.502143859863281
-------------------------------
-------------------------------
model running time:  27.345855712890625
-------------------------------
Vision time :  85.89266967773438
Action time :  106.95484924316406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.71571159362793
-------------------------------
-------------------------------
model running time:  8.474623680114746
-------------------------------


 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:30<01:29,  5.24s/it][A[A-------------------------------
model running time:  27.6713924407959
-------------------------------
-------------------------------
model running time:  10.518719673156738
-------------------------------
-------------------------------
model running time:  27.389951705932617
-------------------------------
Vision time :  85.89446258544922
Action time :  104.99788665771484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.017791748046875
-------------------------------
-------------------------------
model running time:  8.463359832763672
-------------------------------
-------------------------------
model running time:  27.55379295349121
-------------------------------
-------------------------------
model running time:  10.499072074890137
-------------------------------
-------------------------------
model running time:  31.313919067382812
-------------------------------
Vision time :  85.9172134399414
Action time :  109.22291564941406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.764863967895508
-------------------------------
-------------------------------
model running time:  8.367103576660156
-------------------------------
-------------------------------
model running time:  27.653120040893555
-------------------------------
-------------------------------
model running time:  10.514431953430176
-------------------------------
-------------------------------
model running time:  27.412479400634766
-------------------------------
Vision time :  85.8680648803711
Action time :  104.35481262207031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.075136184692383
-------------------------------
-------------------------------
model running time:  8.442879676818848
-------------------------------
-------------------------------
model running time:  27.48111915588379
-------------------------------
-------------------------------
model running time:  10.464256286621094
-------------------------------
-------------------------------
model running time:  32.7476806640625
-------------------------------
Vision time :  85.89286041259766
Action time :  110.53874969482422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.799680709838867
-------------------------------
-------------------------------
model running time:  8.464320182800293
-------------------------------
-------------------------------
model running time:  29.452287673950195
-------------------------------
-------------------------------
model running time:  10.528767585754395
-------------------------------
-------------------------------
model running time:  27.41971206665039
-------------------------------
Vision time :  85.91718292236328
Action time :  106.96185302734375
Trial 8 finished, success: tensor([True]), steps: 295
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89798355102539
-------------------------------
-------------------------------
model running time:  8.537088394165039
-------------------------------
-------------------------------
model running time:  27.720735549926758
-------------------------------
-------------------------------
model running time:  10.51750373840332
-------------------------------
-------------------------------
model running time:  27.54150390625
-------------------------------
Vision time :  85.91340637207031
Action time :  105.63276672363281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.91231918334961
-------------------------------
-------------------------------
model running time:  8.37939167022705
-------------------------------
-------------------------------
model running time:  27.686912536621094
-------------------------------
-------------------------------
model running time:  10.505215644836426
-------------------------------
-------------------------------
model running time:  27.455488204956055
-------------------------------
Vision time :  85.92658996582031
Action time :  105.06854248046875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.931903839111328
-------------------------------
-------------------------------
model running time:  8.434687614440918
-------------------------------
-------------------------------
model running time:  27.668575286865234
-------------------------------
-------------------------------
model running time:  10.549247741699219
-------------------------------
-------------------------------
model running time:  27.74630355834961
-------------------------------
Vision time :  85.87894439697266
Action time :  105.4228515625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.888736724853516
-------------------------------
-------------------------------
model running time:  8.437760353088379
-------------------------------
-------------------------------
model running time:  30.394367218017578
-------------------------------
-------------------------------
model running time:  10.52467155456543
-------------------------------
-------------------------------
model running time:  27.464704513549805
-------------------------------
Vision time :  85.899169921875
Action time :  108.21321868896484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.71980857849121
-------------------------------
-------------------------------
model running time:  8.38758373260498
-------------------------------
-------------------------------
model running time:  35.46521759033203
-------------------------------
-------------------------------
model running time:  10.473504066467285
-------------------------------
-------------------------------
model running time:  27.258880615234375
-------------------------------
Vision time :  85.8885726928711
Action time :  112.42998504638672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.860095977783203
-------------------------------
-------------------------------
model running time:  8.372223854064941
-------------------------------
-------------------------------
model running time:  27.472896575927734
-------------------------------
-------------------------------
model running time:  10.503168106079102
-------------------------------
-------------------------------
model running time:  30.176223754882812
-------------------------------
Vision time :  85.89132690429688
Action time :  107.62854766845703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.488384246826172
-------------------------------
-------------------------------
model running time:  8.417280197143555
-------------------------------
-------------------------------
model running time:  32.865150451660156
-------------------------------
-------------------------------
model running time:  10.41823959350586
-------------------------------
-------------------------------
model running time:  27.31110382080078
-------------------------------
Vision time :  85.8996810913086
Action time :  109.78304290771484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.753599166870117
-------------------------------
-------------------------------
model running time:  8.387711524963379
-------------------------------
-------------------------------
model running time:  27.373567581176758
-------------------------------
-------------------------------
model running time:  10.482687950134277
-------------------------------
-------------------------------
model running time:  27.198591232299805
-------------------------------
Vision time :  85.86300659179688
Action time :  104.08140563964844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.7073917388916
-------------------------------
-------------------------------
model running time:  8.473600387573242
-------------------------------
-------------------------------
model running time:  27.37868881225586
-------------------------------
-------------------------------
model running time:  10.43558406829834
-------------------------------
-------------------------------
model running time:  31.443967819213867
-------------------------------
Vision time :  85.8763198852539
Action time :  108.04838562011719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.94611167907715
-------------------------------
-------------------------------
model running time:  8.398752212524414
-------------------------------
-------------------------------
model running time:  27.70534324645996
-------------------------------
-------------------------------
model running time:  10.513407707214355
-------------------------------
-------------------------------
model running time:  27.586496353149414
-------------------------------
Vision time :  85.89507293701172
Action time :  105.42694091796875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.588287353515625
-------------------------------
-------------------------------
model running time:  8.568832397460938
-------------------------------
-------------------------------
model running time:  27.489376068115234
-------------------------------
-------------------------------
model running time:  10.580991744995117
-------------------------------
-------------------------------
model running time:  27.421695709228516
-------------------------------
Vision time :  85.99005126953125
Action time :  105.57865905761719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.876480102539062
-------------------------------
-------------------------------
model running time:  8.492032051086426
-------------------------------
-------------------------------
model running time:  27.607040405273438
-------------------------------
-------------------------------
model running time:  10.45299243927002
-------------------------------
-------------------------------
model running time:  31.070207595825195
-------------------------------
Vision time :  85.91667175292969
Action time :  108.87980651855469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.5413761138916
-------------------------------
-------------------------------
model running time:  8.401920318603516
-------------------------------
-------------------------------
model running time:  27.54662322998047
-------------------------------
-------------------------------
model running time:  10.646528244018555
-------------------------------
-------------------------------
model running time:  27.38585662841797
-------------------------------
Vision time :  85.88985443115234
Action time :  108.35750579833984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.09872055053711
-------------------------------
-------------------------------
model running time:  8.393728256225586
-------------------------------
-------------------------------
model running time:  27.662208557128906
-------------------------------
-------------------------------
model running time:  10.437631607055664
-------------------------------
-------------------------------
model running time:  31.58425521850586
-------------------------------
Vision time :  85.96409606933594
Action time :  109.61203002929688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.71878433227539
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  27.57632064819336
-------------------------------
-------------------------------
model running time:  10.537983894348145
-------------------------------
-------------------------------
model running time:  32.93183898925781
-------------------------------
Vision time :  85.90048217773438
Action time :  110.18351745605469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.962495803833008
-------------------------------
-------------------------------
model running time:  8.426400184631348
-------------------------------
-------------------------------
model running time:  27.704256057739258
-------------------------------
-------------------------------
model running time:  10.470399856567383
-------------------------------
-------------------------------
model running time:  27.466751098632812
-------------------------------
Vision time :  85.87535858154297
Action time :  104.6661148071289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.91744041442871
-------------------------------
-------------------------------
model running time:  8.420448303222656
-------------------------------
-------------------------------
model running time:  37.19891357421875
-------------------------------
-------------------------------
model running time:  10.52672004699707
-------------------------------
-------------------------------
model running time:  29.06937599182129
-------------------------------
Vision time :  85.94306945800781
Action time :  116.01203155517578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92972755432129
-------------------------------
-------------------------------
model running time:  8.44480037689209
-------------------------------
-------------------------------
model running time:  27.617279052734375
-------------------------------
-------------------------------
model running time:  21.05548858642578
-------------------------------
-------------------------------
model running time:  27.643903732299805
-------------------------------
Vision time :  85.90509033203125
Action time :  115.31574249267578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.5216007232666
-------------------------------
-------------------------------
model running time:  8.471487998962402
-------------------------------
-------------------------------
model running time:  33.137664794921875
-------------------------------
-------------------------------
model running time:  10.53593635559082
-------------------------------
-------------------------------
model running time:  27.546655654907227
-------------------------------
Vision time :  85.9175033569336
Action time :  111.2063980102539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.819135665893555
-------------------------------
-------------------------------
model running time:  8.407039642333984
-------------------------------
-------------------------------
model running time:  27.36636734008789
-------------------------------
-------------------------------
model running time:  13.96121597290039
-------------------------------
-------------------------------
model running time:  27.236352920532227
-------------------------------
Vision time :  85.90576171875
Action time :  

 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:39<01:42,  6.38s/it][A[A108.05554962158203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.220735549926758
-------------------------------
-------------------------------
model running time:  8.431615829467773
-------------------------------
-------------------------------
model running time:  27.440128326416016
-------------------------------
-------------------------------
model running time:  10.424320220947266
-------------------------------
-------------------------------
model running time:  27.263999938964844
-------------------------------
Vision time :  85.8917465209961
Action time :  110.07488250732422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.858047485351562
-------------------------------
-------------------------------
model running time:  8.501248359680176
-------------------------------
-------------------------------
model running time:  27.36128044128418
-------------------------------
-------------------------------
model running time:  10.460160255432129
-------------------------------
-------------------------------
model running time:  27.216928482055664
-------------------------------
Vision time :  85.89385223388672
Action time :  104.07526397705078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.475135803222656
-------------------------------
-------------------------------
model running time:  8.450048446655273
-------------------------------
-------------------------------
model running time:  27.6396484375
-------------------------------
-------------------------------
model running time:  10.48691177368164
-------------------------------
-------------------------------
model running time:  32.935935974121094
-------------------------------
Vision time :  85.89161682128906
Action time :  116.65315246582031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.82102394104004
-------------------------------
-------------------------------
model running time:  8.460127830505371
-------------------------------
-------------------------------
model running time:  27.489280700683594
-------------------------------
-------------------------------
model running time:  10.568575859069824
-------------------------------
-------------------------------
model running time:  27.291648864746094
-------------------------------
Vision time :  85.8834228515625
Action time :  104.54924774169922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.5231990814209
-------------------------------
-------------------------------
model running time:  8.371199607849121
-------------------------------
-------------------------------
model running time:  27.273183822631836
-------------------------------
-------------------------------
model running time:  10.393600463867188
-------------------------------
-------------------------------
model running time:  27.229183197021484
-------------------------------
Vision time :  85.88015747070312
Action time :  104.27897644042969
Trial 9 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.673728942871094
-------------------------------
-------------------------------
model running time:  8.437760353088379
-------------------------------
-------------------------------
model running time:  28.464128494262695
-------------------------------
-------------------------------
model running time:  10.508288383483887
-------------------------------
-------------------------------
model running time:  27.464704513549805
-------------------------------
Vision time :  85.86259460449219
Action time :  105.2508773803711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.738304138183594
-------------------------------
-------------------------------
model running time:  8.457216262817383
-------------------------------
-------------------------------
model running time:  27.74015998840332
-------------------------------
-------------------------------
model running time:  10.483839988708496
-------------------------------
-------------------------------
model running time:  27.36742401123047
-------------------------------
Vision time :  85.87516784667969
Action time :  104.61695861816406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.667680740356445
-------------------------------
-------------------------------
model running time:  8.375295639038086
-------------------------------
-------------------------------
model running time:  27.30291175842285
-------------------------------
-------------------------------
model running time:  10.508288383483887
-------------------------------
-------------------------------
model running time:  27.33772850036621
-------------------------------
Vision time :  85.90128326416016
Action time :  103.89094543457031
before pruning: 


 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:41<01:15,  5.05s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.798784255981445
-------------------------------
-------------------------------
model running time:  8.42956829071045
-------------------------------
-------------------------------
model running time:  27.570175170898438
-------------------------------
-------------------------------
model running time:  10.500096321105957
-------------------------------
-------------------------------
model running time:  27.37664031982422
-------------------------------
Vision time :  85.91584014892578
Action time :  104.36812591552734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.52217674255371
-------------------------------
-------------------------------
model running time:  8.433664321899414
-------------------------------
-------------------------------
model running time:  33.02204895019531
-------------------------------
-------------------------------
model running time:  10.520575523376465
-------------------------------
-------------------------------
model running time:  27.28447914123535
-------------------------------
Vision time :  85.89817810058594
Action time :  109.54541015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.741247177124023
-------------------------------
-------------------------------
model running time:  8.410207748413086
-------------------------------
-------------------------------
model running time:  27.502592086791992
-------------------------------
-------------------------------
model running time:  14.647295951843262
-------------------------------
-------------------------------
model running time:  27.269119262695312
-------------------------------
Vision time :  85.9000015258789
Action time :  108.2787857055664
Trial 10 finished, success: tensor([True]), steps: 85
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.5600643157959
-------------------------------
-------------------------------
model running time:  8.557567596435547
-------------------------------
-------------------------------
model running time:  27.387903213500977
-------------------------------
-------------------------------
model running time:  10.515520095825195
-------------------------------
-------------------------------
model running time:  27.402240753173828
-------------------------------
Vision time :  85.90563201904297
Action time :  104.0025634765625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.91334342956543
-------------------------------
-------------------------------
model running time:  8.407039642333984
-------------------------------
-------------------------------
model running time:  27.795455932617188
-------------------------------
-------------------------------
model running time:  10.521599769592285
-------------------------------
-------------------------------
model running time:  27.35001564025879
-------------------------------
Vision time :  85.94198608398438
Action time :  104.56787109375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.824256896972656
-------------------------------
-------------------------------
model running time:  14.253952026367188
-------------------------------
-------------------------------
model running time:  28.52249526977539
-------------------------------
-------------------------------
model running time:  10.552191734313965
-------------------------------
-------------------------------
model running time:  27.407360076904297
-------------------------------
Vision time :  85.90156555175781
Action time :  111.51360321044922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.797056198120117
-------------------------------
-------------------------------
model running time:  9.763936042785645
-------------------------------
-------------------------------
model running time:  29.602815628051758
-------------------------------
-------------------------------
model running time:  10.607616424560547
-------------------------------
-------------------------------
model running time:  35.116031646728516
-------------------------------
Vision time :  85.91056060791016
Action time :  117.40160369873047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.74835205078125
-------------------------------
-------------------------------
model running time:  8.450048446655273
-------------------------------
-------------------------------
model running time:  27.476991653442383
-------------------------------
-------------------------------
model running time:  10.440544128417969
-------------------------------
-------------------------------
model running time:  28.399616241455078
-------------------------------
Vision time :  85.9176025390625
Action time :  105.12486267089844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:44<01:02,  4.48s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.008575439453125
-------------------------------
-------------------------------
model running time:  8.463359832763672
-------------------------------
-------------------------------
model running time:  27.53424072265625
-------------------------------
-------------------------------
model running time:  10.461183547973633
-------------------------------
-------------------------------
model running time:  30.619680404663086
-------------------------------
Vision time :  85.92316436767578
Action time :  108.13951873779297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.49951934814453
-------------------------------
-------------------------------
model running time:  8.712191581726074
-------------------------------
-------------------------------
model running time:  28.674047470092773
-------------------------------
-------------------------------
model running time:  11.027456283569336
-------------------------------
-------------------------------
model running time:  28.431360244750977
-------------------------------
Vision time :  85.86614227294922
Action time :  109.5926742553711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.438528060913086
-------------------------------
-------------------------------
model running time:  8.482815742492676
-------------------------------
-------------------------------
model running time:  28.211360931396484
-------------------------------
-------------------------------
model running time:  10.602496147155762
-------------------------------
-------------------------------
model running time:  27.37766456604004
-------------------------------
Vision time :  85.92211151123047
Action time :  108.9085464477539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.754623413085938
-------------------------------
-------------------------------
model running time:  8.452095985412598
-------------------------------
-------------------------------
model running time:  27.55072021484375
-------------------------------
-------------------------------
model running time:  10.512384414672852
-------------------------------
-------------------------------
model running time:  34.98495864868164
-------------------------------
Vision time :  85.87916564941406
Action time :  112.72704315185547
Trial 11 finished, success: tensor([True]), steps: 137
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.529888153076172
-------------------------------
-------------------------------
model running time:  8.436736106872559
-------------------------------
-------------------------------
model running time:  27.620256423950195
-------------------------------
-------------------------------
model running time:  10.501055717468262
-------------------------------
-------------------------------
model running time:  27.398303985595703
-------------------------------
Vision time :  85.8458251953125
Action time :  107.30921936035156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.835519790649414
-------------------------------
-------------------------------
model running time:  8.430527687072754
-------------------------------
-------------------------------
model running time:  29.36115264892578
-------------------------------
-------------------------------
model running time:  10.529664039611816
-------------------------------
-------------------------------
model running time:  27.57414436340332
-------------------------------
Vision time :  85.89033508300781
Action time :  106.41305541992188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.830495834350586
-------------------------------
-------------------------------
model running time:  8.501248359680176
-------------------------------
-------------------------------
model running time:  27.511808395385742
-------------------------------
-------------------------------
model running time:  10.459136009216309
-------------------------------
-------------------------------
model running time:  32.917503356933594
-------------------------------
Vision time :  85.94713592529297
Action time :  110.21517181396484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.89900779724121
-------------------------------
-------------------------------
model running time:  10.226688385009766
-------------------------------
-------------------------------
model running time:  31.18294334411621
-------------------------------
-------------------------------
model running time:  10.497023582458496
-------------------------------
-------------------------------
model running time:  27.33977508544922
-------------------------------
Vision time :  85.90220642089844
Action time :  112.33907318115234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:46<00:47,  3.67s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.647104263305664
-------------------------------
-------------------------------
model running time:  8.440832138061523
-------------------------------
-------------------------------
model running time:  27.55580711364746
-------------------------------
-------------------------------
model running time:  10.635392189025879
-------------------------------
-------------------------------
model running time:  27.35206413269043
-------------------------------
Vision time :  85.90684509277344
Action time :  104.84019470214844
Trial 12 finished, success: tensor([True]), steps: 78
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.70240020751953
-------------------------------
-------------------------------
model running time:  8.456192016601562
-------------------------------
-------------------------------
model running time:  27.615232467651367
-------------------------------
-------------------------------
model running time:  10.646464347839355
-------------------------------
-------------------------------
model running time:  33.25235366821289
-------------------------------
Vision time :  85.87264251708984
Action time :  111.88518524169922
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.815040588378906
-------------------------------
-------------------------------
model running time:  8.471424102783203
-------------------------------
-------------------------------
model running time:  34.92572784423828
-------------------------------
-------------------------------
model running time:  10.491904258728027
-------------------------------
-------------------------------
model running time:  27.426816940307617
-------------------------------
Vision time :  85.90531158447266
Action time :  111.80032348632812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.629695892333984
-------------------------------
-------------------------------
model running time:  8.425600051879883
-------------------------------
-------------------------------
model running time:  27.36947250366211
-------------------------------
-------------------------------
model running time:  10.468352317810059
-------------------------------
-------------------------------
model running time:  27.254783630371094
-------------------------------
Vision time :  85.89676666259766
Action time :  106.1080322265625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.55392074584961
-------------------------------
-------------------------------
model running time:  8.433664321899414
-------------------------------
-------------------------------
model running time:  27.478015899658203
-------------------------------
-------------------------------
model running time:  10.53593635559082
-------------------------------
-------------------------------
model running time:  27.35001564025879
-------------------------------
Vision time :  85.90300750732422
Action time :  103.95238494873047
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.862079620361328
-------------------------------
-------------------------------
model running time:  8.436736106872559
-------------------------------
-------------------------------
model running time:  27.627519607543945
-------------------------------
-------------------------------
model running time:  10.54412841796875
-------------------------------
-------------------------------
model running time:  27.95724868774414
-------------------------------
Vision time :  85.91385650634766
Action time :  105.23955535888672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.745407104492188
-------------------------------
-------------------------------
model running time:  8.497152328491211
-------------------------------
-------------------------------
model running time:  27.78112030029297
-------------------------------
-------------------------------
model running time:  10.769408226013184
-------------------------------
-------------------------------
model running time:  27.846656799316406
-------------------------------
Vision time :  85.89337921142578
Action time :  105.67475128173828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.937536239624023
-------------------------------
-------------------------------
model running time:  8.453120231628418
-------------------------------
-------------------------------
model running time:  27.591583251953125
-------------------------------
-------------------------------
model running time:  10.482848167419434
-------------------------------
-------------------------------
model running time:  27.73196792602539
-------------------------------
Vision time :  85.89139556884766
Action time :  110.8326416015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.038272857666016
-------------------------------
-------------------------------
model running time:  8.645631790161133
-------------------------------
-------------------------------
model running time:  35.9444465637207
-------------------------------
-------------------------------
model running time:  11.281408309936523
-------------------------------
-------------------------------
model running time:  27.53740882873535
-------------------------------
Vision time :  85.88406372070312
Action time :  115.44156646728516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.214527130126953
-------------------------------
-------------------------------
model running time:  8.400896072387695
-------------------------------
-------------------------------
model running time:  32.52531051635742
-------------------------------
-------------------------------
model running time:  10.582015991210938
-------------------------------
-------------------------------
model running time:  27.836416244506836
-------------------------------
Vision time :  85.92607879638672
Action time :  110.45887756347656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  31.244287490844727
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  27.839487075805664
-------------------------------
-------------------------------
model running time:  10.522624015808105
-------------------------------
-------------------------------
model running time:  27.606016159057617
-------------------------------
Vision time :  85.86316680908203
Action time :  111.14495849609375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.77337646484375
-------------------------------
-------------------------------
model running time:  8.51968002319336
-------------------------------
-------------------------------
model running time:  27.7893123626709
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  27.602943420410156
-------------------------------
Vision time :  85.92240142822266
Action time :  109.21676635742188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.979904174804688
-------------------------------
-------------------------------
model running time:  10.595328330993652
-------------------------------
-------------------------------
model running time:  27.896831512451172
-------------------------------
-------------------------------
model running time:  10.574848175048828
-------------------------------
-------------------------------
model running time:  27.677631378173828
-------------------------------
Vision time :  85.90185546875
Action time :  110.09120178222656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.084352493286133
-------------------------------
-------------------------------
model running time:  8.49619197845459
-------------------------------
-------------------------------
model running time:  27.699071884155273
-------------------------------
-------------------------------
model running time:  10.556415557861328
-------------------------------
-------------------------------
model running time:  27.45350456237793
-------------------------------
Vision time :  85.89478302001953
Action time :  105.85302734375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.34934425354004
-------------------------------
-------------------------------
model running time:  8.444928169250488
-------------------------------
-------------------------------
model running time:  27.503616333007812
-------------------------------
-------------------------------
model running time:  10.41100788116455
-------------------------------
-------------------------------
model running time:  27.3940486907959
-------------------------------
Vision time :  85.8812484741211
Action time :  107.89785766601562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.871360778808594
-------------------------------
-------------------------------
model running time:  8.41215991973877
-------------------------------
-------------------------------
model running time:  27.380735397338867
-------------------------------
-------------------------------
model running time:  10.440704345703125
-------------------------------
-------------------------------
model running time:  27.226112365722656
-------------------------------
Vision time :  85.89849853515625
Action time :  104.9384994506836
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.672544479370117
-------------------------------
-------------------------------
model running time:  8.3886079788208
-------------------------------
-------------------------------
model running time:  27.512832641601562
-------------------------------
-------------------------------
model running time:  10.779647827148438
-------------------------------
-------------------------------
model running time:  27.544511795043945
-------------------------------
Vision time :  85.87602996826172
Action time :  105.5805435180664
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.76838493347168
-------------------------------
-------------------------------
model running time:  8.441951751708984
-------------------------------
-------------------------------
model running time:  27.462656021118164
-------------------------------
-------------------------------
model running time:  10.423295974731445
-------------------------------
-------------------------------
model running time:  27.282432556152344
-------------------------------
Vision time :  85.97984313964844
Action time :  105.42899322509766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.022911071777344
-------------------------------
-------------------------------
model running time:  8.476608276367188
-------------------------------
-------------------------------
model running time:  30.058496475219727
-------------------------------
-------------------------------
model running time:  10.469375610351562
-------------------------------
-------------------------------
model running time:  27.496448516845703
-------------------------------
Vision time :  85.89087677001953
Action time :  110.34317016601562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.991008758544922
-------------------------------
-------------------------------
model running time:  8.463359832763672
-------------------------------
-------------------------------
model running time:  27.804672241210938
-------------------------------
-------------------------------
model running time:  10.489855766296387
-------------------------------
-------------------------------
model running time:  27.494400024414062
-------------------------------
Vision time :  85.93353271484375
Action time :  105.47917175292969
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.735584259033203
-------------------------------
-------------------------------
model running time:  8.516608238220215
-------------------------------
-------------------------------
model running time:  27.49849510192871
-------------------------------
-------------------------------
model running time:  10.52467155456543
-------------------------------
-------------------------------
model running time:  27.260927200317383
-------------------------------
Vision time :  85.876220703125
Action time :  105.87238311767578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.678239822387695
-------------------------------
-------------------------------
model running time:  8.499199867248535
-------------------------------
-------------------------------
model running time:  27.561983108520508
-------------------------------
-------------------------------
model running time:  10.432512283325195
-------------------------------
-------------------------------
model running time:  27.420543670654297
-------------------------------
Vision time :  85.93452453613281
Action time :  106.3034896850586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.844608306884766
-------------------------------
-------------------------------
model running time:  8.479743957519531
-------------------------------
-------------------------------
model running time:  27.631616592407227
-------------------------------
-------------------------------
model running time:  10.44985580444336
-------------------------------
-------------------------------
model running time:  27.51795196533203
-------------------------------
Vision time :  85.87286376953125
Action time :  105.60819244384766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.26348876953125
-------------------------------
-------------------------------
model running time:  8.47760009765625
-------------------------------
-------------------------------
model running time:  27.850751876831055
-------------------------------
-------------------------------
model running time:  10.53388786315918
-------------------------------
-------------------------------
model running time:  27.664384841918945
-------------------------------
Vision time :  85.87808227539062
Action time :  106.2933120727539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952


 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:55<01:03,  5.27s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.88159942626953
-------------------------------
-------------------------------
model running time:  8.435711860656738
-------------------------------
-------------------------------
model running time:  34.80883026123047
-------------------------------
-------------------------------
model running time:  10.579968452453613
-------------------------------
-------------------------------
model running time:  27.797504425048828
-------------------------------
Vision time :  85.87395477294922
Action time :  112.8551025390625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.191871643066406
-------------------------------
-------------------------------
model running time:  8.418304443359375
-------------------------------
-------------------------------
model running time:  27.69817543029785
-------------------------------
-------------------------------
model running time:  10.462240219116211
-------------------------------
-------------------------------
model running time:  27.56096076965332
-------------------------------
Vision time :  85.89356994628906
Action time :  105.52422332763672
Trial 13 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.1364803314209
-------------------------------
-------------------------------
model running time:  8.570879936218262
-------------------------------
-------------------------------
model running time:  28.042207717895508
-------------------------------
-------------------------------
model running time:  10.611712455749512
-------------------------------
-------------------------------
model running time:  32.47206497192383
-------------------------------
Vision time :  85.86198425292969
Action time :  110.78860473632812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.267648696899414
-------------------------------
-------------------------------
model running time:  8.539199829101562
-------------------------------
-------------------------------
model running time:  28.246015548706055
-------------------------------
-------------------------------
model running time:  10.562560081481934
-------------------------------
-------------------------------
model running time:  28.050432205200195
-------------------------------
Vision time :  85.87967681884766
Action time :  106.4427490234375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.066944122314453
-------------------------------
-------------------------------
model running time:  8.465408325195312
-------------------------------
-------------------------------
model running time:  27.795616149902344
-------------------------------
-------------------------------
model running time:  10.644576072692871
-------------------------------
-------------------------------
model running time:  33.277950286865234
-------------------------------
Vision time :  85.8839340209961
Action time :  111.22681427001953
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.23369598388672
-------------------------------
-------------------------------
model running time:  8.473600387573242
-------------------------------
-------------------------------
model running time:  34.24460983276367
-------------------------------
-------------------------------
model running time:  10.45299243927002
-------------------------------
-------------------------------
model running time:  27.596736907958984
-------------------------------
Vision time :  85.92515563964844
Action time :  111.67030334472656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.842559814453125
-------------------------------
-------------------------------
model running time:  8.369152069091797
-------------------------------
-------------------------------
model running time:  27.480064392089844
-------------------------------
-------------------------------
model running time:  10.510335922241211
-------------------------------
-------------------------------
model running time:  27.276287078857422
-------------------------------
Vision time :  85.88985443115234
Action time :  104.44595336914062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.826175689697266
-------------------------------
-------------------------------
model running time:  8.398847579956055
-------------------------------
-------------------------------
model running time:  27.458688735961914
-------------------------------
-------------------------------
model running time:  10.447872161865234
-------------------------------
-------------------------------
model running time:  27.32851219177246
-------------------------------
Vision time :  85.89295959472656
Action time :  106.19388580322266
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952


 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:58<00:49,  4.53s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.76896095275879
-------------------------------
-------------------------------
model running time:  8.38758373260498
-------------------------------
-------------------------------
model running time:  34.21184158325195
-------------------------------
-------------------------------
model running time:  10.456064224243164
-------------------------------
-------------------------------
model running time:  27.419584274291992
-------------------------------
Vision time :  85.86921691894531
Action time :  111.42144012451172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.192895889282227
-------------------------------
-------------------------------
model running time:  8.436736106872559
-------------------------------
-------------------------------
model running time:  27.457536697387695
-------------------------------
-------------------------------
model running time:  10.458111763000488
-------------------------------
-------------------------------
model running time:  27.460607528686523
-------------------------------
Vision time :  85.88572692871094
Action time :  106.69261169433594
Trial 14 finished, success: tensor([True]), steps: 115
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.72697639465332
-------------------------------
-------------------------------
model running time:  8.3886079788208
-------------------------------
-------------------------------
model running time:  27.686912536621094
-------------------------------
-------------------------------
model running time:  10.456128120422363
-------------------------------
-------------------------------
model running time:  33.916927337646484
-------------------------------
Vision time :  85.91244506835938
Action time :  110.88582611083984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.831424713134766
-------------------------------
-------------------------------
model running time:  8.393728256225586
-------------------------------
-------------------------------
model running time:  27.693056106567383
-------------------------------
-------------------------------
model running time:  10.491744041442871
-------------------------------
-------------------------------
model running time:  27.38688087463379
-------------------------------
Vision time :  85.92169952392578
Action time :  104.95590209960938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.798656463623047
-------------------------------
-------------------------------
model running time:  8.419327735900879
-------------------------------
-------------------------------
model running time:  27.53638458251953
-------------------------------
-------------------------------
model running time:  10.529791831970215
-------------------------------
-------------------------------
model running time:  27.38262367248535
-------------------------------
Vision time :  85.88444519042969
Action time :  104.31385803222656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.140703201293945
-------------------------------
-------------------------------
model running time:  8.475647926330566
-------------------------------
-------------------------------
model running time:  27.73504066467285
-------------------------------
-------------------------------
model running time:  10.491904258728027
-------------------------------
-------------------------------
model running time:  27.51692771911621
-------------------------------
Vision time :  85.93561553955078
Action time :  105.17193603515625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.845760345458984
-------------------------------
-------------------------------
model running time:  8.41113567352295
-------------------------------
-------------------------------
model running time:  27.588607788085938
-------------------------------
-------------------------------
model running time:  10.52774429321289
-------------------------------
-------------------------------
model running time:  31.80544090270996
-------------------------------
Vision time :  85.88556671142578
Action time :  109.17359924316406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.10793685913086
-------------------------------
-------------------------------
model running time:  15.70201587677002
-------------------------------
-------------------------------
model running time:  27.948928833007812
-------------------------------
-------------------------------
model running time:  10.485759735107422
-------------------------------
-------------------------------
model running time:  27.693056106567383
-------------------------------
Vision time :  85.89913940429688
Action time :  114.08998107910156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952


 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [01:00<00:39,  3.92s/it][A[Astate_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.006528854370117
-------------------------------
-------------------------------
model running time:  8.400896072387695
-------------------------------
-------------------------------
model running time:  33.040382385253906
-------------------------------
-------------------------------
model running time:  10.481663703918457
-------------------------------
-------------------------------
model running time:  27.685888290405273
-------------------------------
Vision time :  85.9137954711914
Action time :  110.58380889892578
Trial 15 finished, success: tensor([True]), steps: 108
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.849599838256836
-------------------------------
-------------------------------
model running time:  8.555520057678223
-------------------------------
-------------------------------
model running time:  28.124160766601562
-------------------------------
-------------------------------
model running time:  10.598400115966797
-------------------------------
-------------------------------
model running time:  27.768831253051758
-------------------------------
Vision time :  85.89657592773438
Action time :  110.13324737548828
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.400800704956055
-------------------------------
-------------------------------
model running time:  8.498175621032715
-------------------------------
-------------------------------
model running time:  27.708415985107422
-------------------------------
-------------------------------
model running time:  10.554368019104004
-------------------------------
-------------------------------
model running time:  27.570175170898438
-------------------------------
Vision time :  85.92230224609375
Action time :  105.59292602539062
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.47452735900879
-------------------------------
-------------------------------
model running time:  8.527872085571289
-------------------------------
-------------------------------
model running time:  28.048383712768555
-------------------------------
-------------------------------
model running time:  10.481663703918457
-------------------------------
-------------------------------
model running time:  32.60927963256836
-------------------------------
Vision time :  85.90509033203125
Action time :  111.47366333007812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.244064331054688
-------------------------------
-------------------------------
model running time:  8.523776054382324
-------------------------------
-------------------------------
model running time:  30.47337532043457
-------------------------------
-------------------------------
model running time:  10.562560081481934
-------------------------------
-------------------------------
model running time:  29.697023391723633
-------------------------------
Vision time :  87.3298568725586
Action time :  110.3021469116211
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.365951538085938
-------------------------------
-------------------------------
model running time:  8.568703651428223
-------------------------------
-------------------------------
model running time:  28.12723159790039
-------------------------------
-------------------------------
model running time:  10.477567672729492
-------------------------------
-------------------------------
model running time:  34.169857025146484
-------------------------------
Vision time :  85.88687896728516
Action time :  112.56114959716797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.2391357421875
-------------------------------
-------------------------------
model running time:  8.467455863952637
-------------------------------
-------------------------------
model running time:  28.261375427246094
-------------------------------
-------------------------------
model running time:  10.519424438476562
-------------------------------
-------------------------------
model running time:  27.92959976196289
-------------------------------
Vision time :  85.88832092285156
Action time :  106.355712890625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.50111961364746
-------------------------------
-------------------------------
model running time:  8.539135932922363
-------------------------------
-------------------------------
model running time:  28.095487594604492
-------------------------------
-------------------------------
model running time:  10.52246379852295
-------------------------------
-------------------------------
model running time:  27.95417594909668
-------------------------------
Vision time :  85.89839935302734
Action time :  106.3219223022461
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.11814308166504
-------------------------------
-------------------------------
model running time:  8.50550365447998
-------------------------------
-------------------------------
model running time:  32.568321228027344
-------------------------------
-------------------------------
model running time:  10.588159561157227
-------------------------------
-------------------------------
model running time:  27.97260856628418
-------------------------------
Vision time :  85.87059020996094
Action time :  110.5827865600586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.27084732055664
-------------------------------
-------------------------------
model running time:  8.429408073425293
-------------------------------
-------------------------------
model running time:  27.985919952392578
-------------------------------
-------------------------------
model running time:  10.508288383483887
-------------------------------
-------------------------------
model running time:  27.83135986328125
-------------------------------
Vision time :  85.88432312011719
Action time :  106.32601928710938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.34796714782715
-------------------------------
-------------------------------
model running time:  12.88697624206543
-------------------------------
-------------------------------
model running time:  28.264448165893555
-------------------------------
-------------------------------
model running time:  10.550271987915039
-------------------------------
-------------------------------
model running time:  33.60960006713867
-------------------------------
Vision time :  85.8911361694336
Action time :  117.54182434082031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.43267250061035
-------------------------------
-------------------------------
model running time:  8.51046371459961
-------------------------------
-------------------------------
model running time:  28.088319778442383
-------------------------------
-------------------------------
model running time:  10.493087768554688
-------------------------------
-------------------------------
model running time:  27.9552001953125
-------------------------------
Vision time :  85.94739532470703
Action time :  106.74073791503906
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.214399337768555
-------------------------------
-------------------------------
model running time:  8.48588752746582
-------------------------------
-------------------------------
model running time:  28.32486343383789
-------------------------------
-------------------------------
model running time:  10.568703651428223
-------------------------------
-------------------------------
model running time:  27.9869441986084
-------------------------------
Vision time :  85.96717071533203
Action time :  107.17491149902344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.378559112548828
-------------------------------
-------------------------------
model running time:  8.488960266113281
-------------------------------
-------------------------------
model running time:  27.967487335205078
-------------------------------
-------------------------------
model running time:  10.488832473754883
-------------------------------
-------------------------------
model running time:  27.893695831298828
-------------------------------
Vision time :  85.87286376953125
Action time :  108.96998596191406
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.65862464904785
-------------------------------
-------------------------------
model running time:  8.462335586547852
-------------------------------
-------------------------------
model running time:  28.169343948364258
-------------------------------
-------------------------------
model running time:  10.55129623413086
-------------------------------
-------------------------------
model running time:  27.884544372558594
-------------------------------
Vision time :  85.9032974243164
Action time :  109.63148498535156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.274751663208008
-------------------------------
-------------------------------
model running time:  8.460288047790527
-------------------------------
-------------------------------
model running time:  28.14975929260254
-------------------------------
-------------------------------
model running time:  10.515456199645996
-------------------------------
-------------------------------
model running time:  27.95929527282715
-------------------------------
Vision time :  85.88604736328125
Action time :  107.09622192382812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.58176040649414
-------------------------------
-------------------------------
model running time:  8.536064147949219
-------------------------------
-------------------------------
model running time:  28.130239486694336
-------------------------------
-------------------------------
model running time:  10.546175956726074
-------------------------------
-------------------------------
model running time:  28.005279541015625
-------------------------------
Vision time :  85.90531158447266
Action time :  111.59552001953125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.35468864440918
-------------------------------
-------------------------------
model running time:  8.459263801574707
-------------------------------
-------------------------------
model running time:  31.839231491088867
-------------------------------
-------------------------------
model running time:  10.522560119628906
-------------------------------
-------------------------------
model running time:  27.995136260986328
-------------------------------
Vision time :  85.93577575683594
Action time :  110.96268463134766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.71820831298828
-------------------------------
-------------------------------
model running time:  8.665087699890137
-------------------------------
-------------------------------
model running time:  28.087295532226562
-------------------------------
-------------------------------
model running time:  10.545151710510254
-------------------------------
-------------------------------
model running time:  28.023807525634766
-------------------------------
Vision time :  85.90265655517578
Action time :  107.25785827636719
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.811391830444336
-------------------------------
-------------------------------
model running time:  8.484736442565918
-------------------------------
-------------------------------
model running time:  27.9050235748291
-------------------------------
-------------------------------
model running time:  10.531840324401855
-------------------------------
-------------------------------
model running time:  27.704320907592773
-------------------------------
Vision time :  85.9164810180664
Action time :  106.56463623046875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.646528244018555
-------------------------------
-------------------------------
model running time:  8.532992362976074
-------------------------------
-------------------------------
model running time:  27.826175689697266
-------------------------------
-------------------------------
model running time:  10.51251220703125
-------------------------------
-------------------------------
model running time:  27.58348846435547
-------------------------------
Vision time :  85.90819549560547
Action time :  106.79500579833984
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.37926483154297
-------------------------------
-------------------------------
model running time:  8.44591999053955
-------------------------------
-------------------------------
model running time:  27.76576042175293
-------------------------------
-------------------------------
model running time:  13.932543754577637
-------------------------------
-------------------------------
model running time:  27.612159729003906
-------------------------------
Vision time :  85.9389419555664
Action time :  112.83660888671875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.90108871459961
-------------------------------
-------------------------------
model running time:  8.40176010131836
-------------------------------
-------------------------------
model running time:  27.685888290405273
-------------------------------
-------------------------------
model running time:  10.519488334655762
-------------------------------
-------------------------------
model running time:  27.642879486083984
-------------------------------
Vision time :  85.90435028076172
Action time :  105.93583679199219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.062271118164062
-------------------------------
-------------------------------
model running time:  8.450176239013672
-------------------------------
-------------------------------
model running time:  27.93881607055664
-------------------------------
-------------------------------
model running time:  10.523712158203125
-------------------------------
-------------------------------
model running time:  27.800575256347656
-------------------------------
Vision time :  85.9137954711914
Action time :  107.19641876220703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.336095809936523
-------------------------------
-------------------------------
model running time:  8.466431617736816
-------------------------------


 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [01:09<00:49,  5.45s/it][A[A-------------------------------
model running time:  28.041215896606445
-------------------------------
-------------------------------
model running time:  10.554368019104004
-------------------------------
-------------------------------
model running time:  27.839584350585938
-------------------------------
Vision time :  85.91693115234375
Action time :  106.89036560058594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.420255661010742
-------------------------------
-------------------------------
model running time:  8.463232040405273
-------------------------------
-------------------------------
model running time:  27.98192024230957
-------------------------------
-------------------------------
model running time:  10.544063568115234
-------------------------------
-------------------------------
model running time:  27.9685115814209
-------------------------------
Vision time :  85.90076446533203
Action time :  106.70591735839844
Trial 16 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.51545524597168
-------------------------------
-------------------------------
model running time:  8.480768203735352
-------------------------------
-------------------------------
model running time:  28.354496002197266
-------------------------------
-------------------------------
model running time:  10.595328330993652
-------------------------------
-------------------------------
model running time:  28.14463996887207
-------------------------------
Vision time :  85.92205047607422
Action time :  107.44525146484375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.52876853942871
-------------------------------
-------------------------------
model running time:  8.457183837890625
-------------------------------
-------------------------------
model running time:  28.34227180480957
-------------------------------
-------------------------------
model running time:  10.691583633422852
-------------------------------
-------------------------------
model running time:  28.049407958984375
-------------------------------
Vision time :  85.90223693847656
Action time :  107.70416259765625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.5031681060791
-------------------------------
-------------------------------
model running time:  8.454143524169922
-------------------------------
-------------------------------
model running time:  27.99510383605957
-------------------------------
-------------------------------
model running time:  10.541055679321289
-------------------------------
-------------------------------
model running time:  27.944927215576172
-------------------------------
Vision time :  85.9283218383789
Action time :  106.30963134765625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.33216094970703
-------------------------------
-------------------------------
model running time:  8.464415550231934
-------------------------------
-------------------------------
model running time:  27.96339225769043
-------------------------------
-------------------------------
model running time:  10.563584327697754
-------------------------------
-------------------------------
model running time:  27.809791564941406
-------------------------------
Vision time :  85.89459228515625
Action time :  106.25433349609375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.609792709350586
-------------------------------
-------------------------------
model running time:  8.577024459838867
-------------------------------
-------------------------------
model running time:  28.056575775146484
-------------------------------
-------------------------------
model running time:  10.537983894348145
-------------------------------
-------------------------------
model running time:  27.95827293395996
-------------------------------
Vision time :  85.91734313964844
Action time :  106.78272247314453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.307584762573242
-------------------------------
-------------------------------
model running time:  8.451071739196777
-------------------------------
-------------------------------
model running time:  27.909120559692383
-------------------------------
-------------------------------
model running time:  10.53286361694336
-------------------------------
-------------------------------
model running time:  27.863040924072266
-------------------------------
Vision time :  85.8834228515625
Action time :  105.91222381591797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.256223678588867
-------------------------------
-------------------------------
model running time:  8.448896408081055
-------------------------------
-------------------------------
model running time:  

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [01:12<00:36,  4.57s/it][A[A27.94380760192871
-------------------------------
-------------------------------
model running time:  10.590208053588867
-------------------------------
-------------------------------
model running time:  27.984928131103516
-------------------------------
Vision time :  85.89888000488281
Action time :  106.39769744873047
Trial 17 finished, success: tensor([True]), steps: 111
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.422271728515625
-------------------------------
-------------------------------
model running time:  8.470527648925781
-------------------------------
-------------------------------
model running time:  27.994112014770508
-------------------------------
-------------------------------
model running time:  10.505375862121582
-------------------------------
-------------------------------
model running time:  27.810976028442383
-------------------------------
Vision time :  85.86627197265625
Action time :  106.1048355102539
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.29529571533203
-------------------------------
-------------------------------
model running time:  8.388671875
-------------------------------
-------------------------------
model running time:  27.909215927124023
-------------------------------
-------------------------------
model running time:  10.507391929626465
-------------------------------
-------------------------------
model running time:  27.779071807861328
-------------------------------
Vision time :  85.9142074584961
Action time :  105.8314208984375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.218496322631836
-------------------------------
-------------------------------
model running time:  8.41209602355957
-------------------------------
-------------------------------
model running time:  27.839487075805664
-------------------------------
-------------------------------
model running time:  10.45081615447998
-------------------------------
-------------------------------
model running time:  27.810815811157227
-------------------------------
Vision time :  85.89065551757812
Action time :  105.8529281616211
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.617855072021484
-------------------------------
-------------------------------
model running time:  8.498047828674316
-------------------------------
-------------------------------
model running time:  28.104703903198242
-------------------------------
-------------------------------
model running time:  10.498047828674316
-------------------------------
-------------------------------
model running time:  27.945119857788086
-------------------------------
Vision time :  85.90035247802734
Action time :  106.73868560791016
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.596351623535156
-------------------------------
-------------------------------
model running time:  8.467552185058594
-------------------------------
-------------------------------
model running time:  28.001279830932617
-------------------------------
-------------------------------
model running time:  10.568703651428223
-------------------------------
-------------------------------
model running time:  27.870208740234375
-------------------------------
Vision time :  85.90182495117188
Action time :  107.32134246826172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.161151885986328
-------------------------------
-------------------------------
model running time:  8.432640075683594
-------------------------------
-------------------------------
model running time:  27.864063262939453
-------------------------------
-------------------------------
model running time:  10.499072074890137
-------------------------------
-------------------------------
model running time:  27.839487075805664
-------------------------------
Vision time :  85.91830444335938
Action time :  106.33932495117188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.616832733154297
-------------------------------
-------------------------------
model running time:  8.465408325195312
-------------------------------
-------------------------------
model running time:  27.96544075012207
-------------------------------
-------------------------------
model running time:  10.520607948303223
-------------------------------
-------------------------------
model running time:  27.90825653076172
-------------------------------
Vision time :  85.87715148925781
Action time :  106.6270751953125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.630144119262695
-------------------------------
-------------------------------
model running time:  8.466431617736816
-------------------------------
-------------------------------
model running time:  28.174335479736328
-------------------------------


 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [01:17<00:33,  4.82s/it][A[A-------------------------------
model running time:  10.500096321105957
-------------------------------
-------------------------------
model running time:  27.9552001953125
-------------------------------
Vision time :  85.87709045410156
Action time :  107.97977447509766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.711488723754883
-------------------------------
-------------------------------
model running time:  8.451071739196777
-------------------------------
-------------------------------
model running time:  28.082176208496094
-------------------------------
-------------------------------
model running time:  10.564607620239258
-------------------------------
-------------------------------
model running time:  27.96339225769043
-------------------------------
Vision time :  85.96880340576172
Action time :  107.7043228149414
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.832895278930664
-------------------------------
-------------------------------
model running time:  8.507391929626465
-------------------------------
-------------------------------
model running time:  28.051456451416016
-------------------------------
-------------------------------
model running time:  10.592127799987793
-------------------------------
-------------------------------
model running time:  27.95110321044922
-------------------------------
Vision time :  85.89324951171875
Action time :  107.38995361328125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.798080444335938
-------------------------------
-------------------------------
model running time:  8.491007804870605
-------------------------------
-------------------------------
model running time:  27.91423988342285
-------------------------------
-------------------------------
model running time:  10.469375610351562
-------------------------------
-------------------------------
model running time:  27.73619270324707
-------------------------------
Vision time :  85.94662475585938
Action time :  106.26252746582031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.13759994506836
-------------------------------
-------------------------------
model running time:  8.456192016601562
-------------------------------
-------------------------------
model running time:  27.92140769958496
-------------------------------
-------------------------------
model running time:  10.487872123718262
-------------------------------
-------------------------------
model running time:  27.864063262939453
-------------------------------
Vision time :  85.9168930053711
Action time :  106.32921600341797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.239999771118164
-------------------------------
-------------------------------
model running time:  8.425344467163086
-------------------------------
-------------------------------
model running time:  27.95724868774414
-------------------------------
-------------------------------
model running time:  10.510335922241211
-------------------------------
-------------------------------
model running time:  27.825151443481445
-------------------------------
Vision time :  85.8868179321289
Action time :  106.34239959716797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.142719268798828
-------------------------------
-------------------------------
model running time:  8.405119895935059
-------------------------------
-------------------------------
model running time:  28.725248336791992
-------------------------------
-------------------------------
model running time:  10.484576225280762
-------------------------------
-------------------------------
model running time:  27.880447387695312
-------------------------------
Vision time :  85.87884521484375
Action time :  107.44012451171875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.194944381713867
-------------------------------
-------------------------------
model running time:  8.435647964477539
-------------------------------
-------------------------------
model running time:  27.860992431640625
-------------------------------
-------------------------------
model running time:  10.498047828674316
-------------------------------
-------------------------------
model running time:  27.878400802612305
-------------------------------
Vision time :  85.87113952636719
Action time :  106.4744644165039
Trial 18 finished, success: tensor([True]), steps: 232
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.504192352294922
-------------------------------
-------------------------------
model running time:  8.554495811462402
-------------------------------
-------------------------------
model running time:  28.055583953857422
-------------------------------
-------------------------------
model running time:  

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [01:19<00:24,  4.01s/it][A[A10.629119873046875
-------------------------------
-------------------------------
model running time:  28.051456451416016
-------------------------------
Vision time :  85.90991973876953
Action time :  106.73165130615234
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.412031173706055
-------------------------------
-------------------------------
model running time:  8.443903923034668
-------------------------------
-------------------------------
model running time:  28.106752395629883
-------------------------------
-------------------------------
model running time:  10.552319526672363
-------------------------------
-------------------------------
model running time:  27.883520126342773
-------------------------------
Vision time :  85.90672302246094
Action time :  106.18486022949219
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.4847354888916
-------------------------------
-------------------------------
model running time:  8.524800300598145
-------------------------------
-------------------------------
model running time:  28.10163116455078
-------------------------------
-------------------------------
model running time:  10.578975677490234
-------------------------------
-------------------------------
model running time:  27.99616050720215
-------------------------------
Vision time :  85.91986846923828
Action time :  106.51136016845703
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.364927291870117
-------------------------------
-------------------------------
model running time:  8.445952415466309
-------------------------------
-------------------------------
model running time:  27.98899269104004
-------------------------------
-------------------------------
model running time:  10.522624015808105
-------------------------------
-------------------------------
model running time:  27.859968185424805
-------------------------------
Vision time :  85.90547180175781
Action time :  105.87750244140625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.265504837036133
-------------------------------
-------------------------------
model running time:  8.401920318603516
-------------------------------
-------------------------------
model running time:  27.908063888549805
-------------------------------
-------------------------------
model running time:  10.530816078186035
-------------------------------
-------------------------------
model running time:  27.991039276123047
-------------------------------
Vision time :  85.94076538085938
Action time :  105.85804748535156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.505216598510742
-------------------------------
-------------------------------
model running time:  8.468480110168457
-------------------------------
-------------------------------
model running time:  28.02079963684082
-------------------------------
-------------------------------
model running time:  10.566656112670898
-------------------------------
-------------------------------
model running time:  27.864063262939453
-------------------------------
Vision time :  85.90099334716797
Action time :  106.17459106445312
Trial 19 finished, success: tensor([True]), steps: 89
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.797056198120117
-------------------------------
-------------------------------
model running time:  8.487936019897461
-------------------------------
-------------------------------
model running time:  28.15692710876465
-------------------------------
-------------------------------
model running time:  10.585087776184082
-------------------------------
-------------------------------
model running time:  28.003328323364258
-------------------------------
Vision time :  85.89900970458984
Action time :  106.96089935302734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  30.60736083984375
-------------------------------
-------------------------------
model running time:  8.467455863952637
-------------------------------
-------------------------------
model running time:  28.314624786376953
-------------------------------
-------------------------------
model running time:  10.541055679321289
-------------------------------
-------------------------------
model running time:  28.137344360351562
-------------------------------
Vision time :  85.90419006347656
Action time :  110.85529327392578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.663936614990234
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  28.071935653686523
-------------------------------
-------------------------------
model running time:  11.359231948852539
-------------------------------
-------------------------------
model running time:  27.887615203857422
-------------------------------
Vision time :  85.92390441894531
Action time :  107.36128234863281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.780672073364258
-------------------------------
-------------------------------
model running time:  8.515583992004395
-------------------------------
-------------------------------
model running time:  32.41984176635742
-------------------------------
-------------------------------
model running time:  10.604543685913086
-------------------------------
-------------------------------
model running time:  27.97056007385254
-------------------------------
Vision time :  85.94278717041016
Action time :  111.21868896484375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.363935470581055
-------------------------------
-------------------------------
model running time:  8.497152328491211
-------------------------------
-------------------------------
model running time:  28.003328323364258
-------------------------------
-------------------------------
model running time:  10.514431953430176
-------------------------------
-------------------------------
model running time:  27.893823623657227
-------------------------------
Vision time :  85.91788482666016
Action time :  106.04134368896484
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.29631996154785
-------------------------------
-------------------------------
model running time:  8.438783645629883
-------------------------------
-------------------------------
model running time:  27.926368713378906
-------------------------------
-------------------------------
model running time:  10.486783981323242
-------------------------------
-------------------------------
model running time:  27.874303817749023
-------------------------------
Vision time :  85.89491271972656
Action time :  105.69821166992188
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.93734359741211
-------------------------------
-------------------------------
model running time:  8.438783645629883
-------------------------------
-------------------------------
model running time:  27.96428871154785
-------------------------------
-------------------------------
model running time:  10.548224449157715
-------------------------------
-------------------------------
model running time:  27.96236801147461
-------------------------------
Vision time :  85.89289855957031
Action time :  106.57587432861328
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.59833526611328
-------------------------------
-------------------------------
model running time:  8.467455863952637
-------------------------------
-------------------------------
model running time:  27.915264129638672
-------------------------------
-------------------------------
model running time:  14.268416404724121
-------------------------------
-------------------------------
model running time:  27.95404815673828
-------------------------------
Vision time :  85.90022277832031
Action time :  110.06873321533203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.138656616210938
-------------------------------
-------------------------------
model running time:  8.484864234924316
-------------------------------
-------------------------------
model running time:  34.06131362915039
-------------------------------
-------------------------------
model running time:  10.501119613647461
-------------------------------
-------------------------------
model running time:  28.057600021362305
-------------------------------
Vision time :  85.87551879882812
Action time :  111.97235107421875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.31782341003418
-------------------------------
-------------------------------
model running time:  8.45299243927002
-------------------------------
-------------------------------
model running time:  39.188480377197266
-------------------------------
-------------------------------
model running time:  10.546175956726074
-------------------------------
-------------------------------
model running time:  27.9234561920166
-------------------------------
Vision time :  85.86873626708984
Action time :  118.2208023071289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.471296310424805
-------------------------------
-------------------------------
model running time:  8.539135932922363
-------------------------------
-------------------------------
model running time:  28.112895965576172
-------------------------------
-------------------------------
model running time:  10.57084846496582
-------------------------------
-------------------------------
model running time:  28.99247932434082
-------------------------------
Vision time :  85.92765045166016
Action time :  110.13938903808594
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  29.458431243896484
-------------------------------
-------------------------------
model running time:  8.475647926330566
-------------------------------
-------------------------------
model running time:  28.054527282714844
-------------------------------
-------------------------------
model running time:  10.533760070800781
-------------------------------
-------------------------------
model running time:  27.820032119750977
-------------------------------
Vision time :  85.90767669677734
Action time :  109.25558471679688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.600448608398438
-------------------------------
-------------------------------
model running time:  8.517631530761719
-------------------------------
-------------------------------
model running time:  28.220415115356445
-------------------------------
-------------------------------
model running time:  10.554368019104004
-------------------------------
-------------------------------
model running time:  31.252479553222656
-------------------------------
Vision time :  85.9488296508789
Action time :  110.00822448730469
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.464704513549805
-------------------------------
-------------------------------
model running time:  8.476672172546387
-------------------------------
-------------------------------
model running time:  28.080127716064453
-------------------------------
-------------------------------
model running time:  10.507328033447266
-------------------------------
-------------------------------
model running time:  27.845632553100586
-------------------------------
Vision time :  85.91951751708984
Action time :  107.3602523803711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.7007999420166
-------------------------------
-------------------------------
model running time:  8.441823959350586
-------------------------------
-------------------------------
model running time:  32.861183166503906
-------------------------------
-------------------------------
model running time:  10.508288383483887
-------------------------------
-------------------------------
model running time:  27.936767578125
-------------------------------
Vision time :  85.91983795166016
Action time :  112.41574096679688
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.688480377197266
-------------------------------
-------------------------------
model running time:  8.458239555358887
-------------------------------
-------------------------------
model running time:  28.063743591308594
-------------------------------
-------------------------------
model running time:  10.528767585754395
-------------------------------
-------------------------------
model running time:  27.9552001953125
-------------------------------
Vision time :  85.92630767822266
Action time :  107.6131820678711
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.69977569580078
-------------------------------
-------------------------------
model running time:  8.548352241516113
-------------------------------
-------------------------------
model running time:  28.00035285949707
-------------------------------
-------------------------------
model running time:  10.57372760772705
-------------------------------
-------------------------------
model running time:  27.858943939208984
-------------------------------
Vision time :  85.94306945800781
Action time :  106.79596710205078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.769311904907227
-------------------------------
-------------------------------
model running time:  8.466431617736816
-------------------------------
-------------------------------
model running time:  28.105728149414062
-------------------------------
-------------------------------
model running time:  10.487808227539062
-------------------------------
-------------------------------
model running time:  27.889663696289062
-------------------------------
Vision time :  85.95053100585938
Action time :  107.169921875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.36796760559082
-------------------------------
-------------------------------
model running time:  8.430591583251953
-------------------------------
-------------------------------
model running time:  28.14259147644043
-------------------------------
-------------------------------
model running time:  10.511360168457031
-------------------------------
-------------------------------
model running time:  27.94905662536621
-------------------------------
Vision time :  85.89142608642578
Action time :  106.27670288085938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440


 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [01:28<00:27,  5.52s/it][A[Aimg_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.674175262451172
-------------------------------
-------------------------------
model running time:  8.450048446655273
-------------------------------
-------------------------------
model running time:  28.087295532226562
-------------------------------
-------------------------------
model running time:  10.518655776977539
-------------------------------
-------------------------------
model running time:  27.672576904296875
-------------------------------
Vision time :  85.90412902832031
Action time :  107.64492797851562
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.3239688873291
-------------------------------
-------------------------------
model running time:  8.467455863952637
-------------------------------
-------------------------------
model running time:  28.056543350219727
-------------------------------
-------------------------------
model running time:  10.549247741699219
-------------------------------
-------------------------------
model running time:  27.665407180786133
-------------------------------
Vision time :  85.91014099121094
Action time :  106.23693084716797
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.402816772460938
-------------------------------
-------------------------------
model running time:  8.39475154876709
-------------------------------
-------------------------------
model running time:  28.006399154663086
-------------------------------
-------------------------------
model running time:  10.483839988708496
-------------------------------
-------------------------------
model running time:  27.87433624267578
-------------------------------
Vision time :  85.8985595703125
Action time :  106.27276611328125
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.09766387939453
-------------------------------
-------------------------------
model running time:  8.444928169250488
-------------------------------
-------------------------------
model running time:  34.05414581298828
-------------------------------
-------------------------------
model running time:  10.465279579162598
-------------------------------
-------------------------------
model running time:  27.932575225830078
-------------------------------
Vision time :  85.87276458740234
Action time :  112.80178833007812
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92870330810547
-------------------------------
-------------------------------
model running time:  8.447104454040527
-------------------------------
-------------------------------
model running time:  27.835391998291016
-------------------------------
-------------------------------
model running time:  10.472448348999023
-------------------------------
-------------------------------
model running time:  32.61548614501953
-------------------------------
Vision time :  85.86908721923828
Action time :  110.2561264038086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.181631088256836
-------------------------------
-------------------------------
model running time:  11.246591567993164
-------------------------------
-------------------------------
model running time:  30.240768432617188
-------------------------------
-------------------------------
model running time:  10.511360168457031
-------------------------------
-------------------------------
model running time:  27.844608306884766
-------------------------------
Vision time :  85.8496322631836
Action time :  115.02591705322266
Trial 20 finished, success: tensor([False]), steps: 400
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.221567153930664
-------------------------------
-------------------------------
model running time:  8.48588752746582
-------------------------------
-------------------------------
model running time:  28.082176208496094
-------------------------------
-------------------------------
model running time:  10.630144119262695
-------------------------------
-------------------------------
model running time:  31.832063674926758
-------------------------------
Vision time :  85.87999725341797
Action time :  110.44662475585938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.1713924407959
-------------------------------
-------------------------------
model running time:  8.49612808227539
-------------------------------
-------------------------------
model running time:  29.2096004486084
-------------------------------
-------------------------------
model running time:  10.503168106079102
-------------------------------
-------------------------------
model running time:  27.94598388671875
-------------------------------
Vision time :  85.91567993164062
Action time :  107.47596740722656
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  27.108352661132812
-------------------------------
-------------------------------
model running time:  10.886143684387207
-------------------------------
-------------------------------
model running time:  28.089344024658203
-------------------------------
-------------------------------
model running time:  10.507264137268066
-------------------------------
-------------------------------
model running time:  27.870208740234375
-------------------------------
Vision time :  85.88050842285156
Action time :  111.82284545898438
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.298240661621094
-------------------------------
-------------------------------
model running time:  8.463423728942871
-------------------------------
-------------------------------
model running time:  28.009471893310547
-------------------------------
-------------------------------
model running time:  10.489855766296387
-------------------------------
-------------------------------
model running time:  27.858943939208984
-------------------------------
Vision time :  85.9211196899414
Action time :  108.02381134033203
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.349567413330078
-------------------------------
-------------------------------
model running time:  8.457216262817383
-------------------------------
-------------------------------
model running time:  28.025760650634766
-------------------------------
-------------------------------
model running time:  10.577919960021973
-------------------------------
-------------------------------
model running time:  27.9899845123291
-------------------------------
Vision time :  85.89686584472656
Action time :  107.24658966064453
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.55743980407715
-------------------------------
-------------------------------
model running time:  8.482815742492676
-------------------------------
-------------------------------
model running time:  27.95827293395996
-------------------------------
-------------------------------
model running time:  10.501119613647461
-------------------------------
-------------------------------
model running time:  27.79033660888672
-------------------------------
Vision time :  85.9040298461914
Action time :  112.78950500488281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.50115203857422
-------------------------------
-------------------------------
model running time:  8.461312294006348
-------------------------------
-------------------------------
model running time:  28.033151626586914
-------------------------------
-------------------------------
model running time:  10.471424102783203
-------------------------------
-------------------------------
model running time:  27.816959381103516
-------------------------------
Vision time :  85.94102478027344
Action time :  106.61068725585938
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.51545524597168
-------------------------------
-------------------------------
model running time:  8.42240047454834
-------------------------------
-------------------------------
model running time:  28.024831771850586
-------------------------------
-------------------------------
model running time:  10.516480445861816
-------------------------------
-------------------------------
model running time:  27.92959976196289
-------------------------------
Vision time :  85.90911865234375
Action time :  107.30290985107422
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  28.255231857299805
-------------------------------
-------------------------------
model running time:  8.525888442993164
-------------------------------
-------------------------------
model running time:  27.97158432006836
-------------------------------
-------------------------------
model running time:  10.563520431518555
-------------------------------
-------------------------------
model running time:  27.825151443481445
-------------------------------
Vision time :  85.91251373291016
Action time :  109.12870025634766
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.15705680847168
-------------------------------
-------------------------------
model running time:  8.457216262817383
-------------------------------
-------------------------------
model running time:  30.01036834716797
-------------------------------
-------------------------------
model running time:  10.560511589050293
-------------------------------
-------------------------------
model running time:  27.816959381103516
-------------------------------
Vision time :  85.87334442138672
Action time :  107.82828521728516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 


 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [01:34<00:22,  5.59s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  32.52431869506836
-------------------------------
-------------------------------
model running time:  8.466431617736816
-------------------------------
-------------------------------
model running time:  27.97875213623047
-------------------------------
-------------------------------
model running time:  10.482784271240234
-------------------------------
-------------------------------
model running time:  27.749343872070312
-------------------------------
Vision time :  85.89177703857422
Action time :  112.01744079589844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.166271209716797
-------------------------------
-------------------------------
model running time:  8.436736106872559
-------------------------------
-------------------------------
model running time:  28.96076774597168
-------------------------------
-------------------------------
model running time:  10.513407707214355
-------------------------------
-------------------------------
model running time:  27.877376556396484
-------------------------------
Vision time :  87.2778549194336
Action time :  107.40838623046875
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.33318328857422
-------------------------------
-------------------------------
model running time:  12.164095878601074
-------------------------------
-------------------------------
model running time:  28.15385627746582
-------------------------------
-------------------------------
model running time:  10.614784240722656
-------------------------------
-------------------------------
model running time:  28.032032012939453
-------------------------------
Vision time :  85.88873291015625
Action time :  110.22032165527344
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.34444808959961
-------------------------------
-------------------------------
model running time:  8.48588752746582
-------------------------------
-------------------------------
model running time:  27.94291114807129
-------------------------------
-------------------------------
model running time:  10.484736442565918
-------------------------------
-------------------------------
model running time:  27.635711669921875
-------------------------------
Vision time :  85.9052505493164
Action time :  105.67779541015625
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.060800552368164
-------------------------------
-------------------------------
model running time:  8.473600387573242
-------------------------------
-------------------------------
model running time:  27.999231338500977
-------------------------------
-------------------------------
model running time:  10.561408042907715
-------------------------------
-------------------------------
model running time:  27.788288116455078
-------------------------------
Vision time :  85.87814331054688
Action time :  106.1602554321289
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.315776824951172
-------------------------------
-------------------------------
model running time:  8.435711860656738
-------------------------------
-------------------------------
model running time:  31.648767471313477
-------------------------------
-------------------------------
model running time:  10.531840324401855
-------------------------------
-------------------------------
model running time:  27.891712188720703
-------------------------------
Vision time :  85.92684936523438
Action time :  110.11788940429688
Trial 21 finished, success: tensor([True]), steps: 255
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.107999801635742
-------------------------------
-------------------------------
model running time:  8.48691177368164
-------------------------------
-------------------------------
model running time:  28.433408737182617
-------------------------------
-------------------------------
model running time:  10.926048278808594
-------------------------------
-------------------------------
model running time:  27.694080352783203
-------------------------------
Vision time :  85.9115219116211
Action time :  106.55846405029297
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.54003143310547
-------------------------------
-------------------------------
model running time:  8.675328254699707
-------------------------------
-------------------------------
model running time:  28.17638397216797
-------------------------------
-------------------------------
model running time:  10.52467155456543
-------------------------------
-------------------------------
model running time:  27.43824005126953
-------------------------------
Vision time :  85.92310333251953
Action time :  106.4427490234375
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 


 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [01:37<00:14,  4.88s/it][A[Alang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.754655838012695
-------------------------------
-------------------------------
model running time:  8.515583992004395
-------------------------------
-------------------------------
model running time:  27.76473617553711
-------------------------------
-------------------------------
model running time:  10.492927551269531
-------------------------------
-------------------------------
model running time:  28.14156723022461
-------------------------------
Vision time :  85.94278717041016
Action time :  106.1242904663086
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.910175323486328
-------------------------------
-------------------------------
model running time:  8.390751838684082
-------------------------------
-------------------------------
model running time:  27.6582088470459
-------------------------------
-------------------------------
model running time:  10.488896369934082
-------------------------------
-------------------------------
model running time:  35.47340774536133
-------------------------------
Vision time :  85.86713409423828
Action time :  112.55500793457031
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.036224365234375
-------------------------------
-------------------------------
model running time:  8.488960266113281
-------------------------------
-------------------------------
model running time:  27.70636749267578
-------------------------------
-------------------------------
model running time:  10.796031951904297
-------------------------------
-------------------------------
model running time:  27.631616592407227
-------------------------------
Vision time :  85.94332885742188
Action time :  105.32966613769531
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  26.456064224243164
-------------------------------
-------------------------------
model running time:  8.691712379455566
-------------------------------
-------------------------------
model running time:  32.82112121582031
-------------------------------
-------------------------------
model running time:  10.548224449157715
-------------------------------
-------------------------------
model running time:  27.521024703979492
-------------------------------
Vision time :  85.8614730834961
Action time :  110.98726654052734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.620576858520508
-------------------------------
-------------------------------
model running time:  8.39782428741455
-------------------------------
-------------------------------
model running time:  27.623424530029297
-------------------------------
-------------------------------
model running time:  10.463359832763672
-------------------------------
-------------------------------
model running time:  28.485631942749023
-------------------------------
Vision time :  85.90902709960938
Action time :  105.4382095336914
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.775999069213867
-------------------------------
-------------------------------
model running time:  8.530943870544434
-------------------------------
-------------------------------
model running time:  27.671552658081055
-------------------------------
-------------------------------
model running time:  10.425344467163086
-------------------------------
-------------------------------
model running time:  34.905025482177734
-------------------------------
Vision time :  85.88690948486328
Action time :  111.89043426513672
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.74233627319336
-------------------------------
-------------------------------
model running time:  8.42240047454834
-------------------------------
-------------------------------
model running time:  27.61337661743164
-------------------------------
-------------------------------
model running time:  15.991904258728027
-------------------------------
-------------------------------
model running time:  27.5732479095459
-------------------------------
Vision time :  85.92144012451172
Action time :  110.0031967163086
Trial 22 finished, success: tensor([True]), steps: 134
policy.alpha = 1.0policy.temp = 0.01
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  33.015968322753906
-------------------------------
-------------------------------
model running time:  8.59443187713623
-------------------------------
-------------------------------
model running time:  27.96441650390625
-------------------------------
-------------------------------
model running time:  10.60863971710205
-------------------------------
-------------------------------
model running time:  28.95974349975586
-------------------------------
Vision time :  85.89033508300781
Action time :  113.89955139160156
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.92460823059082
-------------------------------
-------------------------------
model running time:  8.51148796081543
-------------------------------
-------------------------------
model running time:  27.458560943603516
-------------------------------
-------------------------------
model running time:  10.558464050292969
-------------------------------
-------------------------------
model running time:  30.328832626342773
-------------------------------
Vision time :  85.9086685180664
Action time :  108.07603454589844
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.847808837890625
-------------------------------
-------------------------------
model running time:  8.471551895141602
-------------------------------
-------------------------------
model running time:  27.34182357788086
-------------------------------
-------------------------------
model running time:  10.550271987915039
-------------------------------
-------------------------------
model running time:  27.290624618530273
-------------------------------
Vision time :  85.90108489990234
Action time :  104.55757141113281
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.77289581298828
-------------------------------
-------------------------------
model running time:  8.41420841217041
-------------------------------
-------------------------------
model running time:  27.30588722229004
-------------------------------
-------------------------------
model running time:  10.513407707214355
-------------------------------
-------------------------------
model running time:  28.697599411010742
-------------------------------
Vision time :  85.87068939208984
Action time :  108.26236724853516
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.9553279876709
-------------------------------
-------------------------------
model running time:  8.489983558654785
-------------------------------
-------------------------------
model running time:  28.909568786621094
-------------------------------
-------------------------------
model running time:  10.611712455749512
-------------------------------
-------------------------------
model running time:  27.55174446105957
-------------------------------
Vision time :  85.89635467529297
Action time :  106.9148178100586
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.835519790649414
-------------------------------
-------------------------------
model running time:  8.469504356384277
-------------------------------
-------------------------------
model running time:  33.40492630004883
-------------------------------
-------------------------------
model running time:  10.575872421264648
-------------------------------
-------------------------------
model running time:  27.446304321289062
-------------------------------
Vision time :  85.8721923828125
Action time :  110.58380889892578
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.774080276489258
-------------------------------
-------------------------------
model running time:  8.462240219116211
-------------------------------
-------------------------------
model running time:  27.53843116760254
-------------------------------
-------------------------------
model running time:  10.52569580078125
-------------------------------
-------------------------------
model running time:  27.388927459716797
-------------------------------
Vision time :  85.90662384033203
Action time :  104.80025482177734
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.925504684448242
-------------------------------
-------------------------------
model running time:  8.668160438537598
-------------------------------
-------------------------------
model running time:  27.65203285217285
-------------------------------
-------------------------------
model running time:  10.636287689208984
-------------------------------
-------------------------------
model running time:  27.625471115112305
-------------------------------
Vision time :  85.89405059814453
Action time :  105.90924835205078
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
-------------------------------
model running time:  25.811967849731445
-------------------------------
-------------------------------
model running time:  8.491007804870605
-------------------------------
-------------------------------
model running time:  27.608064651489258
-------------------------------
-------------------------------
model running time:  10.613759994506836
-------------------------------
-------------------------------
model running time:  27.650144577026367
-------------------------------
Vision time :  85.88105773925781
Action time :  105.65337371826172
before pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
after pruning: 
lang_cond:  shape=torch.Size([1, 30, 2048]), num_elements=61440
img_cond:   shape=torch.Size([1, 4374, 2048]), num_elements=8957952
state_traj: shape=torch.Size([1, 1, 2048]), num_elements=2048
Terminated
